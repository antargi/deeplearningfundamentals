{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Versión de PyTorch: 2.5.1\n",
      "Versión de CUDA usada por PyTorch: 12.1\n"
     ]
    }
   ],
   "source": [
    "print(\"Versión de PyTorch:\", torch.__version__)\n",
    "print(\"Versión de CUDA usada por PyTorch:\", torch.version.cuda)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset> Size: 2TB\n",
      "Dimensions:                                           (time: 93544,\n",
      "                                                       longitude: 240,\n",
      "                                                       latitude: 121, level: 13)\n",
      "Coordinates:\n",
      "  * latitude                                          (latitude) float64 968B ...\n",
      "  * level                                             (level) int64 104B 50 ....\n",
      "  * longitude                                         (longitude) float64 2kB ...\n",
      "  * time                                              (time) datetime64[ns] 748kB ...\n",
      "Data variables: (12/62)\n",
      "    10m_u_component_of_wind                           (time, longitude, latitude) float32 11GB ...\n",
      "    10m_v_component_of_wind                           (time, longitude, latitude) float32 11GB ...\n",
      "    10m_wind_speed                                    (time, longitude, latitude) float32 11GB ...\n",
      "    2m_dewpoint_temperature                           (time, longitude, latitude) float32 11GB ...\n",
      "    2m_temperature                                    (time, longitude, latitude) float32 11GB ...\n",
      "    above_ground                                      (time, level, longitude, latitude) float32 141GB ...\n",
      "    ...                                                ...\n",
      "    volumetric_soil_water_layer_1                     (time, longitude, latitude) float32 11GB ...\n",
      "    volumetric_soil_water_layer_2                     (time, longitude, latitude) float32 11GB ...\n",
      "    volumetric_soil_water_layer_3                     (time, longitude, latitude) float32 11GB ...\n",
      "    volumetric_soil_water_layer_4                     (time, longitude, latitude) float32 11GB ...\n",
      "    vorticity                                         (time, level, longitude, latitude) float32 141GB ...\n",
      "    wind_speed                                        (time, level, longitude, latitude) float32 141GB ...\n"
     ]
    }
   ],
   "source": [
    "dataset_path = 'gs://weatherbench2/datasets/era5/1959-2023_01_10-6h-240x121_equiangular_with_poles_conservative.zarr'\n",
    "ds = xr.open_zarr(dataset_path, consolidated=True)\n",
    "print(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensiones del dataset: FrozenMappingWarningOnValuesAccess({'time': 93544, 'longitude': 240, 'latitude': 121, 'level': 13})\n"
     ]
    }
   ],
   "source": [
    "print(\"Dimensiones del dataset:\", ds.dims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset> Size: 12MB\n",
      "Dimensions:                                           (time: 5, longitude: 50,\n",
      "                                                       latitude: 50, level: 13)\n",
      "Coordinates:\n",
      "  * latitude                                          (latitude) float64 400B ...\n",
      "  * level                                             (level) int64 104B 50 ....\n",
      "  * longitude                                         (longitude) float64 400B ...\n",
      "  * time                                              (time) datetime64[ns] 40B ...\n",
      "Data variables: (12/62)\n",
      "    10m_u_component_of_wind                           (time, longitude, latitude) float32 50kB ...\n",
      "    10m_v_component_of_wind                           (time, longitude, latitude) float32 50kB ...\n",
      "    10m_wind_speed                                    (time, longitude, latitude) float32 50kB ...\n",
      "    2m_dewpoint_temperature                           (time, longitude, latitude) float32 50kB ...\n",
      "    2m_temperature                                    (time, longitude, latitude) float32 50kB ...\n",
      "    above_ground                                      (time, level, longitude, latitude) float32 650kB ...\n",
      "    ...                                                ...\n",
      "    volumetric_soil_water_layer_1                     (time, longitude, latitude) float32 50kB ...\n",
      "    volumetric_soil_water_layer_2                     (time, longitude, latitude) float32 50kB ...\n",
      "    volumetric_soil_water_layer_3                     (time, longitude, latitude) float32 50kB ...\n",
      "    volumetric_soil_water_layer_4                     (time, longitude, latitude) float32 50kB ...\n",
      "    vorticity                                         (time, level, longitude, latitude) float32 650kB ...\n",
      "    wind_speed                                        (time, level, longitude, latitude) float32 650kB ...\n"
     ]
    }
   ],
   "source": [
    "subset = ds.isel(latitude=slice(0, 50), longitude=slice(0, 50), time=slice(0, 5))\n",
    "print(subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10m_u_component_of_wind: (5, 50, 50)\n",
      "10m_v_component_of_wind: (5, 50, 50)\n",
      "10m_wind_speed: (5, 50, 50)\n",
      "2m_dewpoint_temperature: (5, 50, 50)\n",
      "2m_temperature: (5, 50, 50)\n",
      "above_ground: (5, 13, 50, 50)\n",
      "ageostrophic_wind_speed: (5, 13, 50, 50)\n",
      "angle_of_sub_gridscale_orography: (50, 50)\n",
      "anisotropy_of_sub_gridscale_orography: (50, 50)\n",
      "boundary_layer_height: (5, 50, 50)\n",
      "divergence: (5, 13, 50, 50)\n",
      "eddy_kinetic_energy: (5, 50, 50)\n",
      "geopotential: (5, 13, 50, 50)\n",
      "geopotential_at_surface: (50, 50)\n",
      "geostrophic_wind_speed: (5, 13, 50, 50)\n",
      "high_vegetation_cover: (50, 50)\n",
      "integrated_vapor_transport: (5, 50, 50)\n",
      "lake_cover: (50, 50)\n",
      "land_sea_mask: (50, 50)\n",
      "lapse_rate: (5, 13, 50, 50)\n",
      "leaf_area_index_high_vegetation: (5, 50, 50)\n",
      "leaf_area_index_low_vegetation: (5, 50, 50)\n",
      "low_vegetation_cover: (50, 50)\n",
      "mean_sea_level_pressure: (5, 50, 50)\n",
      "mean_surface_latent_heat_flux: (5, 50, 50)\n",
      "mean_surface_net_long_wave_radiation_flux: (5, 50, 50)\n",
      "mean_surface_net_short_wave_radiation_flux: (5, 50, 50)\n",
      "mean_surface_sensible_heat_flux: (5, 50, 50)\n",
      "mean_top_downward_short_wave_radiation_flux: (5, 50, 50)\n",
      "mean_top_net_long_wave_radiation_flux: (5, 50, 50)\n",
      "mean_top_net_short_wave_radiation_flux: (5, 50, 50)\n",
      "mean_vertically_integrated_moisture_divergence: (5, 50, 50)\n",
      "potential_vorticity: (5, 13, 50, 50)\n",
      "relative_humidity: (5, 13, 50, 50)\n",
      "sea_ice_cover: (5, 50, 50)\n",
      "sea_surface_temperature: (5, 50, 50)\n",
      "slope_of_sub_gridscale_orography: (50, 50)\n",
      "snow_depth: (5, 50, 50)\n",
      "soil_type: (50, 50)\n",
      "specific_humidity: (5, 13, 50, 50)\n",
      "standard_deviation_of_filtered_subgrid_orography: (50, 50)\n",
      "standard_deviation_of_orography: (50, 50)\n",
      "surface_pressure: (5, 50, 50)\n",
      "temperature: (5, 13, 50, 50)\n",
      "total_cloud_cover: (5, 50, 50)\n",
      "total_column_vapor: (5, 50, 50)\n",
      "total_column_water: (5, 50, 50)\n",
      "total_column_water_vapour: (5, 50, 50)\n",
      "total_precipitation_12hr: (5, 50, 50)\n",
      "total_precipitation_24hr: (5, 50, 50)\n",
      "total_precipitation_6hr: (5, 50, 50)\n",
      "type_of_high_vegetation: (50, 50)\n",
      "type_of_low_vegetation: (50, 50)\n",
      "u_component_of_wind: (5, 13, 50, 50)\n",
      "v_component_of_wind: (5, 13, 50, 50)\n",
      "vertical_velocity: (5, 13, 50, 50)\n",
      "volumetric_soil_water_layer_1: (5, 50, 50)\n",
      "volumetric_soil_water_layer_2: (5, 50, 50)\n",
      "volumetric_soil_water_layer_3: (5, 50, 50)\n",
      "volumetric_soil_water_layer_4: (5, 50, 50)\n",
      "vorticity: (5, 13, 50, 50)\n",
      "wind_speed: (5, 13, 50, 50)\n"
     ]
    }
   ],
   "source": [
    "for var in subset.data_vars:\n",
    "    print(f\"{var}: {subset[var].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset> Size: 3MB\n",
      "Dimensions:                  (time: 5, level: 13, longitude: 50, latitude: 50)\n",
      "Coordinates:\n",
      "  * latitude                 (latitude) float64 400B -90.0 -88.5 ... -18.0 -16.5\n",
      "  * level                    (level) int64 104B 50 100 150 200 ... 850 925 1000\n",
      "  * longitude                (longitude) float64 400B 0.0 1.5 3.0 ... 72.0 73.5\n",
      "  * time                     (time) datetime64[ns] 40B 1959-01-01 ... 1959-01-02\n",
      "Data variables:\n",
      "    u_component_of_wind      (time, level, longitude, latitude) float32 650kB ...\n",
      "    v_component_of_wind      (time, level, longitude, latitude) float32 650kB ...\n",
      "    temperature              (time, level, longitude, latitude) float32 650kB ...\n",
      "    specific_humidity        (time, level, longitude, latitude) float32 650kB ...\n",
      "    mean_sea_level_pressure  (time, longitude, latitude) float32 50kB ...\n"
     ]
    }
   ],
   "source": [
    "variables = ['u_component_of_wind', 'v_component_of_wind', \n",
    "             'temperature', 'specific_humidity', 'mean_sea_level_pressure']\n",
    "\n",
    "subset_selected = subset[variables]\n",
    "print(subset_selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 3 timestamps\n",
      "Val size: 1 timestamps\n",
      "Test size: 1 timestamps\n"
     ]
    }
   ],
   "source": [
    "train_idx = 3  # Timestamps para entrenamiento\n",
    "val_idx = 4    # Timestamps para validación\n",
    "test_idx = 5   # Timestamps para prueba\n",
    "\n",
    "# Crear los conjuntos\n",
    "train_data = subset_selected.isel(time=slice(0, train_idx))\n",
    "val_data = subset_selected.isel(time=slice(train_idx, val_idx))\n",
    "test_data = subset_selected.isel(time=slice(val_idx, test_idx))\n",
    "\n",
    "# Confirmar tamaños\n",
    "print(f\"Train size: {train_data['time'].shape[0]} timestamps\")\n",
    "print(f\"Val size: {val_data['time'].shape[0]} timestamps\")\n",
    "print(f\"Test size: {test_data['time'].shape[0]} timestamps\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "u_mean = train_data['u_component_of_wind'].mean().values\n",
    "u_std = train_data['u_component_of_wind'].std().values\n",
    "v_mean = train_data['v_component_of_wind'].mean().values\n",
    "v_std = train_data['v_component_of_wind'].std().values\n",
    "T_mean = train_data['temperature'].mean().values\n",
    "T_std = train_data['temperature'].std().values\n",
    "q_mean = train_data['specific_humidity'].mean().values\n",
    "q_std = train_data['specific_humidity'].std().values\n",
    "p_mean = train_data['mean_sea_level_pressure'].mean().values\n",
    "p_std = train_data['mean_sea_level_pressure'].std().values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "u_mean: 7.663863658905029, u_std: 13.974626541137695\n",
      "v_mean: -0.7824493050575256, v_std: 5.975970268249512\n",
      "T_mean: 244.31552124023438, T_std: 24.694271087646484\n",
      "q_mean: 0.0013965974794700742, q_std: 0.0030203547794371843\n",
      "p_mean: 100022.3203125, p_std: 1284.899658203125\n"
     ]
    }
   ],
   "source": [
    "print(f\"u_mean: {u_mean}, u_std: {u_std}\")\n",
    "print(f\"v_mean: {v_mean}, v_std: {v_std}\")\n",
    "print(f\"T_mean: {T_mean}, T_std: {T_std}\")\n",
    "print(f\"q_mean: {q_mean}, q_std: {q_std}\")\n",
    "print(f\"p_mean: {p_mean}, p_std: {p_std}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "u_train = (train_data['u_component_of_wind'] - u_mean) / u_std\n",
    "v_train = (train_data['v_component_of_wind'] - v_mean) / v_std\n",
    "T_train = (train_data['temperature'] - T_mean) / T_std\n",
    "q_train = (train_data['specific_humidity'] - q_mean) / q_std\n",
    "p_train = (train_data['mean_sea_level_pressure'] - p_mean) / p_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "u_val = (val_data['u_component_of_wind'] - u_mean) / u_std\n",
    "v_val = (val_data['v_component_of_wind'] - v_mean) / v_std\n",
    "T_val = (val_data['temperature'] - T_mean) / T_std\n",
    "q_val = (val_data['specific_humidity'] - q_mean) / q_std\n",
    "p_val = (val_data['mean_sea_level_pressure'] - p_mean) / p_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "u_test = (test_data['u_component_of_wind'] - u_mean) / u_std\n",
    "v_test = (test_data['v_component_of_wind'] - v_mean) / v_std\n",
    "T_test = (test_data['temperature'] - T_mean) / T_std\n",
    "q_test = (test_data['specific_humidity'] - q_mean) / q_std\n",
    "p_test = (test_data['mean_sea_level_pressure'] - p_mean) / p_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "u_train_tensor = torch.tensor(u_train.values, dtype=torch.float32, requires_grad=True)\n",
    "v_train_tensor = torch.tensor(v_train.values, dtype=torch.float32, requires_grad=True)\n",
    "T_train_tensor = torch.tensor(T_train.values, dtype=torch.float32, requires_grad=True)\n",
    "q_train_tensor = torch.tensor(q_train.values, dtype=torch.float32, requires_grad=True)\n",
    "p_train_tensor = torch.tensor(p_train.values, dtype=torch.float32, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "u_val_tensor = torch.tensor(u_val.values, dtype=torch.float32)\n",
    "v_val_tensor = torch.tensor(v_val.values, dtype=torch.float32)\n",
    "T_val_tensor = torch.tensor(T_val.values, dtype=torch.float32)\n",
    "q_val_tensor = torch.tensor(q_val.values, dtype=torch.float32)\n",
    "p_val_tensor = torch.tensor(p_val.values, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "u_test_tensor = torch.tensor(u_test.values, dtype=torch.float32)\n",
    "v_test_tensor = torch.tensor(v_test.values, dtype=torch.float32)\n",
    "T_test_tensor = torch.tensor(T_test.values, dtype=torch.float32)\n",
    "q_test_tensor = torch.tensor(q_test.values, dtype=torch.float32)\n",
    "p_test_tensor = torch.tensor(p_test.values, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "u_test_tensor: torch.Size([1, 13, 50, 50])\n",
      "v_test_tensor: torch.Size([1, 13, 50, 50])\n",
      "T_test_tensor: torch.Size([1, 13, 50, 50])\n",
      "q_test_tensor: torch.Size([1, 13, 50, 50])\n",
      "p_test_tensor: torch.Size([1, 50, 50])\n"
     ]
    }
   ],
   "source": [
    "# Verificar dimensiones\n",
    "print(f\"u_test_tensor: {u_test_tensor.shape}\")\n",
    "print(f\"v_test_tensor: {v_test_tensor.shape}\")\n",
    "print(f\"T_test_tensor: {T_test_tensor.shape}\")\n",
    "print(f\"q_test_tensor: {q_test_tensor.shape}\")\n",
    "print(f\"p_test_tensor: {p_test_tensor.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "pe_test_tensor = p_test_tensor.unsqueeze(1).repeat(1, 13, 1, 1)\n",
    "pe_train_tensor = p_train_tensor.unsqueeze(1).repeat(1, 13, 1, 1)\n",
    "pe_val_tensor =  p_val_tensor.unsqueeze(1).repeat(1, 13, 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ejemplo de u_test_tensor: -0.7994946241378784\n",
      "Ejemplo de v_test_tensor: 0.6234625577926636\n",
      "Ejemplo de T_test_tensor: -0.2519680857658386\n",
      "Ejemplo de q_test_tensor: -0.4612972140312195\n",
      "Ejemplo de pe_test_tensor: 0.08538483083248138\n"
     ]
    }
   ],
   "source": [
    "# Verificar valores de ejemplo\n",
    "print(f\"Ejemplo de u_test_tensor: {u_test_tensor[0, 0, 0, 0]}\")\n",
    "print(f\"Ejemplo de v_test_tensor: {v_test_tensor[0, 0, 0, 0]}\")\n",
    "print(f\"Ejemplo de T_test_tensor: {T_test_tensor[0, 0, 0, 0]}\")\n",
    "print(f\"Ejemplo de q_test_tensor: {q_test_tensor[0, 0, 0, 0]}\")\n",
    "print(f\"Ejemplo de pe_test_tensor: {pe_test_tensor[0, 0, 0, 0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forma de u_train_tensor: torch.Size([3, 13, 50, 50])\n",
      "Forma de v_train_tensor: torch.Size([3, 13, 50, 50])\n",
      "Forma de T_train_tensor: torch.Size([3, 13, 50, 50])\n",
      "Forma de q_train_tensor: torch.Size([3, 13, 50, 50])\n",
      "Forma de pe_train_tensor: torch.Size([3, 13, 50, 50])\n"
     ]
    }
   ],
   "source": [
    "print(f\"Forma de u_train_tensor: {u_train_tensor.shape}\")\n",
    "print(f\"Forma de v_train_tensor: {v_train_tensor.shape}\")\n",
    "print(f\"Forma de T_train_tensor: {T_train_tensor.shape}\")\n",
    "print(f\"Forma de q_train_tensor: {q_train_tensor.shape}\")\n",
    "print(f\"Forma de pe_train_tensor: {pe_train_tensor.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "longitudes = subset_selected['longitude'].values\n",
    "latitudes = subset_selected['latitude'].values\n",
    "levels = subset_selected['level'].values\n",
    "times = subset_selected['time'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizar longitudes y latitudes\n",
    "longitudes_min, longitudes_max = longitudes.min(), longitudes.max()\n",
    "latitudes_min, latitudes_max = latitudes.min(), latitudes.max()\n",
    "levels_min, levels_max = levels.min(), levels.max()\n",
    "\n",
    "# Normalizar tiempo (asumiendo que ya has convertido a numérico)\n",
    "times_numeric = (times - np.datetime64('1970-01-01T00:00:00')) / np.timedelta64(1, 's')\n",
    "times_min, times_max = times_numeric.min(), times_numeric.max()\n",
    "\n",
    "longitudes_normalized = (longitudes - longitudes_min) / (longitudes_max - longitudes_min + 1e-8)\n",
    "latitudes_normalized = (latitudes - latitudes_min) / (latitudes_max - latitudes_min + 1e-8)\n",
    "levels_normalized = (levels - levels_min) / (levels_max - levels_min + 1e-8)\n",
    "times_normalized = (times_numeric - times_min) / (times_max - times_min + 1e-8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Longitudes normalizadas: 0.0 - 0.9999999998639456\n",
      "Latitudes normalizadas: 0.0 - 0.9999999998639456\n",
      "Tiempos normalizados: 0.0 - 0.9999999999998843\n",
      "Niveles normalizados: 0.0 - 0.9999999999894736\n"
     ]
    }
   ],
   "source": [
    "print(f\"Longitudes normalizadas: {longitudes_normalized.min()} - {longitudes_normalized.max()}\")\n",
    "print(f\"Latitudes normalizadas: {latitudes_normalized.min()} - {latitudes_normalized.max()}\")\n",
    "print(f\"Tiempos normalizados: {times_normalized.min()} - {times_normalized.max()}\")\n",
    "print(f\"Niveles normalizados: {levels_normalized.min()} - {levels_normalized.max()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Longitudes: (50,), Latitudes: (50,), Times: (5,), Levels: (13,)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Longitudes: {longitudes.shape}, Latitudes: {latitudes.shape}, Times: {times.shape}, Levels: {levels.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_coords, y_coords, t_coords, level_coords = np.meshgrid(\n",
    "    longitudes_normalized, latitudes_normalized, times_normalized[:u_train_tensor.shape[0]], levels_normalized, indexing=\"ij\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = np.stack([\n",
    "    x_coords.flatten(),\n",
    "    y_coords.flatten(),\n",
    "    t_coords.flatten(),\n",
    "    level_coords.flatten()\n",
    "], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_tensor = torch.tensor(inputs, dtype=torch.float32, requires_grad=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PINNWithCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(PINNWithCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(4, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv3 = nn.Conv2d(64, 5, kernel_size=3, stride=1, padding=1)  # Cambiar a 5 canales de salida\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = nn.ReLU()(self.conv1(x))\n",
    "        x = nn.ReLU()(self.conv2(x))\n",
    "        x = self.conv3(x)  # Última capa genera 5 canales\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PINN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(PINN, self).__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(4, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(128), \n",
    "            nn.Dropout(0.2),   \n",
    "            nn.Linear(128, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 5)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy(pred, true, tolerance=0.05):\n",
    "    \"\"\"\n",
    "    Calcula el porcentaje de predicciones dentro de un rango de tolerancia.\n",
    "    \"\"\"\n",
    "    relative_error = torch.abs((pred - true) / true)\n",
    "    accurate_predictions = torch.sum(relative_error <= tolerance).item()\n",
    "    total_predictions = true.numel()\n",
    "    accuracy = accurate_predictions / total_predictions\n",
    "    return accuracy * 100  # Porcentaje"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_gradients(pred, x):\n",
    "    grad = torch.autograd.grad(pred.sum(), x, create_graph=True, retain_graph=True)[0]\n",
    "    return grad[:, 0], grad[:, 1], grad[:, 2]  # Devuelve las derivadas parciales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_pde(model, x, u_true, v_true, p_true, T_true, q_true, alpha=1.0, beta=1.0):\n",
    "    pred = model(x)\n",
    "    u_pred, v_pred, p_pred, T_pred, q_pred = pred[:, 0], pred[:, 1], pred[:, 2], pred[:, 3], pred[:, 4]\n",
    "\n",
    "    # Calcula gradientes para cada término\n",
    "    u_x, u_y, u_t = compute_gradients(u_pred, x)\n",
    "    v_x, v_y, v_t = compute_gradients(v_pred, x)\n",
    "    T_x, T_y, T_t = compute_gradients(T_pred, x)\n",
    "    q_x, q_y, q_t = compute_gradients(q_pred, x)\n",
    "    p_x, p_y, _ = compute_gradients(p_pred, x)\n",
    "\n",
    "    # Define los términos de la pérdida\n",
    "    momentum_u = u_t + u_pred * u_x + v_pred * u_y + p_x\n",
    "    momentum_v = v_t + u_pred * v_x + v_pred * v_y + p_y\n",
    "    continuity = u_x + v_y\n",
    "    energy = T_t + u_pred * T_x + v_pred * T_y\n",
    "    moisture = q_t + u_pred * q_x + v_pred * q_y\n",
    "\n",
    "    loss_data = (\n",
    "        torch.mean((u_pred - u_true) ** 2) +\n",
    "        torch.mean((v_pred - v_true) ** 2) +\n",
    "        torch.mean((p_pred - p_true) ** 2) +\n",
    "        torch.mean((T_pred - T_true) ** 2) +\n",
    "        torch.mean((q_pred - q_true) ** 2)\n",
    "    )\n",
    "\n",
    "    loss_physics = (\n",
    "        torch.mean(momentum_u ** 2) +\n",
    "        torch.mean(momentum_v ** 2) +\n",
    "        torch.mean(continuity ** 2) +\n",
    "        torch.mean(energy ** 2) +\n",
    "        torch.mean(moisture ** 2)\n",
    "    )\n",
    "\n",
    "    loss_total = alpha * loss_data + beta * loss_physics\n",
    "    return loss_total, loss_data, loss_physics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "u_train_flat.requires_grad: True\n",
      "v_train_flat.requires_grad: True\n",
      "T_train_flat.requires_grad: True\n",
      "q_train_flat.requires_grad: True\n",
      "p_train_flat.requires_grad: True\n",
      "Forma de inputs_tensor: torch.Size([97500, 4])\n",
      "Forma de u_train_flat: torch.Size([97500])\n",
      "Forma de v_train_flat: torch.Size([97500])\n",
      "Forma de T_train_flat: torch.Size([97500])\n",
      "Forma de q_train_flat: torch.Size([97500])\n",
      "Forma de p_train_flat: torch.Size([97500])\n"
     ]
    }
   ],
   "source": [
    "# Ajustar las dimensiones para que coincidan\n",
    "u_train_flat = u_train_tensor.flatten()\n",
    "v_train_flat = v_train_tensor.flatten()\n",
    "T_train_flat = T_train_tensor.flatten()\n",
    "q_train_flat = q_train_tensor.flatten()\n",
    "p_train_flat = pe_train_tensor.flatten()\n",
    "\n",
    "print(f\"u_train_flat.requires_grad: {u_train_flat.requires_grad}\")\n",
    "print(f\"v_train_flat.requires_grad: {v_train_flat.requires_grad}\")\n",
    "print(f\"T_train_flat.requires_grad: {T_train_flat.requires_grad}\")\n",
    "print(f\"q_train_flat.requires_grad: {q_train_flat.requires_grad}\")\n",
    "print(f\"p_train_flat.requires_grad: {p_train_flat.requires_grad}\")\n",
    "\n",
    "print(f\"Forma de inputs_tensor: {inputs_tensor.shape}\")\n",
    "print(f\"Forma de u_train_flat: {u_train_flat.shape}\")\n",
    "print(f\"Forma de v_train_flat: {v_train_flat.shape}\")\n",
    "print(f\"Forma de T_train_flat: {T_train_flat.shape}\")\n",
    "print(f\"Forma de q_train_flat: {q_train_flat.shape}\")\n",
    "print(f\"Forma de p_train_flat: {p_train_flat.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probando batch_size = 16...\n",
      "Batch size 16: Tiempo por batch = 0.0031s, Tiempo por época = 3.98s\n",
      "Probando batch_size = 32...\n",
      "Batch size 32: Tiempo por batch = 0.0061s, Tiempo por época = 2.72s\n",
      "Probando batch_size = 64...\n",
      "Batch size 64: Tiempo por batch = 0.0027s, Tiempo por época = 2.14s\n",
      "Probando batch_size = 128...\n",
      "Batch size 128: Tiempo por batch = 0.0042s, Tiempo por época = 2.02s\n",
      "Probando batch_size = 256...\n",
      "Batch size 256: Tiempo por batch = 0.0059s, Tiempo por época = 2.01s\n",
      "Probando batch_size = 256...\n",
      "Batch size 256: Tiempo por batch = 0.0062s, Tiempo por época = 2.21s\n",
      "Probando batch_size = 512...\n",
      "Batch size 512: Tiempo por batch = 0.0181s, Tiempo por época = 1.74s\n",
      "\n",
      "Resultados finales:\n",
      "Batch size 16: Tiempo por batch = 0.0031s, Tiempo por época = 3.98s\n",
      "Batch size 32: Tiempo por batch = 0.0061s, Tiempo por época = 2.72s\n",
      "Batch size 64: Tiempo por batch = 0.0027s, Tiempo por época = 2.14s\n",
      "Batch size 128: Tiempo por batch = 0.0042s, Tiempo por época = 2.02s\n",
      "Batch size 256: Tiempo por batch = 0.0062s, Tiempo por época = 2.21s\n",
      "Batch size 512: Tiempo por batch = 0.0181s, Tiempo por época = 1.74s\n"
     ]
    }
   ],
   "source": [
    "# Lista de batch sizes a probar\n",
    "batch_sizes = [16, 32, 64, 128, 256, 256, 512]\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Resultados almacenados\n",
    "batch_results = {}\n",
    "\n",
    "for batch_size in batch_sizes:\n",
    "    print(f\"Probando batch_size = {batch_size}...\")\n",
    "    \n",
    "    # Crear DataLoader con el batch size actual\n",
    "    loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    # Inicializar el modelo y mover a GPU\n",
    "    model = PINN().to(device)\n",
    "\n",
    "    # Medir tiempo para procesar un batch\n",
    "    start_time = time.time()\n",
    "    for batch in loader:\n",
    "        inputs, u_true, v_true, p_true, T_true, q_true = [t.to(device) for t in batch]\n",
    "        with torch.no_grad():  # Solo evaluación, sin retropropagación\n",
    "            pred = model(inputs)\n",
    "        break  # Solo medir el primer batch\n",
    "    elapsed_time_batch = time.time() - start_time\n",
    "\n",
    "    # (Opcional) Medir tiempo para procesar toda una época\n",
    "    start_time_epoch = time.time()\n",
    "    for batch in loader:\n",
    "        inputs, u_true, v_true, p_true, T_true, q_true = [t.to(device) for t in batch]\n",
    "        with torch.no_grad():\n",
    "            pred = model(inputs)\n",
    "    elapsed_time_epoch = time.time() - start_time_epoch\n",
    "\n",
    "    # Almacenar resultados\n",
    "    batch_results[batch_size] = {\n",
    "        \"time_per_batch\": elapsed_time_batch,\n",
    "        \"time_per_epoch\": elapsed_time_epoch,\n",
    "    }\n",
    "    print(f\"Batch size {batch_size}: Tiempo por batch = {elapsed_time_batch:.4f}s, Tiempo por época = {elapsed_time_epoch:.2f}s\")\n",
    "\n",
    "# Mostrar resultados finales\n",
    "print(\"\\nResultados finales:\")\n",
    "for batch_size, results in batch_results.items():\n",
    "    print(\n",
    "        f\"Batch size {batch_size}: \"\n",
    "        f\"Tiempo por batch = {results['time_per_batch']:.4f}s, \"\n",
    "        f\"Tiempo por época = {results['time_per_epoch']:.2f}s\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = TensorDataset(inputs_tensor, u_train_flat, v_train_flat, p_train_flat, T_train_flat, q_train_flat)\n",
    "loader = DataLoader(dataset, batch_size=256, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, loader, inputs_tensor, u_train_flat, v_train_flat, p_train_flat, \n",
    "                T_train_flat, q_train_flat, optimizer, loss_pde, compute_accuracy, \n",
    "                device, alpha=1.0, beta=10.0, epochs=1000):\n",
    "    model.to(device)\n",
    "    inputs_tensor = inputs_tensor.to(device)\n",
    "    u_train_flat = u_train_flat.to(device)\n",
    "    v_train_flat = v_train_flat.to(device)\n",
    "    p_train_flat = p_train_flat.to(device)\n",
    "    T_train_flat = T_train_flat.to(device)\n",
    "    q_train_flat = q_train_flat.to(device)\n",
    "\n",
    "    loss_history = []\n",
    "    accuracy_history = {\n",
    "        \"u\": [],\n",
    "        \"v\": [],\n",
    "        \"p\": [],\n",
    "        \"T\": [],\n",
    "        \"q\": []\n",
    "    }\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()  # Modo entrenamiento\n",
    "        epoch_loss_total = 0.0\n",
    "        start_time = time.time()\n",
    "\n",
    "        for batch in loader:\n",
    "            inputs, u_true, v_true, p_true, T_true, q_true = [t.to(device) for t in batch]\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            loss_total, loss_data, loss_physics = loss_pde(model, inputs, u_true, v_true, p_true, T_true, q_true, alpha, beta)\n",
    "            loss_total.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Acumula la pérdida total\n",
    "            epoch_loss_total += loss_total.item()\n",
    "\n",
    "        loss_history.append(epoch_loss_total / len(loader))\n",
    "\n",
    "        # Evaluar precisión después de la época\n",
    "        model.eval()  # Modo evaluación (sin dropout, etc.)\n",
    "        with torch.no_grad():\n",
    "            predictions = model(inputs_tensor)\n",
    "            u_pred, v_pred, p_pred, T_pred, q_pred = predictions[:, 0], predictions[:, 1], predictions[:, 2], predictions[:, 3], predictions[:, 4]\n",
    "\n",
    "            u_accuracy = compute_accuracy(u_pred, u_train_flat)\n",
    "            v_accuracy = compute_accuracy(v_pred, v_train_flat)\n",
    "            p_accuracy = compute_accuracy(p_pred, p_train_flat)\n",
    "            T_accuracy = compute_accuracy(T_pred, T_train_flat)\n",
    "            q_accuracy = compute_accuracy(q_pred, q_train_flat)\n",
    "\n",
    "            # Registrar precisión\n",
    "            accuracy_history[\"u\"].append(u_accuracy)\n",
    "            accuracy_history[\"v\"].append(v_accuracy)\n",
    "            accuracy_history[\"p\"].append(p_accuracy)\n",
    "            accuracy_history[\"T\"].append(T_accuracy)\n",
    "            accuracy_history[\"q\"].append(q_accuracy)\n",
    "\n",
    "        print(f\"Epoch {epoch}, Loss Total: {epoch_loss_total / len(loader):.6f}, \"\n",
    "              f\"Accuracy: u={u_accuracy:.2f}%, v={v_accuracy:.2f}%, p={p_accuracy:.2f}%, \"\n",
    "              f\"T={T_accuracy:.2f}%, q={q_accuracy:.2f}%, time {time.time() - start_time:.2f} s\")\n",
    "\n",
    "    return loss_history, accuracy_history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss Total: nan, Accuracy: u=0.00%, v=0.00%, p=0.00%, T=0.00%, q=0.00%, time 18.97 s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[269], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m model \u001b[38;5;241m=\u001b[39m PINN()\n\u001b[0;32m      2\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mSGD(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-2\u001b[39m, momentum\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.9\u001b[39m, weight_decay\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-2\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m loss_history, accuracy_history \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mloader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_tensor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_tensor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mu_train_flat\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mu_train_flat\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mv_train_flat\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mv_train_flat\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mp_train_flat\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mp_train_flat\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mT_train_flat\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mT_train_flat\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mq_train_flat\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mq_train_flat\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mloss_pde\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloss_pde\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompute_accuracy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompute_accuracy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43malpha\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1.0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbeta\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10.0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\n\u001b[0;32m     19\u001b[0m \u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[219], line 32\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(model, loader, inputs_tensor, u_train_flat, v_train_flat, p_train_flat, T_train_flat, q_train_flat, optimizer, loss_pde, compute_accuracy, device, alpha, beta, epochs)\u001b[0m\n\u001b[0;32m     29\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m     31\u001b[0m loss_total, loss_data, loss_physics \u001b[38;5;241m=\u001b[39m loss_pde(model, inputs, u_true, v_true, p_true, T_true, q_true, alpha, beta)\n\u001b[1;32m---> 32\u001b[0m \u001b[43mloss_total\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     33\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m     35\u001b[0m \u001b[38;5;66;03m# Acumula la pérdida total\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Antonina\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\torch\\_tensor.py:581\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    571\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    572\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    573\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    574\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    579\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    580\u001b[0m     )\n\u001b[1;32m--> 581\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    582\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    583\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Antonina\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\torch\\autograd\\__init__.py:347\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    342\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    344\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    345\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    346\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 347\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    355\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Antonina\\anaconda3\\envs\\pytorch_env\\lib\\site-packages\\torch\\autograd\\graph.py:825\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[1;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    823\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[0;32m    824\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 825\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Variable\u001b[38;5;241m.\u001b[39m_execution_engine\u001b[38;5;241m.\u001b[39mrun_backward(  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    826\u001b[0m         t_outputs, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    827\u001b[0m     )  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    828\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    829\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = PINN()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-2, momentum=0.9, weight_decay=1e-2)\n",
    "loss_history, accuracy_history = train_model(\n",
    "    model=model,\n",
    "    loader=loader,\n",
    "    inputs_tensor=inputs_tensor,\n",
    "    u_train_flat=u_train_flat,\n",
    "    v_train_flat=v_train_flat,\n",
    "    p_train_flat=p_train_flat,\n",
    "    T_train_flat=T_train_flat,\n",
    "    q_train_flat=q_train_flat,\n",
    "    optimizer=optimizer,\n",
    "    loss_pde=loss_pde,\n",
    "    compute_accuracy=compute_accuracy,\n",
    "    device=device,\n",
    "    alpha=1.0,\n",
    "    beta=10.0,\n",
    "    epochs=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forma truncada para CNN: torch.Size([39, 4, 50, 50])\n"
     ]
    }
   ],
   "source": [
    "# Datos originales: (97500, 4)\n",
    "batch_size = 256  # Tamaño del batch\n",
    "channels = 4  # Número de características (latitud, longitud, nivel, tiempo)\n",
    "height, width = 50, 50  # Dimensiones espaciales\n",
    "\n",
    "num_points = (97500 // (50 * 50)) * (50 * 50)  # Total divisible por 2500\n",
    "\n",
    "# Truncar inputs_tensor\n",
    "inputs_tensor_truncated = inputs_tensor[:num_points]\n",
    "\n",
    "# Reorganizar al formato 4D\n",
    "inputs_tensor_cnn = inputs_tensor_truncated.view(-1, channels, height, width)\n",
    "print(f\"Forma truncada para CNN: {inputs_tensor_cnn.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forma de inputs_tensor_cnn: torch.Size([39, 4, 50, 50])\n",
      "Forma de u_train_flat: torch.Size([97500])\n",
      "Forma de v_train_flat: torch.Size([97500])\n",
      "Forma de p_train_flat: torch.Size([97500])\n",
      "Forma de T_train_flat: torch.Size([97500])\n",
      "Forma de q_train_flat: torch.Size([97500])\n"
     ]
    }
   ],
   "source": [
    "print(f\"Forma de inputs_tensor_cnn: {inputs_tensor_cnn.shape}\")\n",
    "print(f\"Forma de u_train_flat: {u_train_flat[:num_points].shape}\")\n",
    "print(f\"Forma de v_train_flat: {v_train_flat[:num_points].shape}\")\n",
    "print(f\"Forma de p_train_flat: {p_train_flat[:num_points].shape}\")\n",
    "print(f\"Forma de T_train_flat: {T_train_flat[:num_points].shape}\")\n",
    "print(f\"Forma de q_train_flat: {q_train_flat[:num_points].shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forma de u_train_cnn: torch.Size([39, 1, 50, 50])\n",
      "Forma de v_train_cnn: torch.Size([39, 1, 50, 50])\n",
      "Forma de p_train_cnn: torch.Size([39, 1, 50, 50])\n",
      "Forma de T_train_cnn: torch.Size([39, 1, 50, 50])\n",
      "Forma de q_train_cnn: torch.Size([39, 1, 50, 50])\n"
     ]
    }
   ],
   "source": [
    "u_train_cnn = u_train_flat[:num_points].view(-1, 1, height, width)\n",
    "v_train_cnn = v_train_flat[:num_points].view(-1, 1, height, width)\n",
    "p_train_cnn = p_train_flat[:num_points].view(-1, 1, height, width)\n",
    "T_train_cnn = T_train_flat[:num_points].view(-1, 1, height, width)\n",
    "q_train_cnn = q_train_flat[:num_points].view(-1, 1, height, width)\n",
    "\n",
    "# Verificar formas\n",
    "print(f\"Forma de u_train_cnn: {u_train_cnn.shape}\")\n",
    "print(f\"Forma de v_train_cnn: {v_train_cnn.shape}\")\n",
    "print(f\"Forma de p_train_cnn: {p_train_cnn.shape}\")\n",
    "print(f\"Forma de T_train_cnn: {T_train_cnn.shape}\")\n",
    "print(f\"Forma de q_train_cnn: {q_train_cnn.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataLoader creado con éxito: 1 batches\n"
     ]
    }
   ],
   "source": [
    "dataset_cnn = TensorDataset(\n",
    "    inputs_tensor_cnn,  # Entrada para la CNN\n",
    "    u_train_cnn,        # Salidas reorganizadas\n",
    "    v_train_cnn,\n",
    "    p_train_cnn,\n",
    "    T_train_cnn,\n",
    "    q_train_cnn\n",
    ")\n",
    "\n",
    "# Crear el DataLoader\n",
    "loader_cnn = DataLoader(dataset_cnn, batch_size=batch_size, shuffle=True)\n",
    "print(f\"DataLoader creado con éxito: {len(loader_cnn)} batches\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forma del dataset:\n",
      "torch.Size([4, 50, 50])\n",
      "torch.Size([1, 50, 50])\n",
      "torch.Size([1, 50, 50])\n",
      "torch.Size([1, 50, 50])\n",
      "torch.Size([1, 50, 50])\n",
      "torch.Size([1, 50, 50])\n"
     ]
    }
   ],
   "source": [
    "print(f\"Forma del dataset:\")\n",
    "for data in dataset_cnn[0]:\n",
    "    print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_pde_cnn(model, x, u_true, v_true, p_true, T_true, q_true, alpha=1.0, beta=1.0):\n",
    "    pred = model(x)\n",
    "    u_pred, v_pred, p_pred, T_pred, q_pred = pred[:, 0], pred[:, 1], pred[:, 2], pred[:, 3], pred[:, 4]\n",
    "\n",
    "    # Calcula gradientes para cada término\n",
    "    u_x, u_y, u_t = compute_gradients(u_pred, x)\n",
    "    v_x, v_y, v_t = compute_gradients(v_pred, x)\n",
    "    T_x, T_y, T_t = compute_gradients(T_pred, x)\n",
    "    q_x, q_y, q_t = compute_gradients(q_pred, x)\n",
    "    p_x, p_y, _ = compute_gradients(p_pred, x)\n",
    "\n",
    "    # Define los términos de la pérdida\n",
    "    momentum_u = u_t + u_pred * u_x + v_pred * u_y + p_x\n",
    "    momentum_v = v_t + u_pred * v_x + v_pred * v_y + p_y\n",
    "    continuity = u_x + v_y\n",
    "    energy = T_t + u_pred * T_x + v_pred * T_y\n",
    "    moisture = q_t + u_pred * q_x + v_pred * q_y\n",
    "\n",
    "    loss_data = (\n",
    "        torch.mean((u_pred - u_true) ** 2) +\n",
    "        torch.mean((v_pred - v_true) ** 2) +\n",
    "        torch.mean((p_pred - p_true) ** 2) +\n",
    "        torch.mean((T_pred - T_true) ** 2) +\n",
    "        torch.mean((q_pred - q_true) ** 2)\n",
    "    )\n",
    "\n",
    "    loss_physics = (\n",
    "        torch.mean(momentum_u ** 2) +\n",
    "        torch.mean(momentum_v ** 2) +\n",
    "        torch.mean(continuity ** 2) +\n",
    "        torch.mean(energy ** 2) +\n",
    "        torch.mean(moisture ** 2)\n",
    "    )\n",
    "\n",
    "    loss_total = alpha * loss_data + beta * loss_physics\n",
    "    return loss_total, loss_data, loss_physics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000, Total Loss: 5.102061, Data Loss: 5.012743, Physics Loss: 0.008932\n",
      "Epoch 2/2000, Total Loss: 5.071255, Data Loss: 5.010281, Physics Loss: 0.006097\n",
      "Epoch 3/2000, Total Loss: 5.065049, Data Loss: 5.008031, Physics Loss: 0.005702\n",
      "Epoch 4/2000, Total Loss: 5.062542, Data Loss: 5.005773, Physics Loss: 0.005677\n",
      "Epoch 5/2000, Total Loss: 5.046628, Data Loss: 5.003206, Physics Loss: 0.004342\n",
      "Epoch 6/2000, Total Loss: 5.040014, Data Loss: 5.001541, Physics Loss: 0.003847\n",
      "Epoch 7/2000, Total Loss: 5.041282, Data Loss: 5.000997, Physics Loss: 0.004029\n",
      "Epoch 8/2000, Total Loss: 5.035583, Data Loss: 5.000733, Physics Loss: 0.003485\n",
      "Epoch 9/2000, Total Loss: 5.026832, Data Loss: 5.000337, Physics Loss: 0.002650\n",
      "Epoch 10/2000, Total Loss: 5.023716, Data Loss: 4.999869, Physics Loss: 0.002385\n",
      "Epoch 11/2000, Total Loss: 5.023689, Data Loss: 4.999271, Physics Loss: 0.002442\n",
      "Epoch 12/2000, Total Loss: 5.020987, Data Loss: 4.998435, Physics Loss: 0.002255\n",
      "Epoch 13/2000, Total Loss: 5.015994, Data Loss: 4.997500, Physics Loss: 0.001849\n",
      "Epoch 14/2000, Total Loss: 5.012322, Data Loss: 4.996678, Physics Loss: 0.001564\n",
      "Epoch 15/2000, Total Loss: 5.010990, Data Loss: 4.995998, Physics Loss: 0.001499\n",
      "Epoch 16/2000, Total Loss: 5.010021, Data Loss: 4.995318, Physics Loss: 0.001470\n",
      "Epoch 17/2000, Total Loss: 5.007794, Data Loss: 4.994556, Physics Loss: 0.001324\n",
      "Epoch 18/2000, Total Loss: 5.004831, Data Loss: 4.993787, Physics Loss: 0.001104\n",
      "Epoch 19/2000, Total Loss: 5.002638, Data Loss: 4.993134, Physics Loss: 0.000950\n",
      "Epoch 20/2000, Total Loss: 5.001778, Data Loss: 4.992620, Physics Loss: 0.000916\n",
      "Epoch 21/2000, Total Loss: 5.001489, Data Loss: 4.992152, Physics Loss: 0.000934\n",
      "Epoch 22/2000, Total Loss: 5.000728, Data Loss: 4.991608, Physics Loss: 0.000912\n",
      "Epoch 23/2000, Total Loss: 4.999263, Data Loss: 4.990940, Physics Loss: 0.000832\n",
      "Epoch 24/2000, Total Loss: 4.997628, Data Loss: 4.990177, Physics Loss: 0.000745\n",
      "Epoch 25/2000, Total Loss: 4.996370, Data Loss: 4.989387, Physics Loss: 0.000698\n",
      "Epoch 26/2000, Total Loss: 4.995457, Data Loss: 4.988592, Physics Loss: 0.000687\n",
      "Epoch 27/2000, Total Loss: 4.994473, Data Loss: 4.987780, Physics Loss: 0.000669\n",
      "Epoch 28/2000, Total Loss: 4.993229, Data Loss: 4.986953, Physics Loss: 0.000628\n",
      "Epoch 29/2000, Total Loss: 4.991995, Data Loss: 4.986132, Physics Loss: 0.000586\n",
      "Epoch 30/2000, Total Loss: 4.991117, Data Loss: 4.985347, Physics Loss: 0.000577\n",
      "Epoch 31/2000, Total Loss: 4.990534, Data Loss: 4.984603, Physics Loss: 0.000593\n",
      "Epoch 32/2000, Total Loss: 4.989789, Data Loss: 4.983860, Physics Loss: 0.000593\n",
      "Epoch 33/2000, Total Loss: 4.988597, Data Loss: 4.983079, Physics Loss: 0.000552\n",
      "Epoch 34/2000, Total Loss: 4.987154, Data Loss: 4.982251, Physics Loss: 0.000490\n",
      "Epoch 35/2000, Total Loss: 4.985863, Data Loss: 4.981386, Physics Loss: 0.000448\n",
      "Epoch 36/2000, Total Loss: 4.984833, Data Loss: 4.980473, Physics Loss: 0.000436\n",
      "Epoch 37/2000, Total Loss: 4.983774, Data Loss: 4.979479, Physics Loss: 0.000430\n",
      "Epoch 38/2000, Total Loss: 4.982505, Data Loss: 4.978399, Physics Loss: 0.000411\n",
      "Epoch 39/2000, Total Loss: 4.981172, Data Loss: 4.977253, Physics Loss: 0.000392\n",
      "Epoch 40/2000, Total Loss: 4.979998, Data Loss: 4.976078, Physics Loss: 0.000392\n",
      "Epoch 41/2000, Total Loss: 4.978868, Data Loss: 4.974868, Physics Loss: 0.000400\n",
      "Epoch 42/2000, Total Loss: 4.977547, Data Loss: 4.973614, Physics Loss: 0.000393\n",
      "Epoch 43/2000, Total Loss: 4.976082, Data Loss: 4.972322, Physics Loss: 0.000376\n",
      "Epoch 44/2000, Total Loss: 4.974701, Data Loss: 4.970999, Physics Loss: 0.000370\n",
      "Epoch 45/2000, Total Loss: 4.973332, Data Loss: 4.969607, Physics Loss: 0.000372\n",
      "Epoch 46/2000, Total Loss: 4.971762, Data Loss: 4.968088, Physics Loss: 0.000367\n",
      "Epoch 47/2000, Total Loss: 4.970100, Data Loss: 4.966453, Physics Loss: 0.000365\n",
      "Epoch 48/2000, Total Loss: 4.968542, Data Loss: 4.964770, Physics Loss: 0.000377\n",
      "Epoch 49/2000, Total Loss: 4.966916, Data Loss: 4.963058, Physics Loss: 0.000386\n",
      "Epoch 50/2000, Total Loss: 4.965136, Data Loss: 4.961322, Physics Loss: 0.000381\n",
      "Epoch 51/2000, Total Loss: 4.963374, Data Loss: 4.959553, Physics Loss: 0.000382\n",
      "Epoch 52/2000, Total Loss: 4.961514, Data Loss: 4.957692, Physics Loss: 0.000382\n",
      "Epoch 53/2000, Total Loss: 4.959502, Data Loss: 4.955709, Physics Loss: 0.000379\n",
      "Epoch 54/2000, Total Loss: 4.957555, Data Loss: 4.953637, Physics Loss: 0.000392\n",
      "Epoch 55/2000, Total Loss: 4.955532, Data Loss: 4.951488, Physics Loss: 0.000404\n",
      "Epoch 56/2000, Total Loss: 4.953468, Data Loss: 4.949303, Physics Loss: 0.000417\n",
      "Epoch 57/2000, Total Loss: 4.951428, Data Loss: 4.947083, Physics Loss: 0.000435\n",
      "Epoch 58/2000, Total Loss: 4.949192, Data Loss: 4.944795, Physics Loss: 0.000440\n",
      "Epoch 59/2000, Total Loss: 4.947043, Data Loss: 4.942465, Physics Loss: 0.000458\n",
      "Epoch 60/2000, Total Loss: 4.944808, Data Loss: 4.940075, Physics Loss: 0.000473\n",
      "Epoch 61/2000, Total Loss: 4.942670, Data Loss: 4.937674, Physics Loss: 0.000500\n",
      "Epoch 62/2000, Total Loss: 4.940463, Data Loss: 4.935258, Physics Loss: 0.000520\n",
      "Epoch 63/2000, Total Loss: 4.938280, Data Loss: 4.932876, Physics Loss: 0.000540\n",
      "Epoch 64/2000, Total Loss: 4.936086, Data Loss: 4.930510, Physics Loss: 0.000558\n",
      "Epoch 65/2000, Total Loss: 4.934042, Data Loss: 4.928149, Physics Loss: 0.000589\n",
      "Epoch 66/2000, Total Loss: 4.931957, Data Loss: 4.925787, Physics Loss: 0.000617\n",
      "Epoch 67/2000, Total Loss: 4.929936, Data Loss: 4.923546, Physics Loss: 0.000639\n",
      "Epoch 68/2000, Total Loss: 4.928043, Data Loss: 4.921400, Physics Loss: 0.000664\n",
      "Epoch 69/2000, Total Loss: 4.926189, Data Loss: 4.919267, Physics Loss: 0.000692\n",
      "Epoch 70/2000, Total Loss: 4.924442, Data Loss: 4.917254, Physics Loss: 0.000719\n",
      "Epoch 71/2000, Total Loss: 4.922794, Data Loss: 4.915418, Physics Loss: 0.000738\n",
      "Epoch 72/2000, Total Loss: 4.921287, Data Loss: 4.913676, Physics Loss: 0.000761\n",
      "Epoch 73/2000, Total Loss: 4.919878, Data Loss: 4.911965, Physics Loss: 0.000791\n",
      "Epoch 74/2000, Total Loss: 4.918552, Data Loss: 4.910478, Physics Loss: 0.000807\n",
      "Epoch 75/2000, Total Loss: 4.917480, Data Loss: 4.909055, Physics Loss: 0.000843\n",
      "Epoch 76/2000, Total Loss: 4.917095, Data Loss: 4.907910, Physics Loss: 0.000918\n",
      "Epoch 77/2000, Total Loss: 4.919613, Data Loss: 4.907040, Physics Loss: 0.001257\n",
      "Epoch 78/2000, Total Loss: 4.940206, Data Loss: 4.909736, Physics Loss: 0.003047\n",
      "Epoch 79/2000, Total Loss: 5.061516, Data Loss: 4.923230, Physics Loss: 0.013829\n",
      "Epoch 80/2000, Total Loss: 5.903803, Data Loss: 5.105895, Physics Loss: 0.079791\n",
      "Epoch 81/2000, Total Loss: 5.574918, Data Loss: 5.001008, Physics Loss: 0.057391\n",
      "Epoch 82/2000, Total Loss: 4.971076, Data Loss: 4.955198, Physics Loss: 0.001588\n",
      "Epoch 83/2000, Total Loss: 5.049593, Data Loss: 5.018599, Physics Loss: 0.003099\n",
      "Epoch 84/2000, Total Loss: 5.073692, Data Loss: 5.020995, Physics Loss: 0.005270\n",
      "Epoch 85/2000, Total Loss: 5.110615, Data Loss: 5.001866, Physics Loss: 0.010875\n",
      "Epoch 86/2000, Total Loss: 5.077873, Data Loss: 4.988373, Physics Loss: 0.008950\n",
      "Epoch 87/2000, Total Loss: 5.020282, Data Loss: 4.986675, Physics Loss: 0.003361\n",
      "Epoch 88/2000, Total Loss: 5.020520, Data Loss: 4.992137, Physics Loss: 0.002838\n",
      "Epoch 89/2000, Total Loss: 5.056580, Data Loss: 4.997885, Physics Loss: 0.005869\n",
      "Epoch 90/2000, Total Loss: 5.077917, Data Loss: 5.000475, Physics Loss: 0.007744\n",
      "Epoch 91/2000, Total Loss: 5.066731, Data Loss: 4.999578, Physics Loss: 0.006715\n",
      "Epoch 92/2000, Total Loss: 5.038735, Data Loss: 4.996454, Physics Loss: 0.004228\n",
      "Epoch 93/2000, Total Loss: 5.016355, Data Loss: 4.992652, Physics Loss: 0.002370\n",
      "Epoch 94/2000, Total Loss: 5.008111, Data Loss: 4.989303, Physics Loss: 0.001881\n",
      "Epoch 95/2000, Total Loss: 5.010531, Data Loss: 4.986925, Physics Loss: 0.002361\n",
      "Epoch 96/2000, Total Loss: 5.015256, Data Loss: 4.985563, Physics Loss: 0.002969\n",
      "Epoch 97/2000, Total Loss: 5.015904, Data Loss: 4.984931, Physics Loss: 0.003097\n",
      "Epoch 98/2000, Total Loss: 5.011895, Data Loss: 4.984681, Physics Loss: 0.002721\n",
      "Epoch 99/2000, Total Loss: 5.006164, Data Loss: 4.984539, Physics Loss: 0.002162\n",
      "Epoch 100/2000, Total Loss: 5.002042, Data Loss: 4.984357, Physics Loss: 0.001768\n",
      "Epoch 101/2000, Total Loss: 5.000257, Data Loss: 4.984073, Physics Loss: 0.001618\n",
      "Epoch 102/2000, Total Loss: 4.999606, Data Loss: 4.983660, Physics Loss: 0.001595\n",
      "Epoch 103/2000, Total Loss: 4.998677, Data Loss: 4.983112, Physics Loss: 0.001557\n",
      "Epoch 104/2000, Total Loss: 4.996764, Data Loss: 4.982429, Physics Loss: 0.001433\n",
      "Epoch 105/2000, Total Loss: 4.994171, Data Loss: 4.981630, Physics Loss: 0.001254\n",
      "Epoch 106/2000, Total Loss: 4.991565, Data Loss: 4.980757, Physics Loss: 0.001081\n",
      "Epoch 107/2000, Total Loss: 4.989470, Data Loss: 4.979861, Physics Loss: 0.000961\n",
      "Epoch 108/2000, Total Loss: 4.987951, Data Loss: 4.978998, Physics Loss: 0.000895\n",
      "Epoch 109/2000, Total Loss: 4.986765, Data Loss: 4.978211, Physics Loss: 0.000855\n",
      "Epoch 110/2000, Total Loss: 4.985659, Data Loss: 4.977524, Physics Loss: 0.000814\n",
      "Epoch 111/2000, Total Loss: 4.984498, Data Loss: 4.976918, Physics Loss: 0.000758\n",
      "Epoch 112/2000, Total Loss: 4.983253, Data Loss: 4.976357, Physics Loss: 0.000690\n",
      "Epoch 113/2000, Total Loss: 4.981977, Data Loss: 4.975776, Physics Loss: 0.000620\n",
      "Epoch 114/2000, Total Loss: 4.980720, Data Loss: 4.975109, Physics Loss: 0.000561\n",
      "Epoch 115/2000, Total Loss: 4.979493, Data Loss: 4.974305, Physics Loss: 0.000519\n",
      "Epoch 116/2000, Total Loss: 4.978234, Data Loss: 4.973319, Physics Loss: 0.000492\n",
      "Epoch 117/2000, Total Loss: 4.976886, Data Loss: 4.972141, Physics Loss: 0.000474\n",
      "Epoch 118/2000, Total Loss: 4.975418, Data Loss: 4.970791, Physics Loss: 0.000463\n",
      "Epoch 119/2000, Total Loss: 4.973812, Data Loss: 4.969304, Physics Loss: 0.000451\n",
      "Epoch 120/2000, Total Loss: 4.972098, Data Loss: 4.967724, Physics Loss: 0.000437\n",
      "Epoch 121/2000, Total Loss: 4.970339, Data Loss: 4.966105, Physics Loss: 0.000423\n",
      "Epoch 122/2000, Total Loss: 4.968581, Data Loss: 4.964478, Physics Loss: 0.000410\n",
      "Epoch 123/2000, Total Loss: 4.966842, Data Loss: 4.962864, Physics Loss: 0.000398\n",
      "Epoch 124/2000, Total Loss: 4.965110, Data Loss: 4.961258, Physics Loss: 0.000385\n",
      "Epoch 125/2000, Total Loss: 4.963351, Data Loss: 4.959634, Physics Loss: 0.000372\n",
      "Epoch 126/2000, Total Loss: 4.961511, Data Loss: 4.957957, Physics Loss: 0.000355\n",
      "Epoch 127/2000, Total Loss: 4.959563, Data Loss: 4.956191, Physics Loss: 0.000337\n",
      "Epoch 128/2000, Total Loss: 4.957509, Data Loss: 4.954316, Physics Loss: 0.000319\n",
      "Epoch 129/2000, Total Loss: 4.955387, Data Loss: 4.952327, Physics Loss: 0.000306\n",
      "Epoch 130/2000, Total Loss: 4.953235, Data Loss: 4.950237, Physics Loss: 0.000300\n",
      "Epoch 131/2000, Total Loss: 4.951086, Data Loss: 4.948070, Physics Loss: 0.000302\n",
      "Epoch 132/2000, Total Loss: 4.948932, Data Loss: 4.945845, Physics Loss: 0.000309\n",
      "Epoch 133/2000, Total Loss: 4.946740, Data Loss: 4.943573, Physics Loss: 0.000317\n",
      "Epoch 134/2000, Total Loss: 4.944479, Data Loss: 4.941244, Physics Loss: 0.000323\n",
      "Epoch 135/2000, Total Loss: 4.942132, Data Loss: 4.938851, Physics Loss: 0.000328\n",
      "Epoch 136/2000, Total Loss: 4.939692, Data Loss: 4.936376, Physics Loss: 0.000332\n",
      "Epoch 137/2000, Total Loss: 4.937208, Data Loss: 4.933822, Physics Loss: 0.000339\n",
      "Epoch 138/2000, Total Loss: 4.934732, Data Loss: 4.931214, Physics Loss: 0.000352\n",
      "Epoch 139/2000, Total Loss: 4.932306, Data Loss: 4.928573, Physics Loss: 0.000373\n",
      "Epoch 140/2000, Total Loss: 4.929945, Data Loss: 4.925935, Physics Loss: 0.000401\n",
      "Epoch 141/2000, Total Loss: 4.927606, Data Loss: 4.923313, Physics Loss: 0.000429\n",
      "Epoch 142/2000, Total Loss: 4.925233, Data Loss: 4.920721, Physics Loss: 0.000451\n",
      "Epoch 143/2000, Total Loss: 4.922840, Data Loss: 4.918184, Physics Loss: 0.000466\n",
      "Epoch 144/2000, Total Loss: 4.920512, Data Loss: 4.915757, Physics Loss: 0.000476\n",
      "Epoch 145/2000, Total Loss: 4.918311, Data Loss: 4.913447, Physics Loss: 0.000486\n",
      "Epoch 146/2000, Total Loss: 4.916240, Data Loss: 4.911216, Physics Loss: 0.000502\n",
      "Epoch 147/2000, Total Loss: 4.914232, Data Loss: 4.909026, Physics Loss: 0.000521\n",
      "Epoch 148/2000, Total Loss: 4.912301, Data Loss: 4.906893, Physics Loss: 0.000541\n",
      "Epoch 149/2000, Total Loss: 4.910542, Data Loss: 4.904904, Physics Loss: 0.000564\n",
      "Epoch 150/2000, Total Loss: 4.908991, Data Loss: 4.903095, Physics Loss: 0.000590\n",
      "Epoch 151/2000, Total Loss: 4.907565, Data Loss: 4.901423, Physics Loss: 0.000614\n",
      "Epoch 152/2000, Total Loss: 4.906221, Data Loss: 4.899851, Physics Loss: 0.000637\n",
      "Epoch 153/2000, Total Loss: 4.905019, Data Loss: 4.898429, Physics Loss: 0.000659\n",
      "Epoch 154/2000, Total Loss: 4.903990, Data Loss: 4.897194, Physics Loss: 0.000680\n",
      "Epoch 155/2000, Total Loss: 4.903035, Data Loss: 4.896098, Physics Loss: 0.000694\n",
      "Epoch 156/2000, Total Loss: 4.902115, Data Loss: 4.895075, Physics Loss: 0.000704\n",
      "Epoch 157/2000, Total Loss: 4.901299, Data Loss: 4.894145, Physics Loss: 0.000715\n",
      "Epoch 158/2000, Total Loss: 4.900580, Data Loss: 4.893303, Physics Loss: 0.000728\n",
      "Epoch 159/2000, Total Loss: 4.899838, Data Loss: 4.892511, Physics Loss: 0.000733\n",
      "Epoch 160/2000, Total Loss: 4.899128, Data Loss: 4.891799, Physics Loss: 0.000733\n",
      "Epoch 161/2000, Total Loss: 4.898480, Data Loss: 4.891160, Physics Loss: 0.000732\n",
      "Epoch 162/2000, Total Loss: 4.897789, Data Loss: 4.890495, Physics Loss: 0.000729\n",
      "Epoch 163/2000, Total Loss: 4.897073, Data Loss: 4.889810, Physics Loss: 0.000726\n",
      "Epoch 164/2000, Total Loss: 4.896375, Data Loss: 4.889163, Physics Loss: 0.000721\n",
      "Epoch 165/2000, Total Loss: 4.895651, Data Loss: 4.888535, Physics Loss: 0.000712\n",
      "Epoch 166/2000, Total Loss: 4.894898, Data Loss: 4.887896, Physics Loss: 0.000700\n",
      "Epoch 167/2000, Total Loss: 4.894159, Data Loss: 4.887263, Physics Loss: 0.000690\n",
      "Epoch 168/2000, Total Loss: 4.893430, Data Loss: 4.886624, Physics Loss: 0.000681\n",
      "Epoch 169/2000, Total Loss: 4.892679, Data Loss: 4.885975, Physics Loss: 0.000670\n",
      "Epoch 170/2000, Total Loss: 4.891952, Data Loss: 4.885342, Physics Loss: 0.000661\n",
      "Epoch 171/2000, Total Loss: 4.891230, Data Loss: 4.884724, Physics Loss: 0.000651\n",
      "Epoch 172/2000, Total Loss: 4.890509, Data Loss: 4.884104, Physics Loss: 0.000640\n",
      "Epoch 173/2000, Total Loss: 4.889803, Data Loss: 4.883489, Physics Loss: 0.000631\n",
      "Epoch 174/2000, Total Loss: 4.889117, Data Loss: 4.882884, Physics Loss: 0.000623\n",
      "Epoch 175/2000, Total Loss: 4.888443, Data Loss: 4.882283, Physics Loss: 0.000616\n",
      "Epoch 176/2000, Total Loss: 4.887775, Data Loss: 4.881681, Physics Loss: 0.000609\n",
      "Epoch 177/2000, Total Loss: 4.887125, Data Loss: 4.881087, Physics Loss: 0.000604\n",
      "Epoch 178/2000, Total Loss: 4.886479, Data Loss: 4.880504, Physics Loss: 0.000598\n",
      "Epoch 179/2000, Total Loss: 4.885840, Data Loss: 4.879922, Physics Loss: 0.000592\n",
      "Epoch 180/2000, Total Loss: 4.885211, Data Loss: 4.879340, Physics Loss: 0.000587\n",
      "Epoch 181/2000, Total Loss: 4.884580, Data Loss: 4.878746, Physics Loss: 0.000583\n",
      "Epoch 182/2000, Total Loss: 4.883950, Data Loss: 4.878148, Physics Loss: 0.000580\n",
      "Epoch 183/2000, Total Loss: 4.883317, Data Loss: 4.877542, Physics Loss: 0.000577\n",
      "Epoch 184/2000, Total Loss: 4.882682, Data Loss: 4.876935, Physics Loss: 0.000575\n",
      "Epoch 185/2000, Total Loss: 4.882053, Data Loss: 4.876323, Physics Loss: 0.000573\n",
      "Epoch 186/2000, Total Loss: 4.881421, Data Loss: 4.875695, Physics Loss: 0.000573\n",
      "Epoch 187/2000, Total Loss: 4.880791, Data Loss: 4.875064, Physics Loss: 0.000573\n",
      "Epoch 188/2000, Total Loss: 4.880157, Data Loss: 4.874422, Physics Loss: 0.000573\n",
      "Epoch 189/2000, Total Loss: 4.879519, Data Loss: 4.873776, Physics Loss: 0.000574\n",
      "Epoch 190/2000, Total Loss: 4.878880, Data Loss: 4.873122, Physics Loss: 0.000576\n",
      "Epoch 191/2000, Total Loss: 4.878241, Data Loss: 4.872468, Physics Loss: 0.000577\n",
      "Epoch 192/2000, Total Loss: 4.877613, Data Loss: 4.871809, Physics Loss: 0.000580\n",
      "Epoch 193/2000, Total Loss: 4.876976, Data Loss: 4.871153, Physics Loss: 0.000582\n",
      "Epoch 194/2000, Total Loss: 4.876340, Data Loss: 4.870482, Physics Loss: 0.000586\n",
      "Epoch 195/2000, Total Loss: 4.875706, Data Loss: 4.869818, Physics Loss: 0.000589\n",
      "Epoch 196/2000, Total Loss: 4.875073, Data Loss: 4.869153, Physics Loss: 0.000592\n",
      "Epoch 197/2000, Total Loss: 4.874443, Data Loss: 4.868498, Physics Loss: 0.000595\n",
      "Epoch 198/2000, Total Loss: 4.873812, Data Loss: 4.867840, Physics Loss: 0.000597\n",
      "Epoch 199/2000, Total Loss: 4.873183, Data Loss: 4.867177, Physics Loss: 0.000601\n",
      "Epoch 200/2000, Total Loss: 4.872560, Data Loss: 4.866523, Physics Loss: 0.000604\n",
      "Epoch 201/2000, Total Loss: 4.871934, Data Loss: 4.865873, Physics Loss: 0.000606\n",
      "Epoch 202/2000, Total Loss: 4.871314, Data Loss: 4.865225, Physics Loss: 0.000609\n",
      "Epoch 203/2000, Total Loss: 4.870699, Data Loss: 4.864584, Physics Loss: 0.000611\n",
      "Epoch 204/2000, Total Loss: 4.870087, Data Loss: 4.863945, Physics Loss: 0.000614\n",
      "Epoch 205/2000, Total Loss: 4.869474, Data Loss: 4.863305, Physics Loss: 0.000617\n",
      "Epoch 206/2000, Total Loss: 4.868860, Data Loss: 4.862677, Physics Loss: 0.000618\n",
      "Epoch 207/2000, Total Loss: 4.868249, Data Loss: 4.862049, Physics Loss: 0.000620\n",
      "Epoch 208/2000, Total Loss: 4.867644, Data Loss: 4.861430, Physics Loss: 0.000621\n",
      "Epoch 209/2000, Total Loss: 4.867038, Data Loss: 4.860809, Physics Loss: 0.000623\n",
      "Epoch 210/2000, Total Loss: 4.866429, Data Loss: 4.860193, Physics Loss: 0.000624\n",
      "Epoch 211/2000, Total Loss: 4.865828, Data Loss: 4.859588, Physics Loss: 0.000624\n",
      "Epoch 212/2000, Total Loss: 4.865227, Data Loss: 4.858979, Physics Loss: 0.000625\n",
      "Epoch 213/2000, Total Loss: 4.864628, Data Loss: 4.858373, Physics Loss: 0.000626\n",
      "Epoch 214/2000, Total Loss: 4.864028, Data Loss: 4.857774, Physics Loss: 0.000625\n",
      "Epoch 215/2000, Total Loss: 4.863432, Data Loss: 4.857177, Physics Loss: 0.000625\n",
      "Epoch 216/2000, Total Loss: 4.862837, Data Loss: 4.856584, Physics Loss: 0.000625\n",
      "Epoch 217/2000, Total Loss: 4.862240, Data Loss: 4.855991, Physics Loss: 0.000625\n",
      "Epoch 218/2000, Total Loss: 4.861646, Data Loss: 4.855403, Physics Loss: 0.000624\n",
      "Epoch 219/2000, Total Loss: 4.861047, Data Loss: 4.854814, Physics Loss: 0.000623\n",
      "Epoch 220/2000, Total Loss: 4.860456, Data Loss: 4.854233, Physics Loss: 0.000622\n",
      "Epoch 221/2000, Total Loss: 4.859867, Data Loss: 4.853650, Physics Loss: 0.000622\n",
      "Epoch 222/2000, Total Loss: 4.859278, Data Loss: 4.853071, Physics Loss: 0.000621\n",
      "Epoch 223/2000, Total Loss: 4.858693, Data Loss: 4.852493, Physics Loss: 0.000620\n",
      "Epoch 224/2000, Total Loss: 4.858107, Data Loss: 4.851915, Physics Loss: 0.000619\n",
      "Epoch 225/2000, Total Loss: 4.857526, Data Loss: 4.851341, Physics Loss: 0.000618\n",
      "Epoch 226/2000, Total Loss: 4.856943, Data Loss: 4.850770, Physics Loss: 0.000617\n",
      "Epoch 227/2000, Total Loss: 4.856361, Data Loss: 4.850199, Physics Loss: 0.000616\n",
      "Epoch 228/2000, Total Loss: 4.855781, Data Loss: 4.849627, Physics Loss: 0.000615\n",
      "Epoch 229/2000, Total Loss: 4.855201, Data Loss: 4.849057, Physics Loss: 0.000614\n",
      "Epoch 230/2000, Total Loss: 4.854625, Data Loss: 4.848495, Physics Loss: 0.000613\n",
      "Epoch 231/2000, Total Loss: 4.854057, Data Loss: 4.847932, Physics Loss: 0.000612\n",
      "Epoch 232/2000, Total Loss: 4.853489, Data Loss: 4.847366, Physics Loss: 0.000612\n",
      "Epoch 233/2000, Total Loss: 4.852926, Data Loss: 4.846805, Physics Loss: 0.000612\n",
      "Epoch 234/2000, Total Loss: 4.852363, Data Loss: 4.846251, Physics Loss: 0.000611\n",
      "Epoch 235/2000, Total Loss: 4.851803, Data Loss: 4.845704, Physics Loss: 0.000610\n",
      "Epoch 236/2000, Total Loss: 4.851242, Data Loss: 4.845153, Physics Loss: 0.000609\n",
      "Epoch 237/2000, Total Loss: 4.850684, Data Loss: 4.844606, Physics Loss: 0.000608\n",
      "Epoch 238/2000, Total Loss: 4.850128, Data Loss: 4.844058, Physics Loss: 0.000607\n",
      "Epoch 239/2000, Total Loss: 4.849578, Data Loss: 4.843518, Physics Loss: 0.000606\n",
      "Epoch 240/2000, Total Loss: 4.849029, Data Loss: 4.842983, Physics Loss: 0.000605\n",
      "Epoch 241/2000, Total Loss: 4.848483, Data Loss: 4.842453, Physics Loss: 0.000603\n",
      "Epoch 242/2000, Total Loss: 4.847944, Data Loss: 4.841922, Physics Loss: 0.000602\n",
      "Epoch 243/2000, Total Loss: 4.847409, Data Loss: 4.841396, Physics Loss: 0.000601\n",
      "Epoch 244/2000, Total Loss: 4.846874, Data Loss: 4.840875, Physics Loss: 0.000600\n",
      "Epoch 245/2000, Total Loss: 4.846345, Data Loss: 4.840363, Physics Loss: 0.000598\n",
      "Epoch 246/2000, Total Loss: 4.845817, Data Loss: 4.839847, Physics Loss: 0.000597\n",
      "Epoch 247/2000, Total Loss: 4.845294, Data Loss: 4.839338, Physics Loss: 0.000596\n",
      "Epoch 248/2000, Total Loss: 4.844774, Data Loss: 4.838833, Physics Loss: 0.000594\n",
      "Epoch 249/2000, Total Loss: 4.844259, Data Loss: 4.838335, Physics Loss: 0.000592\n",
      "Epoch 250/2000, Total Loss: 4.843747, Data Loss: 4.837843, Physics Loss: 0.000590\n",
      "Epoch 251/2000, Total Loss: 4.843237, Data Loss: 4.837350, Physics Loss: 0.000589\n",
      "Epoch 252/2000, Total Loss: 4.842734, Data Loss: 4.836863, Physics Loss: 0.000587\n",
      "Epoch 253/2000, Total Loss: 4.842232, Data Loss: 4.836382, Physics Loss: 0.000585\n",
      "Epoch 254/2000, Total Loss: 4.841738, Data Loss: 4.835911, Physics Loss: 0.000583\n",
      "Epoch 255/2000, Total Loss: 4.841244, Data Loss: 4.835441, Physics Loss: 0.000580\n",
      "Epoch 256/2000, Total Loss: 4.840763, Data Loss: 4.834968, Physics Loss: 0.000579\n",
      "Epoch 257/2000, Total Loss: 4.840279, Data Loss: 4.834507, Physics Loss: 0.000577\n",
      "Epoch 258/2000, Total Loss: 4.839802, Data Loss: 4.834058, Physics Loss: 0.000574\n",
      "Epoch 259/2000, Total Loss: 4.839327, Data Loss: 4.833605, Physics Loss: 0.000572\n",
      "Epoch 260/2000, Total Loss: 4.838861, Data Loss: 4.833154, Physics Loss: 0.000571\n",
      "Epoch 261/2000, Total Loss: 4.838392, Data Loss: 4.832708, Physics Loss: 0.000568\n",
      "Epoch 262/2000, Total Loss: 4.837935, Data Loss: 4.832278, Physics Loss: 0.000566\n",
      "Epoch 263/2000, Total Loss: 4.837481, Data Loss: 4.831848, Physics Loss: 0.000563\n",
      "Epoch 264/2000, Total Loss: 4.837030, Data Loss: 4.831415, Physics Loss: 0.000562\n",
      "Epoch 265/2000, Total Loss: 4.836587, Data Loss: 4.830995, Physics Loss: 0.000559\n",
      "Epoch 266/2000, Total Loss: 4.836144, Data Loss: 4.830577, Physics Loss: 0.000557\n",
      "Epoch 267/2000, Total Loss: 4.835706, Data Loss: 4.830167, Physics Loss: 0.000554\n",
      "Epoch 268/2000, Total Loss: 4.835274, Data Loss: 4.829756, Physics Loss: 0.000552\n",
      "Epoch 269/2000, Total Loss: 4.834851, Data Loss: 4.829354, Physics Loss: 0.000550\n",
      "Epoch 270/2000, Total Loss: 4.834429, Data Loss: 4.828959, Physics Loss: 0.000547\n",
      "Epoch 271/2000, Total Loss: 4.834012, Data Loss: 4.828568, Physics Loss: 0.000544\n",
      "Epoch 272/2000, Total Loss: 4.833600, Data Loss: 4.828178, Physics Loss: 0.000542\n",
      "Epoch 273/2000, Total Loss: 4.833190, Data Loss: 4.827795, Physics Loss: 0.000540\n",
      "Epoch 274/2000, Total Loss: 4.832788, Data Loss: 4.827422, Physics Loss: 0.000537\n",
      "Epoch 275/2000, Total Loss: 4.832387, Data Loss: 4.827047, Physics Loss: 0.000534\n",
      "Epoch 276/2000, Total Loss: 4.831993, Data Loss: 4.826677, Physics Loss: 0.000532\n",
      "Epoch 277/2000, Total Loss: 4.831603, Data Loss: 4.826319, Physics Loss: 0.000528\n",
      "Epoch 278/2000, Total Loss: 4.831222, Data Loss: 4.825960, Physics Loss: 0.000526\n",
      "Epoch 279/2000, Total Loss: 4.830844, Data Loss: 4.825612, Physics Loss: 0.000523\n",
      "Epoch 280/2000, Total Loss: 4.830469, Data Loss: 4.825264, Physics Loss: 0.000520\n",
      "Epoch 281/2000, Total Loss: 4.830100, Data Loss: 4.824920, Physics Loss: 0.000518\n",
      "Epoch 282/2000, Total Loss: 4.829732, Data Loss: 4.824583, Physics Loss: 0.000515\n",
      "Epoch 283/2000, Total Loss: 4.829373, Data Loss: 4.824255, Physics Loss: 0.000512\n",
      "Epoch 284/2000, Total Loss: 4.829015, Data Loss: 4.823921, Physics Loss: 0.000509\n",
      "Epoch 285/2000, Total Loss: 4.828661, Data Loss: 4.823599, Physics Loss: 0.000506\n",
      "Epoch 286/2000, Total Loss: 4.828318, Data Loss: 4.823284, Physics Loss: 0.000503\n",
      "Epoch 287/2000, Total Loss: 4.827977, Data Loss: 4.822968, Physics Loss: 0.000501\n",
      "Epoch 288/2000, Total Loss: 4.827641, Data Loss: 4.822661, Physics Loss: 0.000498\n",
      "Epoch 289/2000, Total Loss: 4.827305, Data Loss: 4.822354, Physics Loss: 0.000495\n",
      "Epoch 290/2000, Total Loss: 4.826981, Data Loss: 4.822060, Physics Loss: 0.000492\n",
      "Epoch 291/2000, Total Loss: 4.826654, Data Loss: 4.821760, Physics Loss: 0.000489\n",
      "Epoch 292/2000, Total Loss: 4.826338, Data Loss: 4.821468, Physics Loss: 0.000487\n",
      "Epoch 293/2000, Total Loss: 4.826025, Data Loss: 4.821184, Physics Loss: 0.000484\n",
      "Epoch 294/2000, Total Loss: 4.825717, Data Loss: 4.820901, Physics Loss: 0.000482\n",
      "Epoch 295/2000, Total Loss: 4.825416, Data Loss: 4.820625, Physics Loss: 0.000479\n",
      "Epoch 296/2000, Total Loss: 4.825119, Data Loss: 4.820353, Physics Loss: 0.000477\n",
      "Epoch 297/2000, Total Loss: 4.824823, Data Loss: 4.820085, Physics Loss: 0.000474\n",
      "Epoch 298/2000, Total Loss: 4.824532, Data Loss: 4.819815, Physics Loss: 0.000472\n",
      "Epoch 299/2000, Total Loss: 4.824249, Data Loss: 4.819554, Physics Loss: 0.000470\n",
      "Epoch 300/2000, Total Loss: 4.823969, Data Loss: 4.819303, Physics Loss: 0.000467\n",
      "Epoch 301/2000, Total Loss: 4.823696, Data Loss: 4.819054, Physics Loss: 0.000464\n",
      "Epoch 302/2000, Total Loss: 4.823422, Data Loss: 4.818801, Physics Loss: 0.000462\n",
      "Epoch 303/2000, Total Loss: 4.823153, Data Loss: 4.818556, Physics Loss: 0.000460\n",
      "Epoch 304/2000, Total Loss: 4.822891, Data Loss: 4.818323, Physics Loss: 0.000457\n",
      "Epoch 305/2000, Total Loss: 4.822631, Data Loss: 4.818081, Physics Loss: 0.000455\n",
      "Epoch 306/2000, Total Loss: 4.822372, Data Loss: 4.817848, Physics Loss: 0.000452\n",
      "Epoch 307/2000, Total Loss: 4.822119, Data Loss: 4.817626, Physics Loss: 0.000449\n",
      "Epoch 308/2000, Total Loss: 4.821870, Data Loss: 4.817401, Physics Loss: 0.000447\n",
      "Epoch 309/2000, Total Loss: 4.821626, Data Loss: 4.817174, Physics Loss: 0.000445\n",
      "Epoch 310/2000, Total Loss: 4.821384, Data Loss: 4.816966, Physics Loss: 0.000442\n",
      "Epoch 311/2000, Total Loss: 4.821142, Data Loss: 4.816746, Physics Loss: 0.000440\n",
      "Epoch 312/2000, Total Loss: 4.820908, Data Loss: 4.816536, Physics Loss: 0.000437\n",
      "Epoch 313/2000, Total Loss: 4.820674, Data Loss: 4.816330, Physics Loss: 0.000434\n",
      "Epoch 314/2000, Total Loss: 4.820450, Data Loss: 4.816130, Physics Loss: 0.000432\n",
      "Epoch 315/2000, Total Loss: 4.820221, Data Loss: 4.815926, Physics Loss: 0.000430\n",
      "Epoch 316/2000, Total Loss: 4.820004, Data Loss: 4.815732, Physics Loss: 0.000427\n",
      "Epoch 317/2000, Total Loss: 4.819785, Data Loss: 4.815536, Physics Loss: 0.000425\n",
      "Epoch 318/2000, Total Loss: 4.819572, Data Loss: 4.815344, Physics Loss: 0.000423\n",
      "Epoch 319/2000, Total Loss: 4.819358, Data Loss: 4.815160, Physics Loss: 0.000420\n",
      "Epoch 320/2000, Total Loss: 4.819152, Data Loss: 4.814981, Physics Loss: 0.000417\n",
      "Epoch 321/2000, Total Loss: 4.818948, Data Loss: 4.814790, Physics Loss: 0.000416\n",
      "Epoch 322/2000, Total Loss: 4.818745, Data Loss: 4.814614, Physics Loss: 0.000413\n",
      "Epoch 323/2000, Total Loss: 4.818547, Data Loss: 4.814446, Physics Loss: 0.000410\n",
      "Epoch 324/2000, Total Loss: 4.818350, Data Loss: 4.814263, Physics Loss: 0.000409\n",
      "Epoch 325/2000, Total Loss: 4.818158, Data Loss: 4.814095, Physics Loss: 0.000406\n",
      "Epoch 326/2000, Total Loss: 4.817968, Data Loss: 4.813929, Physics Loss: 0.000404\n",
      "Epoch 327/2000, Total Loss: 4.817781, Data Loss: 4.813759, Physics Loss: 0.000402\n",
      "Epoch 328/2000, Total Loss: 4.817597, Data Loss: 4.813606, Physics Loss: 0.000399\n",
      "Epoch 329/2000, Total Loss: 4.817414, Data Loss: 4.813437, Physics Loss: 0.000398\n",
      "Epoch 330/2000, Total Loss: 4.817240, Data Loss: 4.813281, Physics Loss: 0.000396\n",
      "Epoch 331/2000, Total Loss: 4.817061, Data Loss: 4.813135, Physics Loss: 0.000393\n",
      "Epoch 332/2000, Total Loss: 4.816885, Data Loss: 4.812974, Physics Loss: 0.000391\n",
      "Epoch 333/2000, Total Loss: 4.816715, Data Loss: 4.812817, Physics Loss: 0.000390\n",
      "Epoch 334/2000, Total Loss: 4.816547, Data Loss: 4.812680, Physics Loss: 0.000387\n",
      "Epoch 335/2000, Total Loss: 4.816377, Data Loss: 4.812527, Physics Loss: 0.000385\n",
      "Epoch 336/2000, Total Loss: 4.816214, Data Loss: 4.812378, Physics Loss: 0.000384\n",
      "Epoch 337/2000, Total Loss: 4.816053, Data Loss: 4.812245, Physics Loss: 0.000381\n",
      "Epoch 338/2000, Total Loss: 4.815893, Data Loss: 4.812102, Physics Loss: 0.000379\n",
      "Epoch 339/2000, Total Loss: 4.815732, Data Loss: 4.811960, Physics Loss: 0.000377\n",
      "Epoch 340/2000, Total Loss: 4.815581, Data Loss: 4.811831, Physics Loss: 0.000375\n",
      "Epoch 341/2000, Total Loss: 4.815423, Data Loss: 4.811691, Physics Loss: 0.000373\n",
      "Epoch 342/2000, Total Loss: 4.815269, Data Loss: 4.811561, Physics Loss: 0.000371\n",
      "Epoch 343/2000, Total Loss: 4.815123, Data Loss: 4.811434, Physics Loss: 0.000369\n",
      "Epoch 344/2000, Total Loss: 4.814972, Data Loss: 4.811294, Physics Loss: 0.000368\n",
      "Epoch 345/2000, Total Loss: 4.814821, Data Loss: 4.811173, Physics Loss: 0.000365\n",
      "Epoch 346/2000, Total Loss: 4.814678, Data Loss: 4.811049, Physics Loss: 0.000363\n",
      "Epoch 347/2000, Total Loss: 4.814544, Data Loss: 4.810917, Physics Loss: 0.000363\n",
      "Epoch 348/2000, Total Loss: 4.814395, Data Loss: 4.810805, Physics Loss: 0.000359\n",
      "Epoch 349/2000, Total Loss: 4.814254, Data Loss: 4.810679, Physics Loss: 0.000357\n",
      "Epoch 350/2000, Total Loss: 4.814127, Data Loss: 4.810555, Physics Loss: 0.000357\n",
      "Epoch 351/2000, Total Loss: 4.813988, Data Loss: 4.810447, Physics Loss: 0.000354\n",
      "Epoch 352/2000, Total Loss: 4.813849, Data Loss: 4.810324, Physics Loss: 0.000353\n",
      "Epoch 353/2000, Total Loss: 4.813722, Data Loss: 4.810206, Physics Loss: 0.000352\n",
      "Epoch 354/2000, Total Loss: 4.813591, Data Loss: 4.810098, Physics Loss: 0.000349\n",
      "Epoch 355/2000, Total Loss: 4.813457, Data Loss: 4.809980, Physics Loss: 0.000348\n",
      "Epoch 356/2000, Total Loss: 4.813333, Data Loss: 4.809868, Physics Loss: 0.000346\n",
      "Epoch 357/2000, Total Loss: 4.813210, Data Loss: 4.809766, Physics Loss: 0.000344\n",
      "Epoch 358/2000, Total Loss: 4.813084, Data Loss: 4.809649, Physics Loss: 0.000343\n",
      "Epoch 359/2000, Total Loss: 4.812958, Data Loss: 4.809547, Physics Loss: 0.000341\n",
      "Epoch 360/2000, Total Loss: 4.812840, Data Loss: 4.809443, Physics Loss: 0.000340\n",
      "Epoch 361/2000, Total Loss: 4.812725, Data Loss: 4.809328, Physics Loss: 0.000340\n",
      "Epoch 362/2000, Total Loss: 4.812597, Data Loss: 4.809231, Physics Loss: 0.000337\n",
      "Epoch 363/2000, Total Loss: 4.812483, Data Loss: 4.809129, Physics Loss: 0.000335\n",
      "Epoch 364/2000, Total Loss: 4.812369, Data Loss: 4.809018, Physics Loss: 0.000335\n",
      "Epoch 365/2000, Total Loss: 4.812256, Data Loss: 4.808931, Physics Loss: 0.000333\n",
      "Epoch 366/2000, Total Loss: 4.812135, Data Loss: 4.808822, Physics Loss: 0.000331\n",
      "Epoch 367/2000, Total Loss: 4.812031, Data Loss: 4.808723, Physics Loss: 0.000331\n",
      "Epoch 368/2000, Total Loss: 4.811914, Data Loss: 4.808631, Physics Loss: 0.000328\n",
      "Epoch 369/2000, Total Loss: 4.811801, Data Loss: 4.808530, Physics Loss: 0.000327\n",
      "Epoch 370/2000, Total Loss: 4.811701, Data Loss: 4.808433, Physics Loss: 0.000327\n",
      "Epoch 371/2000, Total Loss: 4.811592, Data Loss: 4.808355, Physics Loss: 0.000324\n",
      "Epoch 372/2000, Total Loss: 4.811479, Data Loss: 4.808243, Physics Loss: 0.000324\n",
      "Epoch 373/2000, Total Loss: 4.811381, Data Loss: 4.808149, Physics Loss: 0.000323\n",
      "Epoch 374/2000, Total Loss: 4.811277, Data Loss: 4.808073, Physics Loss: 0.000320\n",
      "Epoch 375/2000, Total Loss: 4.811170, Data Loss: 4.807968, Physics Loss: 0.000320\n",
      "Epoch 376/2000, Total Loss: 4.811066, Data Loss: 4.807875, Physics Loss: 0.000319\n",
      "Epoch 377/2000, Total Loss: 4.810966, Data Loss: 4.807789, Physics Loss: 0.000318\n",
      "Epoch 378/2000, Total Loss: 4.810865, Data Loss: 4.807704, Physics Loss: 0.000316\n",
      "Epoch 379/2000, Total Loss: 4.810763, Data Loss: 4.807608, Physics Loss: 0.000316\n",
      "Epoch 380/2000, Total Loss: 4.810670, Data Loss: 4.807530, Physics Loss: 0.000314\n",
      "Epoch 381/2000, Total Loss: 4.810571, Data Loss: 4.807434, Physics Loss: 0.000314\n",
      "Epoch 382/2000, Total Loss: 4.810471, Data Loss: 4.807356, Physics Loss: 0.000311\n",
      "Epoch 383/2000, Total Loss: 4.810376, Data Loss: 4.807262, Physics Loss: 0.000311\n",
      "Epoch 384/2000, Total Loss: 4.810280, Data Loss: 4.807179, Physics Loss: 0.000310\n",
      "Epoch 385/2000, Total Loss: 4.810187, Data Loss: 4.807104, Physics Loss: 0.000308\n",
      "Epoch 386/2000, Total Loss: 4.810091, Data Loss: 4.807011, Physics Loss: 0.000308\n",
      "Epoch 387/2000, Total Loss: 4.809999, Data Loss: 4.806930, Physics Loss: 0.000307\n",
      "Epoch 388/2000, Total Loss: 4.809905, Data Loss: 4.806853, Physics Loss: 0.000305\n",
      "Epoch 389/2000, Total Loss: 4.809815, Data Loss: 4.806767, Physics Loss: 0.000305\n",
      "Epoch 390/2000, Total Loss: 4.809725, Data Loss: 4.806685, Physics Loss: 0.000304\n",
      "Epoch 391/2000, Total Loss: 4.809642, Data Loss: 4.806611, Physics Loss: 0.000303\n",
      "Epoch 392/2000, Total Loss: 4.809555, Data Loss: 4.806530, Physics Loss: 0.000303\n",
      "Epoch 393/2000, Total Loss: 4.809466, Data Loss: 4.806449, Physics Loss: 0.000302\n",
      "Epoch 394/2000, Total Loss: 4.809381, Data Loss: 4.806376, Physics Loss: 0.000301\n",
      "Epoch 395/2000, Total Loss: 4.809297, Data Loss: 4.806292, Physics Loss: 0.000301\n",
      "Epoch 396/2000, Total Loss: 4.809214, Data Loss: 4.806222, Physics Loss: 0.000299\n",
      "Epoch 397/2000, Total Loss: 4.809127, Data Loss: 4.806141, Physics Loss: 0.000299\n",
      "Epoch 398/2000, Total Loss: 4.809044, Data Loss: 4.806065, Physics Loss: 0.000298\n",
      "Epoch 399/2000, Total Loss: 4.808965, Data Loss: 4.805999, Physics Loss: 0.000297\n",
      "Epoch 400/2000, Total Loss: 4.808885, Data Loss: 4.805912, Physics Loss: 0.000297\n",
      "Epoch 401/2000, Total Loss: 4.808801, Data Loss: 4.805850, Physics Loss: 0.000295\n",
      "Epoch 402/2000, Total Loss: 4.808717, Data Loss: 4.805769, Physics Loss: 0.000295\n",
      "Epoch 403/2000, Total Loss: 4.808640, Data Loss: 4.805692, Physics Loss: 0.000295\n",
      "Epoch 404/2000, Total Loss: 4.808565, Data Loss: 4.805627, Physics Loss: 0.000294\n",
      "Epoch 405/2000, Total Loss: 4.808484, Data Loss: 4.805554, Physics Loss: 0.000293\n",
      "Epoch 406/2000, Total Loss: 4.808404, Data Loss: 4.805477, Physics Loss: 0.000293\n",
      "Epoch 407/2000, Total Loss: 4.808334, Data Loss: 4.805421, Physics Loss: 0.000291\n",
      "Epoch 408/2000, Total Loss: 4.808256, Data Loss: 4.805336, Physics Loss: 0.000292\n",
      "Epoch 409/2000, Total Loss: 4.808170, Data Loss: 4.805273, Physics Loss: 0.000290\n",
      "Epoch 410/2000, Total Loss: 4.808095, Data Loss: 4.805200, Physics Loss: 0.000290\n",
      "Epoch 411/2000, Total Loss: 4.808029, Data Loss: 4.805127, Physics Loss: 0.000290\n",
      "Epoch 412/2000, Total Loss: 4.807952, Data Loss: 4.805071, Physics Loss: 0.000288\n",
      "Epoch 413/2000, Total Loss: 4.807873, Data Loss: 4.804990, Physics Loss: 0.000288\n",
      "Epoch 414/2000, Total Loss: 4.807804, Data Loss: 4.804920, Physics Loss: 0.000288\n",
      "Epoch 415/2000, Total Loss: 4.807735, Data Loss: 4.804863, Physics Loss: 0.000287\n",
      "Epoch 416/2000, Total Loss: 4.807662, Data Loss: 4.804790, Physics Loss: 0.000287\n",
      "Epoch 417/2000, Total Loss: 4.807591, Data Loss: 4.804726, Physics Loss: 0.000287\n",
      "Epoch 418/2000, Total Loss: 4.807519, Data Loss: 4.804656, Physics Loss: 0.000286\n",
      "Epoch 419/2000, Total Loss: 4.807452, Data Loss: 4.804590, Physics Loss: 0.000286\n",
      "Epoch 420/2000, Total Loss: 4.807379, Data Loss: 4.804532, Physics Loss: 0.000285\n",
      "Epoch 421/2000, Total Loss: 4.807314, Data Loss: 4.804459, Physics Loss: 0.000286\n",
      "Epoch 422/2000, Total Loss: 4.807241, Data Loss: 4.804396, Physics Loss: 0.000285\n",
      "Epoch 423/2000, Total Loss: 4.807171, Data Loss: 4.804337, Physics Loss: 0.000283\n",
      "Epoch 424/2000, Total Loss: 4.807107, Data Loss: 4.804267, Physics Loss: 0.000284\n",
      "Epoch 425/2000, Total Loss: 4.807045, Data Loss: 4.804211, Physics Loss: 0.000283\n",
      "Epoch 426/2000, Total Loss: 4.806980, Data Loss: 4.804146, Physics Loss: 0.000283\n",
      "Epoch 427/2000, Total Loss: 4.806908, Data Loss: 4.804085, Physics Loss: 0.000282\n",
      "Epoch 428/2000, Total Loss: 4.806843, Data Loss: 4.804018, Physics Loss: 0.000282\n",
      "Epoch 429/2000, Total Loss: 4.806782, Data Loss: 4.803958, Physics Loss: 0.000282\n",
      "Epoch 430/2000, Total Loss: 4.806720, Data Loss: 4.803905, Physics Loss: 0.000282\n",
      "Epoch 431/2000, Total Loss: 4.806651, Data Loss: 4.803832, Physics Loss: 0.000282\n",
      "Epoch 432/2000, Total Loss: 4.806588, Data Loss: 4.803782, Physics Loss: 0.000281\n",
      "Epoch 433/2000, Total Loss: 4.806529, Data Loss: 4.803720, Physics Loss: 0.000281\n",
      "Epoch 434/2000, Total Loss: 4.806465, Data Loss: 4.803658, Physics Loss: 0.000281\n",
      "Epoch 435/2000, Total Loss: 4.806397, Data Loss: 4.803601, Physics Loss: 0.000280\n",
      "Epoch 436/2000, Total Loss: 4.806338, Data Loss: 4.803541, Physics Loss: 0.000280\n",
      "Epoch 437/2000, Total Loss: 4.806267, Data Loss: 4.803477, Physics Loss: 0.000279\n",
      "Epoch 438/2000, Total Loss: 4.806208, Data Loss: 4.803423, Physics Loss: 0.000278\n",
      "Epoch 439/2000, Total Loss: 4.806147, Data Loss: 4.803360, Physics Loss: 0.000279\n",
      "Epoch 440/2000, Total Loss: 4.806082, Data Loss: 4.803308, Physics Loss: 0.000277\n",
      "Epoch 441/2000, Total Loss: 4.806023, Data Loss: 4.803252, Physics Loss: 0.000277\n",
      "Epoch 442/2000, Total Loss: 4.805971, Data Loss: 4.803190, Physics Loss: 0.000278\n",
      "Epoch 443/2000, Total Loss: 4.805905, Data Loss: 4.803141, Physics Loss: 0.000276\n",
      "Epoch 444/2000, Total Loss: 4.805841, Data Loss: 4.803079, Physics Loss: 0.000276\n",
      "Epoch 445/2000, Total Loss: 4.805786, Data Loss: 4.803019, Physics Loss: 0.000277\n",
      "Epoch 446/2000, Total Loss: 4.805722, Data Loss: 4.802969, Physics Loss: 0.000275\n",
      "Epoch 447/2000, Total Loss: 4.805662, Data Loss: 4.802907, Physics Loss: 0.000275\n",
      "Epoch 448/2000, Total Loss: 4.805606, Data Loss: 4.802852, Physics Loss: 0.000275\n",
      "Epoch 449/2000, Total Loss: 4.805546, Data Loss: 4.802797, Physics Loss: 0.000275\n",
      "Epoch 450/2000, Total Loss: 4.805489, Data Loss: 4.802739, Physics Loss: 0.000275\n",
      "Epoch 451/2000, Total Loss: 4.805434, Data Loss: 4.802690, Physics Loss: 0.000274\n",
      "Epoch 452/2000, Total Loss: 4.805377, Data Loss: 4.802628, Physics Loss: 0.000275\n",
      "Epoch 453/2000, Total Loss: 4.805324, Data Loss: 4.802581, Physics Loss: 0.000274\n",
      "Epoch 454/2000, Total Loss: 4.805268, Data Loss: 4.802521, Physics Loss: 0.000275\n",
      "Epoch 455/2000, Total Loss: 4.805209, Data Loss: 4.802472, Physics Loss: 0.000274\n",
      "Epoch 456/2000, Total Loss: 4.805150, Data Loss: 4.802414, Physics Loss: 0.000274\n",
      "Epoch 457/2000, Total Loss: 4.805095, Data Loss: 4.802360, Physics Loss: 0.000273\n",
      "Epoch 458/2000, Total Loss: 4.805043, Data Loss: 4.802316, Physics Loss: 0.000273\n",
      "Epoch 459/2000, Total Loss: 4.804994, Data Loss: 4.802254, Physics Loss: 0.000274\n",
      "Epoch 460/2000, Total Loss: 4.804932, Data Loss: 4.802212, Physics Loss: 0.000272\n",
      "Epoch 461/2000, Total Loss: 4.804870, Data Loss: 4.802145, Physics Loss: 0.000273\n",
      "Epoch 462/2000, Total Loss: 4.804818, Data Loss: 4.802095, Physics Loss: 0.000272\n",
      "Epoch 463/2000, Total Loss: 4.804770, Data Loss: 4.802048, Physics Loss: 0.000272\n",
      "Epoch 464/2000, Total Loss: 4.804719, Data Loss: 4.801997, Physics Loss: 0.000272\n",
      "Epoch 465/2000, Total Loss: 4.804670, Data Loss: 4.801954, Physics Loss: 0.000272\n",
      "Epoch 466/2000, Total Loss: 4.804617, Data Loss: 4.801889, Physics Loss: 0.000273\n",
      "Epoch 467/2000, Total Loss: 4.804562, Data Loss: 4.801852, Physics Loss: 0.000271\n",
      "Epoch 468/2000, Total Loss: 4.804506, Data Loss: 4.801792, Physics Loss: 0.000271\n",
      "Epoch 469/2000, Total Loss: 4.804456, Data Loss: 4.801739, Physics Loss: 0.000272\n",
      "Epoch 470/2000, Total Loss: 4.804403, Data Loss: 4.801701, Physics Loss: 0.000270\n",
      "Epoch 471/2000, Total Loss: 4.804366, Data Loss: 4.801645, Physics Loss: 0.000272\n",
      "Epoch 472/2000, Total Loss: 4.804317, Data Loss: 4.801612, Physics Loss: 0.000270\n",
      "Epoch 473/2000, Total Loss: 4.804254, Data Loss: 4.801541, Physics Loss: 0.000271\n",
      "Epoch 474/2000, Total Loss: 4.804198, Data Loss: 4.801500, Physics Loss: 0.000270\n",
      "Epoch 475/2000, Total Loss: 4.804141, Data Loss: 4.801445, Physics Loss: 0.000270\n",
      "Epoch 476/2000, Total Loss: 4.804099, Data Loss: 4.801392, Physics Loss: 0.000271\n",
      "Epoch 477/2000, Total Loss: 4.804056, Data Loss: 4.801362, Physics Loss: 0.000269\n",
      "Epoch 478/2000, Total Loss: 4.804004, Data Loss: 4.801300, Physics Loss: 0.000270\n",
      "Epoch 479/2000, Total Loss: 4.803943, Data Loss: 4.801256, Physics Loss: 0.000269\n",
      "Epoch 480/2000, Total Loss: 4.803888, Data Loss: 4.801200, Physics Loss: 0.000269\n",
      "Epoch 481/2000, Total Loss: 4.803844, Data Loss: 4.801155, Physics Loss: 0.000269\n",
      "Epoch 482/2000, Total Loss: 4.803795, Data Loss: 4.801118, Physics Loss: 0.000268\n",
      "Epoch 483/2000, Total Loss: 4.803746, Data Loss: 4.801060, Physics Loss: 0.000269\n",
      "Epoch 484/2000, Total Loss: 4.803689, Data Loss: 4.801014, Physics Loss: 0.000267\n",
      "Epoch 485/2000, Total Loss: 4.803642, Data Loss: 4.800971, Physics Loss: 0.000267\n",
      "Epoch 486/2000, Total Loss: 4.803592, Data Loss: 4.800920, Physics Loss: 0.000267\n",
      "Epoch 487/2000, Total Loss: 4.803545, Data Loss: 4.800879, Physics Loss: 0.000266\n",
      "Epoch 488/2000, Total Loss: 4.803498, Data Loss: 4.800831, Physics Loss: 0.000267\n",
      "Epoch 489/2000, Total Loss: 4.803452, Data Loss: 4.800786, Physics Loss: 0.000267\n",
      "Epoch 490/2000, Total Loss: 4.803403, Data Loss: 4.800739, Physics Loss: 0.000266\n",
      "Epoch 491/2000, Total Loss: 4.803356, Data Loss: 4.800697, Physics Loss: 0.000266\n",
      "Epoch 492/2000, Total Loss: 4.803319, Data Loss: 4.800648, Physics Loss: 0.000267\n",
      "Epoch 493/2000, Total Loss: 4.803277, Data Loss: 4.800622, Physics Loss: 0.000266\n",
      "Epoch 494/2000, Total Loss: 4.803236, Data Loss: 4.800560, Physics Loss: 0.000268\n",
      "Epoch 495/2000, Total Loss: 4.803188, Data Loss: 4.800532, Physics Loss: 0.000266\n",
      "Epoch 496/2000, Total Loss: 4.803146, Data Loss: 4.800475, Physics Loss: 0.000267\n",
      "Epoch 497/2000, Total Loss: 4.803090, Data Loss: 4.800436, Physics Loss: 0.000265\n",
      "Epoch 498/2000, Total Loss: 4.803040, Data Loss: 4.800379, Physics Loss: 0.000266\n",
      "Epoch 499/2000, Total Loss: 4.803000, Data Loss: 4.800342, Physics Loss: 0.000266\n",
      "Epoch 500/2000, Total Loss: 4.802969, Data Loss: 4.800313, Physics Loss: 0.000266\n",
      "Epoch 501/2000, Total Loss: 4.802932, Data Loss: 4.800258, Physics Loss: 0.000267\n",
      "Epoch 502/2000, Total Loss: 4.802896, Data Loss: 4.800248, Physics Loss: 0.000265\n",
      "Epoch 503/2000, Total Loss: 4.802847, Data Loss: 4.800173, Physics Loss: 0.000267\n",
      "Epoch 504/2000, Total Loss: 4.802779, Data Loss: 4.800134, Physics Loss: 0.000265\n",
      "Epoch 505/2000, Total Loss: 4.802732, Data Loss: 4.800090, Physics Loss: 0.000264\n",
      "Epoch 506/2000, Total Loss: 4.802708, Data Loss: 4.800045, Physics Loss: 0.000266\n",
      "Epoch 507/2000, Total Loss: 4.802666, Data Loss: 4.800027, Physics Loss: 0.000264\n",
      "Epoch 508/2000, Total Loss: 4.802612, Data Loss: 4.799956, Physics Loss: 0.000266\n",
      "Epoch 509/2000, Total Loss: 4.802563, Data Loss: 4.799927, Physics Loss: 0.000264\n",
      "Epoch 510/2000, Total Loss: 4.802519, Data Loss: 4.799878, Physics Loss: 0.000264\n",
      "Epoch 511/2000, Total Loss: 4.802479, Data Loss: 4.799836, Physics Loss: 0.000264\n",
      "Epoch 512/2000, Total Loss: 4.802433, Data Loss: 4.799790, Physics Loss: 0.000264\n",
      "Epoch 513/2000, Total Loss: 4.802396, Data Loss: 4.799759, Physics Loss: 0.000264\n",
      "Epoch 514/2000, Total Loss: 4.802359, Data Loss: 4.799715, Physics Loss: 0.000264\n",
      "Epoch 515/2000, Total Loss: 4.802313, Data Loss: 4.799665, Physics Loss: 0.000265\n",
      "Epoch 516/2000, Total Loss: 4.802280, Data Loss: 4.799645, Physics Loss: 0.000263\n",
      "Epoch 517/2000, Total Loss: 4.802242, Data Loss: 4.799591, Physics Loss: 0.000265\n",
      "Epoch 518/2000, Total Loss: 4.802190, Data Loss: 4.799557, Physics Loss: 0.000263\n",
      "Epoch 519/2000, Total Loss: 4.802138, Data Loss: 4.799511, Physics Loss: 0.000263\n",
      "Epoch 520/2000, Total Loss: 4.802112, Data Loss: 4.799470, Physics Loss: 0.000264\n",
      "Epoch 521/2000, Total Loss: 4.802093, Data Loss: 4.799466, Physics Loss: 0.000263\n",
      "Epoch 522/2000, Total Loss: 4.802067, Data Loss: 4.799406, Physics Loss: 0.000266\n",
      "Epoch 523/2000, Total Loss: 4.802013, Data Loss: 4.799386, Physics Loss: 0.000263\n",
      "Epoch 524/2000, Total Loss: 4.801957, Data Loss: 4.799317, Physics Loss: 0.000264\n",
      "Epoch 525/2000, Total Loss: 4.801906, Data Loss: 4.799283, Physics Loss: 0.000262\n",
      "Epoch 526/2000, Total Loss: 4.801862, Data Loss: 4.799244, Physics Loss: 0.000262\n",
      "Epoch 527/2000, Total Loss: 4.801824, Data Loss: 4.799196, Physics Loss: 0.000263\n",
      "Epoch 528/2000, Total Loss: 4.801789, Data Loss: 4.799175, Physics Loss: 0.000261\n",
      "Epoch 529/2000, Total Loss: 4.801746, Data Loss: 4.799125, Physics Loss: 0.000262\n",
      "Epoch 530/2000, Total Loss: 4.801705, Data Loss: 4.799095, Physics Loss: 0.000261\n",
      "Epoch 531/2000, Total Loss: 4.801661, Data Loss: 4.799049, Physics Loss: 0.000261\n",
      "Epoch 532/2000, Total Loss: 4.801622, Data Loss: 4.799014, Physics Loss: 0.000261\n",
      "Epoch 533/2000, Total Loss: 4.801590, Data Loss: 4.798984, Physics Loss: 0.000261\n",
      "Epoch 534/2000, Total Loss: 4.801556, Data Loss: 4.798938, Physics Loss: 0.000262\n",
      "Epoch 535/2000, Total Loss: 4.801523, Data Loss: 4.798914, Physics Loss: 0.000261\n",
      "Epoch 536/2000, Total Loss: 4.801478, Data Loss: 4.798866, Physics Loss: 0.000261\n",
      "Epoch 537/2000, Total Loss: 4.801443, Data Loss: 4.798831, Physics Loss: 0.000261\n",
      "Epoch 538/2000, Total Loss: 4.801404, Data Loss: 4.798798, Physics Loss: 0.000261\n",
      "Epoch 539/2000, Total Loss: 4.801370, Data Loss: 4.798755, Physics Loss: 0.000262\n",
      "Epoch 540/2000, Total Loss: 4.801341, Data Loss: 4.798734, Physics Loss: 0.000261\n",
      "Epoch 541/2000, Total Loss: 4.801312, Data Loss: 4.798687, Physics Loss: 0.000263\n",
      "Epoch 542/2000, Total Loss: 4.801272, Data Loss: 4.798674, Physics Loss: 0.000260\n",
      "Epoch 543/2000, Total Loss: 4.801239, Data Loss: 4.798619, Physics Loss: 0.000262\n",
      "Epoch 544/2000, Total Loss: 4.801198, Data Loss: 4.798598, Physics Loss: 0.000260\n",
      "Epoch 545/2000, Total Loss: 4.801162, Data Loss: 4.798546, Physics Loss: 0.000262\n",
      "Epoch 546/2000, Total Loss: 4.801122, Data Loss: 4.798521, Physics Loss: 0.000260\n",
      "Epoch 547/2000, Total Loss: 4.801088, Data Loss: 4.798476, Physics Loss: 0.000261\n",
      "Epoch 548/2000, Total Loss: 4.801051, Data Loss: 4.798439, Physics Loss: 0.000261\n",
      "Epoch 549/2000, Total Loss: 4.801023, Data Loss: 4.798414, Physics Loss: 0.000261\n",
      "Epoch 550/2000, Total Loss: 4.800995, Data Loss: 4.798375, Physics Loss: 0.000262\n",
      "Epoch 551/2000, Total Loss: 4.800961, Data Loss: 4.798348, Physics Loss: 0.000261\n",
      "Epoch 552/2000, Total Loss: 4.800932, Data Loss: 4.798312, Physics Loss: 0.000262\n",
      "Epoch 553/2000, Total Loss: 4.800901, Data Loss: 4.798287, Physics Loss: 0.000261\n",
      "Epoch 554/2000, Total Loss: 4.800875, Data Loss: 4.798241, Physics Loss: 0.000263\n",
      "Epoch 555/2000, Total Loss: 4.800855, Data Loss: 4.798240, Physics Loss: 0.000261\n",
      "Epoch 556/2000, Total Loss: 4.800833, Data Loss: 4.798188, Physics Loss: 0.000265\n",
      "Epoch 557/2000, Total Loss: 4.800802, Data Loss: 4.798182, Physics Loss: 0.000262\n",
      "Epoch 558/2000, Total Loss: 4.800773, Data Loss: 4.798125, Physics Loss: 0.000265\n",
      "Epoch 559/2000, Total Loss: 4.800740, Data Loss: 4.798125, Physics Loss: 0.000261\n",
      "Epoch 560/2000, Total Loss: 4.800697, Data Loss: 4.798056, Physics Loss: 0.000264\n",
      "Epoch 561/2000, Total Loss: 4.800659, Data Loss: 4.798043, Physics Loss: 0.000262\n",
      "Epoch 562/2000, Total Loss: 4.800621, Data Loss: 4.797994, Physics Loss: 0.000263\n",
      "Epoch 563/2000, Total Loss: 4.800581, Data Loss: 4.797969, Physics Loss: 0.000261\n",
      "Epoch 564/2000, Total Loss: 4.800546, Data Loss: 4.797919, Physics Loss: 0.000263\n",
      "Epoch 565/2000, Total Loss: 4.800511, Data Loss: 4.797895, Physics Loss: 0.000262\n",
      "Epoch 566/2000, Total Loss: 4.800474, Data Loss: 4.797862, Physics Loss: 0.000261\n",
      "Epoch 567/2000, Total Loss: 4.800447, Data Loss: 4.797825, Physics Loss: 0.000262\n",
      "Epoch 568/2000, Total Loss: 4.800416, Data Loss: 4.797802, Physics Loss: 0.000261\n",
      "Epoch 569/2000, Total Loss: 4.800394, Data Loss: 4.797776, Physics Loss: 0.000262\n",
      "Epoch 570/2000, Total Loss: 4.800369, Data Loss: 4.797755, Physics Loss: 0.000261\n",
      "Epoch 571/2000, Total Loss: 4.800339, Data Loss: 4.797709, Physics Loss: 0.000263\n",
      "Epoch 572/2000, Total Loss: 4.800301, Data Loss: 4.797696, Physics Loss: 0.000260\n",
      "Epoch 573/2000, Total Loss: 4.800269, Data Loss: 4.797647, Physics Loss: 0.000262\n",
      "Epoch 574/2000, Total Loss: 4.800240, Data Loss: 4.797628, Physics Loss: 0.000261\n",
      "Epoch 575/2000, Total Loss: 4.800207, Data Loss: 4.797588, Physics Loss: 0.000262\n",
      "Epoch 576/2000, Total Loss: 4.800174, Data Loss: 4.797567, Physics Loss: 0.000261\n",
      "Epoch 577/2000, Total Loss: 4.800156, Data Loss: 4.797532, Physics Loss: 0.000262\n",
      "Epoch 578/2000, Total Loss: 4.800135, Data Loss: 4.797524, Physics Loss: 0.000261\n",
      "Epoch 579/2000, Total Loss: 4.800127, Data Loss: 4.797491, Physics Loss: 0.000264\n",
      "Epoch 580/2000, Total Loss: 4.800125, Data Loss: 4.797502, Physics Loss: 0.000262\n",
      "Epoch 581/2000, Total Loss: 4.800126, Data Loss: 4.797455, Physics Loss: 0.000267\n",
      "Epoch 582/2000, Total Loss: 4.800139, Data Loss: 4.797498, Physics Loss: 0.000264\n",
      "Epoch 583/2000, Total Loss: 4.800163, Data Loss: 4.797444, Physics Loss: 0.000272\n",
      "Epoch 584/2000, Total Loss: 4.800203, Data Loss: 4.797523, Physics Loss: 0.000268\n",
      "Epoch 585/2000, Total Loss: 4.800280, Data Loss: 4.797486, Physics Loss: 0.000279\n",
      "Epoch 586/2000, Total Loss: 4.800361, Data Loss: 4.797607, Physics Loss: 0.000275\n",
      "Epoch 587/2000, Total Loss: 4.800451, Data Loss: 4.797551, Physics Loss: 0.000290\n",
      "Epoch 588/2000, Total Loss: 4.800546, Data Loss: 4.797708, Physics Loss: 0.000284\n",
      "Epoch 589/2000, Total Loss: 4.800624, Data Loss: 4.797627, Physics Loss: 0.000300\n",
      "Epoch 590/2000, Total Loss: 4.800740, Data Loss: 4.797801, Physics Loss: 0.000294\n",
      "Epoch 591/2000, Total Loss: 4.800899, Data Loss: 4.797754, Physics Loss: 0.000314\n",
      "Epoch 592/2000, Total Loss: 4.801152, Data Loss: 4.798058, Physics Loss: 0.000309\n",
      "Epoch 593/2000, Total Loss: 4.801322, Data Loss: 4.797981, Physics Loss: 0.000334\n",
      "Epoch 594/2000, Total Loss: 4.801489, Data Loss: 4.798265, Physics Loss: 0.000322\n",
      "Epoch 595/2000, Total Loss: 4.801423, Data Loss: 4.798038, Physics Loss: 0.000338\n",
      "Epoch 596/2000, Total Loss: 4.801346, Data Loss: 4.798169, Physics Loss: 0.000318\n",
      "Epoch 597/2000, Total Loss: 4.801077, Data Loss: 4.797861, Physics Loss: 0.000322\n",
      "Epoch 598/2000, Total Loss: 4.800742, Data Loss: 4.797830, Physics Loss: 0.000291\n",
      "Epoch 599/2000, Total Loss: 4.800297, Data Loss: 4.797450, Physics Loss: 0.000285\n",
      "Epoch 600/2000, Total Loss: 4.799899, Data Loss: 4.797318, Physics Loss: 0.000258\n",
      "Epoch 601/2000, Total Loss: 4.799611, Data Loss: 4.797093, Physics Loss: 0.000252\n",
      "Epoch 602/2000, Total Loss: 4.799461, Data Loss: 4.797019, Physics Loss: 0.000244\n",
      "Epoch 603/2000, Total Loss: 4.799450, Data Loss: 4.797011, Physics Loss: 0.000244\n",
      "Epoch 604/2000, Total Loss: 4.799512, Data Loss: 4.797008, Physics Loss: 0.000250\n",
      "Epoch 605/2000, Total Loss: 4.799578, Data Loss: 4.797079, Physics Loss: 0.000250\n",
      "Epoch 606/2000, Total Loss: 4.799594, Data Loss: 4.797013, Physics Loss: 0.000258\n",
      "Epoch 607/2000, Total Loss: 4.799548, Data Loss: 4.797033, Physics Loss: 0.000251\n",
      "Epoch 608/2000, Total Loss: 4.799463, Data Loss: 4.796919, Physics Loss: 0.000254\n",
      "Epoch 609/2000, Total Loss: 4.799345, Data Loss: 4.796873, Physics Loss: 0.000247\n",
      "Epoch 610/2000, Total Loss: 4.799247, Data Loss: 4.796778, Physics Loss: 0.000247\n",
      "Epoch 611/2000, Total Loss: 4.799183, Data Loss: 4.796744, Physics Loss: 0.000244\n",
      "Epoch 612/2000, Total Loss: 4.799154, Data Loss: 4.796705, Physics Loss: 0.000245\n",
      "Epoch 613/2000, Total Loss: 4.799136, Data Loss: 4.796677, Physics Loss: 0.000246\n",
      "Epoch 614/2000, Total Loss: 4.799130, Data Loss: 4.796678, Physics Loss: 0.000245\n",
      "Epoch 615/2000, Total Loss: 4.799144, Data Loss: 4.796636, Physics Loss: 0.000251\n",
      "Epoch 616/2000, Total Loss: 4.799122, Data Loss: 4.796652, Physics Loss: 0.000247\n",
      "Epoch 617/2000, Total Loss: 4.799117, Data Loss: 4.796588, Physics Loss: 0.000253\n",
      "Epoch 618/2000, Total Loss: 4.799099, Data Loss: 4.796608, Physics Loss: 0.000249\n",
      "Epoch 619/2000, Total Loss: 4.799096, Data Loss: 4.796547, Physics Loss: 0.000255\n",
      "Epoch 620/2000, Total Loss: 4.799067, Data Loss: 4.796573, Physics Loss: 0.000249\n",
      "Epoch 621/2000, Total Loss: 4.799021, Data Loss: 4.796483, Physics Loss: 0.000254\n",
      "Epoch 622/2000, Total Loss: 4.798954, Data Loss: 4.796479, Physics Loss: 0.000248\n",
      "Epoch 623/2000, Total Loss: 4.798898, Data Loss: 4.796399, Physics Loss: 0.000250\n",
      "Epoch 624/2000, Total Loss: 4.798835, Data Loss: 4.796385, Physics Loss: 0.000245\n",
      "Epoch 625/2000, Total Loss: 4.798787, Data Loss: 4.796323, Physics Loss: 0.000246\n",
      "Epoch 626/2000, Total Loss: 4.798745, Data Loss: 4.796305, Physics Loss: 0.000244\n",
      "Epoch 627/2000, Total Loss: 4.798712, Data Loss: 4.796272, Physics Loss: 0.000244\n",
      "Epoch 628/2000, Total Loss: 4.798685, Data Loss: 4.796241, Physics Loss: 0.000244\n",
      "Epoch 629/2000, Total Loss: 4.798654, Data Loss: 4.796224, Physics Loss: 0.000243\n",
      "Epoch 630/2000, Total Loss: 4.798647, Data Loss: 4.796198, Physics Loss: 0.000245\n",
      "Epoch 631/2000, Total Loss: 4.798648, Data Loss: 4.796203, Physics Loss: 0.000245\n",
      "Epoch 632/2000, Total Loss: 4.798651, Data Loss: 4.796165, Physics Loss: 0.000249\n",
      "Epoch 633/2000, Total Loss: 4.798638, Data Loss: 4.796189, Physics Loss: 0.000245\n",
      "Epoch 634/2000, Total Loss: 4.798618, Data Loss: 4.796124, Physics Loss: 0.000249\n",
      "Epoch 635/2000, Total Loss: 4.798573, Data Loss: 4.796131, Physics Loss: 0.000244\n",
      "Epoch 636/2000, Total Loss: 4.798533, Data Loss: 4.796062, Physics Loss: 0.000247\n",
      "Epoch 637/2000, Total Loss: 4.798501, Data Loss: 4.796069, Physics Loss: 0.000243\n",
      "Epoch 638/2000, Total Loss: 4.798499, Data Loss: 4.796020, Physics Loss: 0.000248\n",
      "Epoch 639/2000, Total Loss: 4.798521, Data Loss: 4.796060, Physics Loss: 0.000246\n",
      "Epoch 640/2000, Total Loss: 4.798577, Data Loss: 4.796037, Physics Loss: 0.000254\n",
      "Epoch 641/2000, Total Loss: 4.798651, Data Loss: 4.796126, Physics Loss: 0.000252\n",
      "Epoch 642/2000, Total Loss: 4.798772, Data Loss: 4.796111, Physics Loss: 0.000266\n",
      "Epoch 643/2000, Total Loss: 4.798937, Data Loss: 4.796295, Physics Loss: 0.000264\n",
      "Epoch 644/2000, Total Loss: 4.799161, Data Loss: 4.796287, Physics Loss: 0.000287\n",
      "Epoch 645/2000, Total Loss: 4.799482, Data Loss: 4.796593, Physics Loss: 0.000289\n",
      "Epoch 646/2000, Total Loss: 4.799873, Data Loss: 4.796653, Physics Loss: 0.000322\n",
      "Epoch 647/2000, Total Loss: 4.800568, Data Loss: 4.797224, Physics Loss: 0.000334\n",
      "Epoch 648/2000, Total Loss: 4.801324, Data Loss: 4.797409, Physics Loss: 0.000391\n",
      "Epoch 649/2000, Total Loss: 4.802540, Data Loss: 4.798385, Physics Loss: 0.000416\n",
      "Epoch 650/2000, Total Loss: 4.803316, Data Loss: 4.798489, Physics Loss: 0.000483\n",
      "Epoch 651/2000, Total Loss: 4.804402, Data Loss: 4.799539, Physics Loss: 0.000486\n",
      "Epoch 652/2000, Total Loss: 4.804000, Data Loss: 4.798948, Physics Loss: 0.000505\n",
      "Epoch 653/2000, Total Loss: 4.803342, Data Loss: 4.799006, Physics Loss: 0.000434\n",
      "Epoch 654/2000, Total Loss: 4.801167, Data Loss: 4.797501, Physics Loss: 0.000367\n",
      "Epoch 655/2000, Total Loss: 4.799196, Data Loss: 4.796579, Physics Loss: 0.000262\n",
      "Epoch 656/2000, Total Loss: 4.798178, Data Loss: 4.795953, Physics Loss: 0.000222\n",
      "Epoch 657/2000, Total Loss: 4.798520, Data Loss: 4.796136, Physics Loss: 0.000238\n",
      "Epoch 658/2000, Total Loss: 4.799404, Data Loss: 4.796728, Physics Loss: 0.000268\n",
      "Epoch 659/2000, Total Loss: 4.799592, Data Loss: 4.796727, Physics Loss: 0.000286\n",
      "Epoch 660/2000, Total Loss: 4.798941, Data Loss: 4.796463, Physics Loss: 0.000248\n",
      "Epoch 661/2000, Total Loss: 4.798186, Data Loss: 4.795926, Physics Loss: 0.000226\n",
      "Epoch 662/2000, Total Loss: 4.798126, Data Loss: 4.795879, Physics Loss: 0.000225\n",
      "Epoch 663/2000, Total Loss: 4.798607, Data Loss: 4.796205, Physics Loss: 0.000240\n",
      "Epoch 664/2000, Total Loss: 4.798862, Data Loss: 4.796245, Physics Loss: 0.000262\n",
      "Epoch 665/2000, Total Loss: 4.798580, Data Loss: 4.796138, Physics Loss: 0.000244\n",
      "Epoch 666/2000, Total Loss: 4.798079, Data Loss: 4.795775, Physics Loss: 0.000230\n",
      "Epoch 667/2000, Total Loss: 4.797859, Data Loss: 4.795648, Physics Loss: 0.000221\n",
      "Epoch 668/2000, Total Loss: 4.798067, Data Loss: 4.795776, Physics Loss: 0.000229\n",
      "Epoch 669/2000, Total Loss: 4.798361, Data Loss: 4.795864, Physics Loss: 0.000250\n",
      "Epoch 670/2000, Total Loss: 4.798375, Data Loss: 4.795944, Physics Loss: 0.000243\n",
      "Epoch 671/2000, Total Loss: 4.798082, Data Loss: 4.795674, Physics Loss: 0.000241\n",
      "Epoch 672/2000, Total Loss: 4.797745, Data Loss: 4.795520, Physics Loss: 0.000222\n",
      "Epoch 673/2000, Total Loss: 4.797658, Data Loss: 4.795441, Physics Loss: 0.000222\n",
      "Epoch 674/2000, Total Loss: 4.797813, Data Loss: 4.795481, Physics Loss: 0.000233\n",
      "Epoch 675/2000, Total Loss: 4.797962, Data Loss: 4.795619, Physics Loss: 0.000234\n",
      "Epoch 676/2000, Total Loss: 4.797935, Data Loss: 4.795507, Physics Loss: 0.000243\n",
      "Epoch 677/2000, Total Loss: 4.797751, Data Loss: 4.795457, Physics Loss: 0.000229\n",
      "Epoch 678/2000, Total Loss: 4.797557, Data Loss: 4.795281, Physics Loss: 0.000228\n",
      "Epoch 679/2000, Total Loss: 4.797462, Data Loss: 4.795228, Physics Loss: 0.000223\n",
      "Epoch 680/2000, Total Loss: 4.797488, Data Loss: 4.795247, Physics Loss: 0.000224\n",
      "Epoch 681/2000, Total Loss: 4.797589, Data Loss: 4.795251, Physics Loss: 0.000234\n",
      "Epoch 682/2000, Total Loss: 4.797663, Data Loss: 4.795330, Physics Loss: 0.000233\n",
      "Epoch 683/2000, Total Loss: 4.797688, Data Loss: 4.795267, Physics Loss: 0.000242\n",
      "Epoch 684/2000, Total Loss: 4.797615, Data Loss: 4.795273, Physics Loss: 0.000234\n",
      "Epoch 685/2000, Total Loss: 4.797468, Data Loss: 4.795131, Physics Loss: 0.000234\n",
      "Epoch 686/2000, Total Loss: 4.797326, Data Loss: 4.795075, Physics Loss: 0.000225\n",
      "Epoch 687/2000, Total Loss: 4.797253, Data Loss: 4.795007, Physics Loss: 0.000225\n",
      "Epoch 688/2000, Total Loss: 4.797238, Data Loss: 4.794989, Physics Loss: 0.000225\n",
      "Epoch 689/2000, Total Loss: 4.797256, Data Loss: 4.795004, Physics Loss: 0.000225\n",
      "Epoch 690/2000, Total Loss: 4.797285, Data Loss: 4.794978, Physics Loss: 0.000231\n",
      "Epoch 691/2000, Total Loss: 4.797276, Data Loss: 4.795010, Physics Loss: 0.000227\n",
      "Epoch 692/2000, Total Loss: 4.797213, Data Loss: 4.794919, Physics Loss: 0.000229\n",
      "Epoch 693/2000, Total Loss: 4.797121, Data Loss: 4.794881, Physics Loss: 0.000224\n",
      "Epoch 694/2000, Total Loss: 4.797073, Data Loss: 4.794832, Physics Loss: 0.000224\n",
      "Epoch 695/2000, Total Loss: 4.797065, Data Loss: 4.794810, Physics Loss: 0.000226\n",
      "Epoch 696/2000, Total Loss: 4.797062, Data Loss: 4.794816, Physics Loss: 0.000225\n",
      "Epoch 697/2000, Total Loss: 4.797088, Data Loss: 4.794784, Physics Loss: 0.000230\n",
      "Epoch 698/2000, Total Loss: 4.797112, Data Loss: 4.794823, Physics Loss: 0.000229\n",
      "Epoch 699/2000, Total Loss: 4.797116, Data Loss: 4.794777, Physics Loss: 0.000234\n",
      "Epoch 700/2000, Total Loss: 4.797084, Data Loss: 4.794786, Physics Loss: 0.000230\n",
      "Epoch 701/2000, Total Loss: 4.797046, Data Loss: 4.794713, Physics Loss: 0.000233\n",
      "Epoch 702/2000, Total Loss: 4.796986, Data Loss: 4.794722, Physics Loss: 0.000226\n",
      "Epoch 703/2000, Total Loss: 4.796919, Data Loss: 4.794631, Physics Loss: 0.000229\n",
      "Epoch 704/2000, Total Loss: 4.796847, Data Loss: 4.794607, Physics Loss: 0.000224\n",
      "Epoch 705/2000, Total Loss: 4.796803, Data Loss: 4.794561, Physics Loss: 0.000224\n",
      "Epoch 706/2000, Total Loss: 4.796771, Data Loss: 4.794539, Physics Loss: 0.000223\n",
      "Epoch 707/2000, Total Loss: 4.796739, Data Loss: 4.794515, Physics Loss: 0.000222\n",
      "Epoch 708/2000, Total Loss: 4.796717, Data Loss: 4.794487, Physics Loss: 0.000223\n",
      "Epoch 709/2000, Total Loss: 4.796706, Data Loss: 4.794478, Physics Loss: 0.000223\n",
      "Epoch 710/2000, Total Loss: 4.796692, Data Loss: 4.794457, Physics Loss: 0.000223\n",
      "Epoch 711/2000, Total Loss: 4.796663, Data Loss: 4.794440, Physics Loss: 0.000222\n",
      "Epoch 712/2000, Total Loss: 4.796641, Data Loss: 4.794407, Physics Loss: 0.000223\n",
      "Epoch 713/2000, Total Loss: 4.796608, Data Loss: 4.794395, Physics Loss: 0.000221\n",
      "Epoch 714/2000, Total Loss: 4.796587, Data Loss: 4.794362, Physics Loss: 0.000222\n",
      "Epoch 715/2000, Total Loss: 4.796554, Data Loss: 4.794343, Physics Loss: 0.000221\n",
      "Epoch 716/2000, Total Loss: 4.796527, Data Loss: 4.794321, Physics Loss: 0.000221\n",
      "Epoch 717/2000, Total Loss: 4.796528, Data Loss: 4.794302, Physics Loss: 0.000223\n",
      "Epoch 718/2000, Total Loss: 4.796518, Data Loss: 4.794302, Physics Loss: 0.000222\n",
      "Epoch 719/2000, Total Loss: 4.796504, Data Loss: 4.794266, Physics Loss: 0.000224\n",
      "Epoch 720/2000, Total Loss: 4.796492, Data Loss: 4.794275, Physics Loss: 0.000222\n",
      "Epoch 721/2000, Total Loss: 4.796458, Data Loss: 4.794221, Physics Loss: 0.000224\n",
      "Epoch 722/2000, Total Loss: 4.796413, Data Loss: 4.794205, Physics Loss: 0.000221\n",
      "Epoch 723/2000, Total Loss: 4.796379, Data Loss: 4.794166, Physics Loss: 0.000221\n",
      "Epoch 724/2000, Total Loss: 4.796344, Data Loss: 4.794145, Physics Loss: 0.000220\n",
      "Epoch 725/2000, Total Loss: 4.796320, Data Loss: 4.794118, Physics Loss: 0.000220\n",
      "Epoch 726/2000, Total Loss: 4.796302, Data Loss: 4.794099, Physics Loss: 0.000220\n",
      "Epoch 727/2000, Total Loss: 4.796285, Data Loss: 4.794087, Physics Loss: 0.000220\n",
      "Epoch 728/2000, Total Loss: 4.796286, Data Loss: 4.794062, Physics Loss: 0.000222\n",
      "Epoch 729/2000, Total Loss: 4.796271, Data Loss: 4.794068, Physics Loss: 0.000220\n",
      "Epoch 730/2000, Total Loss: 4.796263, Data Loss: 4.794027, Physics Loss: 0.000224\n",
      "Epoch 731/2000, Total Loss: 4.796268, Data Loss: 4.794047, Physics Loss: 0.000222\n",
      "Epoch 732/2000, Total Loss: 4.796298, Data Loss: 4.794024, Physics Loss: 0.000227\n",
      "Epoch 733/2000, Total Loss: 4.796353, Data Loss: 4.794088, Physics Loss: 0.000227\n",
      "Epoch 734/2000, Total Loss: 4.796440, Data Loss: 4.794073, Physics Loss: 0.000237\n",
      "Epoch 735/2000, Total Loss: 4.796549, Data Loss: 4.794188, Physics Loss: 0.000236\n",
      "Epoch 736/2000, Total Loss: 4.796700, Data Loss: 4.794181, Physics Loss: 0.000252\n",
      "Epoch 737/2000, Total Loss: 4.796927, Data Loss: 4.794398, Physics Loss: 0.000253\n",
      "Epoch 738/2000, Total Loss: 4.797207, Data Loss: 4.794428, Physics Loss: 0.000278\n",
      "Epoch 739/2000, Total Loss: 4.797617, Data Loss: 4.794792, Physics Loss: 0.000282\n",
      "Epoch 740/2000, Total Loss: 4.798042, Data Loss: 4.794862, Physics Loss: 0.000318\n",
      "Epoch 741/2000, Total Loss: 4.798662, Data Loss: 4.795384, Physics Loss: 0.000328\n",
      "Epoch 742/2000, Total Loss: 4.799147, Data Loss: 4.795437, Physics Loss: 0.000371\n",
      "Epoch 743/2000, Total Loss: 4.799902, Data Loss: 4.796121, Physics Loss: 0.000378\n",
      "Epoch 744/2000, Total Loss: 4.800133, Data Loss: 4.795988, Physics Loss: 0.000415\n",
      "Epoch 745/2000, Total Loss: 4.800405, Data Loss: 4.796468, Physics Loss: 0.000394\n",
      "Epoch 746/2000, Total Loss: 4.799718, Data Loss: 4.795825, Physics Loss: 0.000389\n",
      "Epoch 747/2000, Total Loss: 4.798846, Data Loss: 4.795595, Physics Loss: 0.000325\n",
      "Epoch 748/2000, Total Loss: 4.797412, Data Loss: 4.794647, Physics Loss: 0.000277\n",
      "Epoch 749/2000, Total Loss: 4.796308, Data Loss: 4.794130, Physics Loss: 0.000218\n",
      "Epoch 750/2000, Total Loss: 4.795955, Data Loss: 4.793911, Physics Loss: 0.000204\n",
      "Epoch 751/2000, Total Loss: 4.796354, Data Loss: 4.794109, Physics Loss: 0.000224\n",
      "Epoch 752/2000, Total Loss: 4.796922, Data Loss: 4.794508, Physics Loss: 0.000241\n",
      "Epoch 753/2000, Total Loss: 4.797019, Data Loss: 4.794456, Physics Loss: 0.000256\n",
      "Epoch 754/2000, Total Loss: 4.796626, Data Loss: 4.794304, Physics Loss: 0.000232\n",
      "Epoch 755/2000, Total Loss: 4.796084, Data Loss: 4.793925, Physics Loss: 0.000216\n",
      "Epoch 756/2000, Total Loss: 4.795838, Data Loss: 4.793787, Physics Loss: 0.000205\n",
      "Epoch 757/2000, Total Loss: 4.796015, Data Loss: 4.793894, Physics Loss: 0.000212\n",
      "Epoch 758/2000, Total Loss: 4.796339, Data Loss: 4.794015, Physics Loss: 0.000232\n",
      "Epoch 759/2000, Total Loss: 4.796413, Data Loss: 4.794101, Physics Loss: 0.000231\n",
      "Epoch 760/2000, Total Loss: 4.796174, Data Loss: 4.793887, Physics Loss: 0.000229\n",
      "Epoch 761/2000, Total Loss: 4.795834, Data Loss: 4.793722, Physics Loss: 0.000211\n",
      "Epoch 762/2000, Total Loss: 4.795680, Data Loss: 4.793603, Physics Loss: 0.000208\n",
      "Epoch 763/2000, Total Loss: 4.795761, Data Loss: 4.793619, Physics Loss: 0.000214\n",
      "Epoch 764/2000, Total Loss: 4.795952, Data Loss: 4.793755, Physics Loss: 0.000220\n",
      "Epoch 765/2000, Total Loss: 4.796074, Data Loss: 4.793745, Physics Loss: 0.000233\n",
      "Epoch 766/2000, Total Loss: 4.796014, Data Loss: 4.793769, Physics Loss: 0.000224\n",
      "Epoch 767/2000, Total Loss: 4.795844, Data Loss: 4.793591, Physics Loss: 0.000225\n",
      "Epoch 768/2000, Total Loss: 4.795650, Data Loss: 4.793518, Physics Loss: 0.000213\n",
      "Epoch 769/2000, Total Loss: 4.795529, Data Loss: 4.793408, Physics Loss: 0.000212\n",
      "Epoch 770/2000, Total Loss: 4.795489, Data Loss: 4.793377, Physics Loss: 0.000211\n",
      "Epoch 771/2000, Total Loss: 4.795503, Data Loss: 4.793381, Physics Loss: 0.000212\n",
      "Epoch 772/2000, Total Loss: 4.795527, Data Loss: 4.793362, Physics Loss: 0.000217\n",
      "Epoch 773/2000, Total Loss: 4.795525, Data Loss: 4.793377, Physics Loss: 0.000215\n",
      "Epoch 774/2000, Total Loss: 4.795519, Data Loss: 4.793328, Physics Loss: 0.000219\n",
      "Epoch 775/2000, Total Loss: 4.795467, Data Loss: 4.793320, Physics Loss: 0.000215\n",
      "Epoch 776/2000, Total Loss: 4.795413, Data Loss: 4.793252, Physics Loss: 0.000216\n",
      "Epoch 777/2000, Total Loss: 4.795357, Data Loss: 4.793230, Physics Loss: 0.000213\n",
      "Epoch 778/2000, Total Loss: 4.795320, Data Loss: 4.793191, Physics Loss: 0.000213\n",
      "Epoch 779/2000, Total Loss: 4.795298, Data Loss: 4.793167, Physics Loss: 0.000213\n",
      "Epoch 780/2000, Total Loss: 4.795300, Data Loss: 4.793169, Physics Loss: 0.000213\n",
      "Epoch 781/2000, Total Loss: 4.795305, Data Loss: 4.793144, Physics Loss: 0.000216\n",
      "Epoch 782/2000, Total Loss: 4.795287, Data Loss: 4.793146, Physics Loss: 0.000214\n",
      "Epoch 783/2000, Total Loss: 4.795261, Data Loss: 4.793101, Physics Loss: 0.000216\n",
      "Epoch 784/2000, Total Loss: 4.795222, Data Loss: 4.793085, Physics Loss: 0.000214\n",
      "Epoch 785/2000, Total Loss: 4.795186, Data Loss: 4.793048, Physics Loss: 0.000214\n",
      "Epoch 786/2000, Total Loss: 4.795154, Data Loss: 4.793023, Physics Loss: 0.000213\n",
      "Epoch 787/2000, Total Loss: 4.795129, Data Loss: 4.793001, Physics Loss: 0.000213\n",
      "Epoch 788/2000, Total Loss: 4.795116, Data Loss: 4.792978, Physics Loss: 0.000214\n",
      "Epoch 789/2000, Total Loss: 4.795103, Data Loss: 4.792971, Physics Loss: 0.000213\n",
      "Epoch 790/2000, Total Loss: 4.795089, Data Loss: 4.792943, Physics Loss: 0.000215\n",
      "Epoch 791/2000, Total Loss: 4.795064, Data Loss: 4.792929, Physics Loss: 0.000214\n",
      "Epoch 792/2000, Total Loss: 4.795043, Data Loss: 4.792898, Physics Loss: 0.000215\n",
      "Epoch 793/2000, Total Loss: 4.795022, Data Loss: 4.792892, Physics Loss: 0.000213\n",
      "Epoch 794/2000, Total Loss: 4.795022, Data Loss: 4.792865, Physics Loss: 0.000216\n",
      "Epoch 795/2000, Total Loss: 4.795001, Data Loss: 4.792870, Physics Loss: 0.000213\n",
      "Epoch 796/2000, Total Loss: 4.794980, Data Loss: 4.792829, Physics Loss: 0.000215\n",
      "Epoch 797/2000, Total Loss: 4.794946, Data Loss: 4.792816, Physics Loss: 0.000213\n",
      "Epoch 798/2000, Total Loss: 4.794923, Data Loss: 4.792782, Physics Loss: 0.000214\n",
      "Epoch 799/2000, Total Loss: 4.794901, Data Loss: 4.792774, Physics Loss: 0.000213\n",
      "Epoch 800/2000, Total Loss: 4.794878, Data Loss: 4.792752, Physics Loss: 0.000213\n",
      "Epoch 801/2000, Total Loss: 4.794856, Data Loss: 4.792728, Physics Loss: 0.000213\n",
      "Epoch 802/2000, Total Loss: 4.794840, Data Loss: 4.792716, Physics Loss: 0.000212\n",
      "Epoch 803/2000, Total Loss: 4.794837, Data Loss: 4.792704, Physics Loss: 0.000213\n",
      "Epoch 804/2000, Total Loss: 4.794827, Data Loss: 4.792696, Physics Loss: 0.000213\n",
      "Epoch 805/2000, Total Loss: 4.794807, Data Loss: 4.792667, Physics Loss: 0.000214\n",
      "Epoch 806/2000, Total Loss: 4.794788, Data Loss: 4.792670, Physics Loss: 0.000212\n",
      "Epoch 807/2000, Total Loss: 4.794781, Data Loss: 4.792637, Physics Loss: 0.000214\n",
      "Epoch 808/2000, Total Loss: 4.794762, Data Loss: 4.792638, Physics Loss: 0.000212\n",
      "Epoch 809/2000, Total Loss: 4.794760, Data Loss: 4.792610, Physics Loss: 0.000215\n",
      "Epoch 810/2000, Total Loss: 4.794764, Data Loss: 4.792629, Physics Loss: 0.000213\n",
      "Epoch 811/2000, Total Loss: 4.794797, Data Loss: 4.792608, Physics Loss: 0.000219\n",
      "Epoch 812/2000, Total Loss: 4.794826, Data Loss: 4.792653, Physics Loss: 0.000217\n",
      "Epoch 813/2000, Total Loss: 4.794904, Data Loss: 4.792647, Physics Loss: 0.000226\n",
      "Epoch 814/2000, Total Loss: 4.795009, Data Loss: 4.792757, Physics Loss: 0.000225\n",
      "Epoch 815/2000, Total Loss: 4.795165, Data Loss: 4.792761, Physics Loss: 0.000240\n",
      "Epoch 816/2000, Total Loss: 4.795390, Data Loss: 4.792959, Physics Loss: 0.000243\n",
      "Epoch 817/2000, Total Loss: 4.795744, Data Loss: 4.793034, Physics Loss: 0.000271\n",
      "Epoch 818/2000, Total Loss: 4.796268, Data Loss: 4.793446, Physics Loss: 0.000282\n",
      "Epoch 819/2000, Total Loss: 4.796885, Data Loss: 4.793613, Physics Loss: 0.000327\n",
      "Epoch 820/2000, Total Loss: 4.797837, Data Loss: 4.794363, Physics Loss: 0.000347\n",
      "Epoch 821/2000, Total Loss: 4.798700, Data Loss: 4.794573, Physics Loss: 0.000413\n",
      "Epoch 822/2000, Total Loss: 4.800169, Data Loss: 4.795746, Physics Loss: 0.000442\n",
      "Epoch 823/2000, Total Loss: 4.800895, Data Loss: 4.795782, Physics Loss: 0.000511\n",
      "Epoch 824/2000, Total Loss: 4.801798, Data Loss: 4.796751, Physics Loss: 0.000505\n",
      "Epoch 825/2000, Total Loss: 4.800468, Data Loss: 4.795652, Physics Loss: 0.000482\n",
      "Epoch 826/2000, Total Loss: 4.798679, Data Loss: 4.795027, Physics Loss: 0.000365\n",
      "Epoch 827/2000, Total Loss: 4.796089, Data Loss: 4.793406, Physics Loss: 0.000268\n",
      "Epoch 828/2000, Total Loss: 4.794679, Data Loss: 4.792707, Physics Loss: 0.000197\n",
      "Epoch 829/2000, Total Loss: 4.795118, Data Loss: 4.792971, Physics Loss: 0.000215\n",
      "Epoch 830/2000, Total Loss: 4.796379, Data Loss: 4.793621, Physics Loss: 0.000276\n",
      "Epoch 831/2000, Total Loss: 4.796764, Data Loss: 4.793988, Physics Loss: 0.000278\n",
      "Epoch 832/2000, Total Loss: 4.795708, Data Loss: 4.793255, Physics Loss: 0.000245\n",
      "Epoch 833/2000, Total Loss: 4.794696, Data Loss: 4.792718, Physics Loss: 0.000198\n",
      "Epoch 834/2000, Total Loss: 4.794805, Data Loss: 4.792765, Physics Loss: 0.000204\n",
      "Epoch 835/2000, Total Loss: 4.795532, Data Loss: 4.793121, Physics Loss: 0.000241\n",
      "Epoch 836/2000, Total Loss: 4.795734, Data Loss: 4.793321, Physics Loss: 0.000241\n",
      "Epoch 837/2000, Total Loss: 4.795158, Data Loss: 4.792875, Physics Loss: 0.000228\n",
      "Epoch 838/2000, Total Loss: 4.794544, Data Loss: 4.792537, Physics Loss: 0.000201\n",
      "Epoch 839/2000, Total Loss: 4.794598, Data Loss: 4.792561, Physics Loss: 0.000204\n",
      "Epoch 840/2000, Total Loss: 4.795067, Data Loss: 4.792758, Physics Loss: 0.000231\n",
      "Epoch 841/2000, Total Loss: 4.795181, Data Loss: 4.792892, Physics Loss: 0.000229\n",
      "Epoch 842/2000, Total Loss: 4.794805, Data Loss: 4.792565, Physics Loss: 0.000224\n",
      "Epoch 843/2000, Total Loss: 4.794405, Data Loss: 4.792364, Physics Loss: 0.000204\n",
      "Epoch 844/2000, Total Loss: 4.794407, Data Loss: 4.792356, Physics Loss: 0.000205\n",
      "Epoch 845/2000, Total Loss: 4.794690, Data Loss: 4.792454, Physics Loss: 0.000224\n",
      "Epoch 846/2000, Total Loss: 4.794841, Data Loss: 4.792594, Physics Loss: 0.000225\n",
      "Epoch 847/2000, Total Loss: 4.794744, Data Loss: 4.792445, Physics Loss: 0.000230\n",
      "Epoch 848/2000, Total Loss: 4.794445, Data Loss: 4.792323, Physics Loss: 0.000212\n",
      "Epoch 849/2000, Total Loss: 4.794242, Data Loss: 4.792164, Physics Loss: 0.000208\n",
      "Epoch 850/2000, Total Loss: 4.794258, Data Loss: 4.792153, Physics Loss: 0.000210\n",
      "Epoch 851/2000, Total Loss: 4.794423, Data Loss: 4.792277, Physics Loss: 0.000215\n",
      "Epoch 852/2000, Total Loss: 4.794581, Data Loss: 4.792296, Physics Loss: 0.000228\n",
      "Epoch 853/2000, Total Loss: 4.794528, Data Loss: 4.792329, Physics Loss: 0.000220\n",
      "Epoch 854/2000, Total Loss: 4.794364, Data Loss: 4.792166, Physics Loss: 0.000220\n",
      "Epoch 855/2000, Total Loss: 4.794162, Data Loss: 4.792088, Physics Loss: 0.000207\n",
      "Epoch 856/2000, Total Loss: 4.794062, Data Loss: 4.792006, Physics Loss: 0.000206\n",
      "Epoch 857/2000, Total Loss: 4.794093, Data Loss: 4.792009, Physics Loss: 0.000208\n",
      "Epoch 858/2000, Total Loss: 4.794208, Data Loss: 4.792108, Physics Loss: 0.000210\n",
      "Epoch 859/2000, Total Loss: 4.794327, Data Loss: 4.792110, Physics Loss: 0.000222\n",
      "Epoch 860/2000, Total Loss: 4.794312, Data Loss: 4.792156, Physics Loss: 0.000216\n",
      "Epoch 861/2000, Total Loss: 4.794201, Data Loss: 4.792035, Physics Loss: 0.000217\n",
      "Epoch 862/2000, Total Loss: 4.794038, Data Loss: 4.791984, Physics Loss: 0.000205\n",
      "Epoch 863/2000, Total Loss: 4.793932, Data Loss: 4.791890, Physics Loss: 0.000204\n",
      "Epoch 864/2000, Total Loss: 4.793903, Data Loss: 4.791868, Physics Loss: 0.000204\n",
      "Epoch 865/2000, Total Loss: 4.793936, Data Loss: 4.791895, Physics Loss: 0.000204\n",
      "Epoch 866/2000, Total Loss: 4.794009, Data Loss: 4.791897, Physics Loss: 0.000211\n",
      "Epoch 867/2000, Total Loss: 4.794024, Data Loss: 4.791941, Physics Loss: 0.000208\n",
      "Epoch 868/2000, Total Loss: 4.794003, Data Loss: 4.791870, Physics Loss: 0.000213\n",
      "Epoch 869/2000, Total Loss: 4.793921, Data Loss: 4.791853, Physics Loss: 0.000207\n",
      "Epoch 870/2000, Total Loss: 4.793857, Data Loss: 4.791776, Physics Loss: 0.000208\n",
      "Epoch 871/2000, Total Loss: 4.793794, Data Loss: 4.791745, Physics Loss: 0.000205\n",
      "Epoch 872/2000, Total Loss: 4.793772, Data Loss: 4.791719, Physics Loss: 0.000205\n",
      "Epoch 873/2000, Total Loss: 4.793764, Data Loss: 4.791698, Physics Loss: 0.000207\n",
      "Epoch 874/2000, Total Loss: 4.793759, Data Loss: 4.791699, Physics Loss: 0.000206\n",
      "Epoch 875/2000, Total Loss: 4.793751, Data Loss: 4.791667, Physics Loss: 0.000208\n",
      "Epoch 876/2000, Total Loss: 4.793721, Data Loss: 4.791655, Physics Loss: 0.000207\n",
      "Epoch 877/2000, Total Loss: 4.793703, Data Loss: 4.791630, Physics Loss: 0.000207\n",
      "Epoch 878/2000, Total Loss: 4.793693, Data Loss: 4.791616, Physics Loss: 0.000208\n",
      "Epoch 879/2000, Total Loss: 4.793683, Data Loss: 4.791606, Physics Loss: 0.000208\n",
      "Epoch 880/2000, Total Loss: 4.793676, Data Loss: 4.791590, Physics Loss: 0.000209\n",
      "Epoch 881/2000, Total Loss: 4.793667, Data Loss: 4.791587, Physics Loss: 0.000208\n",
      "Epoch 882/2000, Total Loss: 4.793656, Data Loss: 4.791560, Physics Loss: 0.000210\n",
      "Epoch 883/2000, Total Loss: 4.793627, Data Loss: 4.791553, Physics Loss: 0.000207\n",
      "Epoch 884/2000, Total Loss: 4.793604, Data Loss: 4.791522, Physics Loss: 0.000208\n",
      "Epoch 885/2000, Total Loss: 4.793586, Data Loss: 4.791508, Physics Loss: 0.000208\n",
      "Epoch 886/2000, Total Loss: 4.793565, Data Loss: 4.791491, Physics Loss: 0.000207\n",
      "Epoch 887/2000, Total Loss: 4.793561, Data Loss: 4.791474, Physics Loss: 0.000209\n",
      "Epoch 888/2000, Total Loss: 4.793557, Data Loss: 4.791476, Physics Loss: 0.000208\n",
      "Epoch 889/2000, Total Loss: 4.793553, Data Loss: 4.791451, Physics Loss: 0.000210\n",
      "Epoch 890/2000, Total Loss: 4.793540, Data Loss: 4.791454, Physics Loss: 0.000209\n",
      "Epoch 891/2000, Total Loss: 4.793533, Data Loss: 4.791424, Physics Loss: 0.000211\n",
      "Epoch 892/2000, Total Loss: 4.793507, Data Loss: 4.791418, Physics Loss: 0.000209\n",
      "Epoch 893/2000, Total Loss: 4.793489, Data Loss: 4.791385, Physics Loss: 0.000210\n",
      "Epoch 894/2000, Total Loss: 4.793467, Data Loss: 4.791377, Physics Loss: 0.000209\n",
      "Epoch 895/2000, Total Loss: 4.793454, Data Loss: 4.791349, Physics Loss: 0.000210\n",
      "Epoch 896/2000, Total Loss: 4.793443, Data Loss: 4.791340, Physics Loss: 0.000210\n",
      "Epoch 897/2000, Total Loss: 4.793440, Data Loss: 4.791324, Physics Loss: 0.000212\n",
      "Epoch 898/2000, Total Loss: 4.793437, Data Loss: 4.791311, Physics Loss: 0.000213\n",
      "Epoch 899/2000, Total Loss: 4.793428, Data Loss: 4.791292, Physics Loss: 0.000214\n",
      "Epoch 900/2000, Total Loss: 4.793426, Data Loss: 4.791286, Physics Loss: 0.000214\n",
      "Epoch 901/2000, Total Loss: 4.793425, Data Loss: 4.791265, Physics Loss: 0.000216\n",
      "Epoch 902/2000, Total Loss: 4.793415, Data Loss: 4.791262, Physics Loss: 0.000215\n",
      "Epoch 903/2000, Total Loss: 4.793417, Data Loss: 4.791241, Physics Loss: 0.000218\n",
      "Epoch 904/2000, Total Loss: 4.793396, Data Loss: 4.791236, Physics Loss: 0.000216\n",
      "Epoch 905/2000, Total Loss: 4.793385, Data Loss: 4.791208, Physics Loss: 0.000218\n",
      "Epoch 906/2000, Total Loss: 4.793365, Data Loss: 4.791206, Physics Loss: 0.000216\n",
      "Epoch 907/2000, Total Loss: 4.793362, Data Loss: 4.791184, Physics Loss: 0.000218\n",
      "Epoch 908/2000, Total Loss: 4.793341, Data Loss: 4.791184, Physics Loss: 0.000216\n",
      "Epoch 909/2000, Total Loss: 4.793328, Data Loss: 4.791159, Physics Loss: 0.000217\n",
      "Epoch 910/2000, Total Loss: 4.793313, Data Loss: 4.791159, Physics Loss: 0.000215\n",
      "Epoch 911/2000, Total Loss: 4.793312, Data Loss: 4.791136, Physics Loss: 0.000218\n",
      "Epoch 912/2000, Total Loss: 4.793293, Data Loss: 4.791143, Physics Loss: 0.000215\n",
      "Epoch 913/2000, Total Loss: 4.793296, Data Loss: 4.791116, Physics Loss: 0.000218\n",
      "Epoch 914/2000, Total Loss: 4.793298, Data Loss: 4.791135, Physics Loss: 0.000216\n",
      "Epoch 915/2000, Total Loss: 4.793307, Data Loss: 4.791108, Physics Loss: 0.000220\n",
      "Epoch 916/2000, Total Loss: 4.793297, Data Loss: 4.791131, Physics Loss: 0.000217\n",
      "Epoch 917/2000, Total Loss: 4.793303, Data Loss: 4.791090, Physics Loss: 0.000221\n",
      "Epoch 918/2000, Total Loss: 4.793290, Data Loss: 4.791111, Physics Loss: 0.000218\n",
      "Epoch 919/2000, Total Loss: 4.793316, Data Loss: 4.791083, Physics Loss: 0.000223\n",
      "Epoch 920/2000, Total Loss: 4.793337, Data Loss: 4.791126, Physics Loss: 0.000221\n",
      "Epoch 921/2000, Total Loss: 4.793404, Data Loss: 4.791113, Physics Loss: 0.000229\n",
      "Epoch 922/2000, Total Loss: 4.793451, Data Loss: 4.791185, Physics Loss: 0.000227\n",
      "Epoch 923/2000, Total Loss: 4.793566, Data Loss: 4.791175, Physics Loss: 0.000239\n",
      "Epoch 924/2000, Total Loss: 4.793689, Data Loss: 4.791331, Physics Loss: 0.000236\n",
      "Epoch 925/2000, Total Loss: 4.793905, Data Loss: 4.791335, Physics Loss: 0.000257\n",
      "Epoch 926/2000, Total Loss: 4.794148, Data Loss: 4.791579, Physics Loss: 0.000257\n",
      "Epoch 927/2000, Total Loss: 4.794461, Data Loss: 4.791612, Physics Loss: 0.000285\n",
      "Epoch 928/2000, Total Loss: 4.794817, Data Loss: 4.791943, Physics Loss: 0.000287\n",
      "Epoch 929/2000, Total Loss: 4.795235, Data Loss: 4.791994, Physics Loss: 0.000324\n",
      "Epoch 930/2000, Total Loss: 4.795839, Data Loss: 4.792546, Physics Loss: 0.000329\n",
      "Epoch 931/2000, Total Loss: 4.796394, Data Loss: 4.792615, Physics Loss: 0.000378\n",
      "Epoch 932/2000, Total Loss: 4.797122, Data Loss: 4.793310, Physics Loss: 0.000381\n",
      "Epoch 933/2000, Total Loss: 4.797326, Data Loss: 4.793133, Physics Loss: 0.000419\n",
      "Epoch 934/2000, Total Loss: 4.797475, Data Loss: 4.793584, Physics Loss: 0.000389\n",
      "Epoch 935/2000, Total Loss: 4.796657, Data Loss: 4.792842, Physics Loss: 0.000382\n",
      "Epoch 936/2000, Total Loss: 4.795485, Data Loss: 4.792450, Physics Loss: 0.000303\n",
      "Epoch 937/2000, Total Loss: 4.794142, Data Loss: 4.791540, Physics Loss: 0.000260\n",
      "Epoch 938/2000, Total Loss: 4.793302, Data Loss: 4.791139, Physics Loss: 0.000216\n",
      "Epoch 939/2000, Total Loss: 4.793373, Data Loss: 4.791169, Physics Loss: 0.000220\n",
      "Epoch 940/2000, Total Loss: 4.794009, Data Loss: 4.791473, Physics Loss: 0.000254\n",
      "Epoch 941/2000, Total Loss: 4.794378, Data Loss: 4.791787, Physics Loss: 0.000259\n",
      "Epoch 942/2000, Total Loss: 4.794176, Data Loss: 4.791549, Physics Loss: 0.000263\n",
      "Epoch 943/2000, Total Loss: 4.793585, Data Loss: 4.791270, Physics Loss: 0.000231\n",
      "Epoch 944/2000, Total Loss: 4.793260, Data Loss: 4.791036, Physics Loss: 0.000222\n",
      "Epoch 945/2000, Total Loss: 4.793401, Data Loss: 4.791083, Physics Loss: 0.000232\n",
      "Epoch 946/2000, Total Loss: 4.793674, Data Loss: 4.791297, Physics Loss: 0.000238\n",
      "Epoch 947/2000, Total Loss: 4.793837, Data Loss: 4.791293, Physics Loss: 0.000254\n",
      "Epoch 948/2000, Total Loss: 4.793625, Data Loss: 4.791230, Physics Loss: 0.000239\n",
      "Epoch 949/2000, Total Loss: 4.793318, Data Loss: 4.790993, Physics Loss: 0.000233\n",
      "Epoch 950/2000, Total Loss: 4.793139, Data Loss: 4.790904, Physics Loss: 0.000223\n",
      "Epoch 951/2000, Total Loss: 4.793205, Data Loss: 4.790951, Physics Loss: 0.000225\n",
      "Epoch 952/2000, Total Loss: 4.793398, Data Loss: 4.790998, Physics Loss: 0.000240\n",
      "Epoch 953/2000, Total Loss: 4.793469, Data Loss: 4.791093, Physics Loss: 0.000238\n",
      "Epoch 954/2000, Total Loss: 4.793414, Data Loss: 4.790993, Physics Loss: 0.000242\n",
      "Epoch 955/2000, Total Loss: 4.793224, Data Loss: 4.790923, Physics Loss: 0.000230\n",
      "Epoch 956/2000, Total Loss: 4.793079, Data Loss: 4.790801, Physics Loss: 0.000228\n",
      "Epoch 957/2000, Total Loss: 4.792998, Data Loss: 4.790771, Physics Loss: 0.000223\n",
      "Epoch 958/2000, Total Loss: 4.793032, Data Loss: 4.790778, Physics Loss: 0.000225\n",
      "Epoch 959/2000, Total Loss: 4.793132, Data Loss: 4.790798, Physics Loss: 0.000233\n",
      "Epoch 960/2000, Total Loss: 4.793200, Data Loss: 4.790874, Physics Loss: 0.000233\n",
      "Epoch 961/2000, Total Loss: 4.793244, Data Loss: 4.790831, Physics Loss: 0.000241\n",
      "Epoch 962/2000, Total Loss: 4.793166, Data Loss: 4.790843, Physics Loss: 0.000232\n",
      "Epoch 963/2000, Total Loss: 4.793061, Data Loss: 4.790720, Physics Loss: 0.000234\n",
      "Epoch 964/2000, Total Loss: 4.792946, Data Loss: 4.790679, Physics Loss: 0.000227\n",
      "Epoch 965/2000, Total Loss: 4.792899, Data Loss: 4.790635, Physics Loss: 0.000226\n",
      "Epoch 966/2000, Total Loss: 4.792929, Data Loss: 4.790636, Physics Loss: 0.000229\n",
      "Epoch 967/2000, Total Loss: 4.793005, Data Loss: 4.790701, Physics Loss: 0.000230\n",
      "Epoch 968/2000, Total Loss: 4.793124, Data Loss: 4.790716, Physics Loss: 0.000241\n",
      "Epoch 969/2000, Total Loss: 4.793190, Data Loss: 4.790803, Physics Loss: 0.000239\n",
      "Epoch 970/2000, Total Loss: 4.793180, Data Loss: 4.790732, Physics Loss: 0.000245\n",
      "Epoch 971/2000, Total Loss: 4.793087, Data Loss: 4.790740, Physics Loss: 0.000235\n",
      "Epoch 972/2000, Total Loss: 4.792989, Data Loss: 4.790631, Physics Loss: 0.000236\n",
      "Epoch 973/2000, Total Loss: 4.792868, Data Loss: 4.790601, Physics Loss: 0.000227\n",
      "Epoch 974/2000, Total Loss: 4.792788, Data Loss: 4.790533, Physics Loss: 0.000225\n",
      "Epoch 975/2000, Total Loss: 4.792761, Data Loss: 4.790518, Physics Loss: 0.000224\n",
      "Epoch 976/2000, Total Loss: 4.792759, Data Loss: 4.790534, Physics Loss: 0.000222\n",
      "Epoch 977/2000, Total Loss: 4.792787, Data Loss: 4.790517, Physics Loss: 0.000227\n",
      "Epoch 978/2000, Total Loss: 4.792804, Data Loss: 4.790554, Physics Loss: 0.000225\n",
      "Epoch 979/2000, Total Loss: 4.792805, Data Loss: 4.790518, Physics Loss: 0.000229\n",
      "Epoch 980/2000, Total Loss: 4.792750, Data Loss: 4.790518, Physics Loss: 0.000223\n",
      "Epoch 981/2000, Total Loss: 4.792695, Data Loss: 4.790454, Physics Loss: 0.000224\n",
      "Epoch 982/2000, Total Loss: 4.792635, Data Loss: 4.790442, Physics Loss: 0.000219\n",
      "Epoch 983/2000, Total Loss: 4.792602, Data Loss: 4.790402, Physics Loss: 0.000220\n",
      "Epoch 984/2000, Total Loss: 4.792592, Data Loss: 4.790393, Physics Loss: 0.000220\n",
      "Epoch 985/2000, Total Loss: 4.792602, Data Loss: 4.790404, Physics Loss: 0.000220\n",
      "Epoch 986/2000, Total Loss: 4.792619, Data Loss: 4.790387, Physics Loss: 0.000223\n",
      "Epoch 987/2000, Total Loss: 4.792631, Data Loss: 4.790421, Physics Loss: 0.000221\n",
      "Epoch 988/2000, Total Loss: 4.792633, Data Loss: 4.790387, Physics Loss: 0.000225\n",
      "Epoch 989/2000, Total Loss: 4.792618, Data Loss: 4.790411, Physics Loss: 0.000221\n",
      "Epoch 990/2000, Total Loss: 4.792612, Data Loss: 4.790363, Physics Loss: 0.000225\n",
      "Epoch 991/2000, Total Loss: 4.792593, Data Loss: 4.790388, Physics Loss: 0.000221\n",
      "Epoch 992/2000, Total Loss: 4.792557, Data Loss: 4.790332, Physics Loss: 0.000222\n",
      "Epoch 993/2000, Total Loss: 4.792504, Data Loss: 4.790327, Physics Loss: 0.000218\n",
      "Epoch 994/2000, Total Loss: 4.792449, Data Loss: 4.790275, Physics Loss: 0.000217\n",
      "Epoch 995/2000, Total Loss: 4.792404, Data Loss: 4.790266, Physics Loss: 0.000214\n",
      "Epoch 996/2000, Total Loss: 4.792377, Data Loss: 4.790235, Physics Loss: 0.000214\n",
      "Epoch 997/2000, Total Loss: 4.792356, Data Loss: 4.790221, Physics Loss: 0.000214\n",
      "Epoch 998/2000, Total Loss: 4.792350, Data Loss: 4.790226, Physics Loss: 0.000212\n",
      "Epoch 999/2000, Total Loss: 4.792343, Data Loss: 4.790201, Physics Loss: 0.000214\n",
      "Epoch 1000/2000, Total Loss: 4.792332, Data Loss: 4.790204, Physics Loss: 0.000213\n",
      "Epoch 1001/2000, Total Loss: 4.792328, Data Loss: 4.790184, Physics Loss: 0.000214\n",
      "Epoch 1002/2000, Total Loss: 4.792329, Data Loss: 4.790189, Physics Loss: 0.000214\n",
      "Epoch 1003/2000, Total Loss: 4.792327, Data Loss: 4.790167, Physics Loss: 0.000216\n",
      "Epoch 1004/2000, Total Loss: 4.792309, Data Loss: 4.790174, Physics Loss: 0.000214\n",
      "Epoch 1005/2000, Total Loss: 4.792304, Data Loss: 4.790142, Physics Loss: 0.000216\n",
      "Epoch 1006/2000, Total Loss: 4.792297, Data Loss: 4.790159, Physics Loss: 0.000214\n",
      "Epoch 1007/2000, Total Loss: 4.792279, Data Loss: 4.790115, Physics Loss: 0.000216\n",
      "Epoch 1008/2000, Total Loss: 4.792251, Data Loss: 4.790121, Physics Loss: 0.000213\n",
      "Epoch 1009/2000, Total Loss: 4.792238, Data Loss: 4.790082, Physics Loss: 0.000216\n",
      "Epoch 1010/2000, Total Loss: 4.792233, Data Loss: 4.790094, Physics Loss: 0.000214\n",
      "Epoch 1011/2000, Total Loss: 4.792243, Data Loss: 4.790070, Physics Loss: 0.000217\n",
      "Epoch 1012/2000, Total Loss: 4.792277, Data Loss: 4.790122, Physics Loss: 0.000216\n",
      "Epoch 1013/2000, Total Loss: 4.792335, Data Loss: 4.790099, Physics Loss: 0.000224\n",
      "Epoch 1014/2000, Total Loss: 4.792388, Data Loss: 4.790181, Physics Loss: 0.000221\n",
      "Epoch 1015/2000, Total Loss: 4.792440, Data Loss: 4.790142, Physics Loss: 0.000230\n",
      "Epoch 1016/2000, Total Loss: 4.792515, Data Loss: 4.790243, Physics Loss: 0.000227\n",
      "Epoch 1017/2000, Total Loss: 4.792634, Data Loss: 4.790228, Physics Loss: 0.000241\n",
      "Epoch 1018/2000, Total Loss: 4.792822, Data Loss: 4.790415, Physics Loss: 0.000241\n",
      "Epoch 1019/2000, Total Loss: 4.793031, Data Loss: 4.790424, Physics Loss: 0.000261\n",
      "Epoch 1020/2000, Total Loss: 4.793331, Data Loss: 4.790713, Physics Loss: 0.000262\n",
      "Epoch 1021/2000, Total Loss: 4.793611, Data Loss: 4.790738, Physics Loss: 0.000287\n",
      "Epoch 1022/2000, Total Loss: 4.794029, Data Loss: 4.791121, Physics Loss: 0.000291\n",
      "Epoch 1023/2000, Total Loss: 4.794377, Data Loss: 4.791112, Physics Loss: 0.000326\n",
      "Epoch 1024/2000, Total Loss: 4.794943, Data Loss: 4.791630, Physics Loss: 0.000331\n",
      "Epoch 1025/2000, Total Loss: 4.795131, Data Loss: 4.791520, Physics Loss: 0.000361\n",
      "Epoch 1026/2000, Total Loss: 4.795353, Data Loss: 4.791916, Physics Loss: 0.000344\n",
      "Epoch 1027/2000, Total Loss: 4.794888, Data Loss: 4.791457, Physics Loss: 0.000343\n",
      "Epoch 1028/2000, Total Loss: 4.794317, Data Loss: 4.791384, Physics Loss: 0.000293\n",
      "Epoch 1029/2000, Total Loss: 4.793334, Data Loss: 4.790679, Physics Loss: 0.000265\n",
      "Epoch 1030/2000, Total Loss: 4.792513, Data Loss: 4.790323, Physics Loss: 0.000219\n",
      "Epoch 1031/2000, Total Loss: 4.792025, Data Loss: 4.790017, Physics Loss: 0.000201\n",
      "Epoch 1032/2000, Total Loss: 4.791987, Data Loss: 4.789999, Physics Loss: 0.000199\n",
      "Epoch 1033/2000, Total Loss: 4.792290, Data Loss: 4.790202, Physics Loss: 0.000209\n",
      "Epoch 1034/2000, Total Loss: 4.792635, Data Loss: 4.790323, Physics Loss: 0.000231\n",
      "Epoch 1035/2000, Total Loss: 4.792777, Data Loss: 4.790468, Physics Loss: 0.000231\n",
      "Epoch 1036/2000, Total Loss: 4.792564, Data Loss: 4.790271, Physics Loss: 0.000229\n",
      "Epoch 1037/2000, Total Loss: 4.792211, Data Loss: 4.790122, Physics Loss: 0.000209\n",
      "Epoch 1038/2000, Total Loss: 4.791930, Data Loss: 4.789917, Physics Loss: 0.000201\n",
      "Epoch 1039/2000, Total Loss: 4.791819, Data Loss: 4.789853, Physics Loss: 0.000197\n",
      "Epoch 1040/2000, Total Loss: 4.791875, Data Loss: 4.789886, Physics Loss: 0.000199\n",
      "Epoch 1041/2000, Total Loss: 4.792002, Data Loss: 4.789908, Physics Loss: 0.000209\n",
      "Epoch 1042/2000, Total Loss: 4.792080, Data Loss: 4.789987, Physics Loss: 0.000209\n",
      "Epoch 1043/2000, Total Loss: 4.792059, Data Loss: 4.789902, Physics Loss: 0.000216\n",
      "Epoch 1044/2000, Total Loss: 4.791947, Data Loss: 4.789877, Physics Loss: 0.000207\n",
      "Epoch 1045/2000, Total Loss: 4.791806, Data Loss: 4.789749, Physics Loss: 0.000206\n",
      "Epoch 1046/2000, Total Loss: 4.791698, Data Loss: 4.789699, Physics Loss: 0.000200\n",
      "Epoch 1047/2000, Total Loss: 4.791664, Data Loss: 4.789662, Physics Loss: 0.000200\n",
      "Epoch 1048/2000, Total Loss: 4.791677, Data Loss: 4.789646, Physics Loss: 0.000203\n",
      "Epoch 1049/2000, Total Loss: 4.791703, Data Loss: 4.789669, Physics Loss: 0.000203\n",
      "Epoch 1050/2000, Total Loss: 4.791718, Data Loss: 4.789634, Physics Loss: 0.000208\n",
      "Epoch 1051/2000, Total Loss: 4.791708, Data Loss: 4.789658, Physics Loss: 0.000205\n",
      "Epoch 1052/2000, Total Loss: 4.791694, Data Loss: 4.789598, Physics Loss: 0.000210\n",
      "Epoch 1053/2000, Total Loss: 4.791665, Data Loss: 4.789610, Physics Loss: 0.000205\n",
      "Epoch 1054/2000, Total Loss: 4.791642, Data Loss: 4.789551, Physics Loss: 0.000209\n",
      "Epoch 1055/2000, Total Loss: 4.791611, Data Loss: 4.789558, Physics Loss: 0.000205\n",
      "Epoch 1056/2000, Total Loss: 4.791576, Data Loss: 4.789504, Physics Loss: 0.000207\n",
      "Epoch 1057/2000, Total Loss: 4.791540, Data Loss: 4.789496, Physics Loss: 0.000204\n",
      "Epoch 1058/2000, Total Loss: 4.791519, Data Loss: 4.789464, Physics Loss: 0.000205\n",
      "Epoch 1059/2000, Total Loss: 4.791500, Data Loss: 4.789460, Physics Loss: 0.000204\n",
      "Epoch 1060/2000, Total Loss: 4.791486, Data Loss: 4.789436, Physics Loss: 0.000205\n",
      "Epoch 1061/2000, Total Loss: 4.791465, Data Loss: 4.789429, Physics Loss: 0.000204\n",
      "Epoch 1062/2000, Total Loss: 4.791445, Data Loss: 4.789406, Physics Loss: 0.000204\n",
      "Epoch 1063/2000, Total Loss: 4.791443, Data Loss: 4.789396, Physics Loss: 0.000205\n",
      "Epoch 1064/2000, Total Loss: 4.791441, Data Loss: 4.789402, Physics Loss: 0.000204\n",
      "Epoch 1065/2000, Total Loss: 4.791449, Data Loss: 4.789380, Physics Loss: 0.000207\n",
      "Epoch 1066/2000, Total Loss: 4.791453, Data Loss: 4.789399, Physics Loss: 0.000205\n",
      "Epoch 1067/2000, Total Loss: 4.791464, Data Loss: 4.789368, Physics Loss: 0.000210\n",
      "Epoch 1068/2000, Total Loss: 4.791469, Data Loss: 4.789402, Physics Loss: 0.000207\n",
      "Epoch 1069/2000, Total Loss: 4.791468, Data Loss: 4.789358, Physics Loss: 0.000211\n",
      "Epoch 1070/2000, Total Loss: 4.791465, Data Loss: 4.789387, Physics Loss: 0.000208\n",
      "Epoch 1071/2000, Total Loss: 4.791479, Data Loss: 4.789356, Physics Loss: 0.000212\n",
      "Epoch 1072/2000, Total Loss: 4.791482, Data Loss: 4.789394, Physics Loss: 0.000209\n",
      "Epoch 1073/2000, Total Loss: 4.791513, Data Loss: 4.789355, Physics Loss: 0.000216\n",
      "Epoch 1074/2000, Total Loss: 4.791556, Data Loss: 4.789428, Physics Loss: 0.000213\n",
      "Epoch 1075/2000, Total Loss: 4.791614, Data Loss: 4.789395, Physics Loss: 0.000222\n",
      "Epoch 1076/2000, Total Loss: 4.791688, Data Loss: 4.789485, Physics Loss: 0.000220\n",
      "Epoch 1077/2000, Total Loss: 4.791774, Data Loss: 4.789459, Physics Loss: 0.000232\n",
      "Epoch 1078/2000, Total Loss: 4.791885, Data Loss: 4.789598, Physics Loss: 0.000229\n",
      "Epoch 1079/2000, Total Loss: 4.792008, Data Loss: 4.789572, Physics Loss: 0.000244\n",
      "Epoch 1080/2000, Total Loss: 4.792194, Data Loss: 4.789774, Physics Loss: 0.000242\n",
      "Epoch 1081/2000, Total Loss: 4.792392, Data Loss: 4.789769, Physics Loss: 0.000262\n",
      "Epoch 1082/2000, Total Loss: 4.792718, Data Loss: 4.790070, Physics Loss: 0.000265\n",
      "Epoch 1083/2000, Total Loss: 4.793022, Data Loss: 4.790089, Physics Loss: 0.000293\n",
      "Epoch 1084/2000, Total Loss: 4.793478, Data Loss: 4.790500, Physics Loss: 0.000298\n",
      "Epoch 1085/2000, Total Loss: 4.793665, Data Loss: 4.790428, Physics Loss: 0.000324\n",
      "Epoch 1086/2000, Total Loss: 4.793906, Data Loss: 4.790780, Physics Loss: 0.000313\n",
      "Epoch 1087/2000, Total Loss: 4.793727, Data Loss: 4.790504, Physics Loss: 0.000322\n",
      "Epoch 1088/2000, Total Loss: 4.793536, Data Loss: 4.790617, Physics Loss: 0.000292\n",
      "Epoch 1089/2000, Total Loss: 4.792869, Data Loss: 4.790077, Physics Loss: 0.000279\n",
      "Epoch 1090/2000, Total Loss: 4.792173, Data Loss: 4.789824, Physics Loss: 0.000235\n",
      "Epoch 1091/2000, Total Loss: 4.791534, Data Loss: 4.789400, Physics Loss: 0.000213\n",
      "Epoch 1092/2000, Total Loss: 4.791193, Data Loss: 4.789249, Physics Loss: 0.000194\n",
      "Epoch 1093/2000, Total Loss: 4.791195, Data Loss: 4.789254, Physics Loss: 0.000194\n",
      "Epoch 1094/2000, Total Loss: 4.791445, Data Loss: 4.789357, Physics Loss: 0.000209\n",
      "Epoch 1095/2000, Total Loss: 4.791728, Data Loss: 4.789559, Physics Loss: 0.000217\n",
      "Epoch 1096/2000, Total Loss: 4.791813, Data Loss: 4.789524, Physics Loss: 0.000229\n",
      "Epoch 1097/2000, Total Loss: 4.791668, Data Loss: 4.789512, Physics Loss: 0.000216\n",
      "Epoch 1098/2000, Total Loss: 4.791368, Data Loss: 4.789274, Physics Loss: 0.000209\n",
      "Epoch 1099/2000, Total Loss: 4.791124, Data Loss: 4.789165, Physics Loss: 0.000196\n",
      "Epoch 1100/2000, Total Loss: 4.791041, Data Loss: 4.789096, Physics Loss: 0.000195\n",
      "Epoch 1101/2000, Total Loss: 4.791092, Data Loss: 4.789104, Physics Loss: 0.000199\n",
      "Epoch 1102/2000, Total Loss: 4.791171, Data Loss: 4.789163, Physics Loss: 0.000201\n",
      "Epoch 1103/2000, Total Loss: 4.791242, Data Loss: 4.789147, Physics Loss: 0.000209\n",
      "Epoch 1104/2000, Total Loss: 4.791278, Data Loss: 4.789206, Physics Loss: 0.000207\n",
      "Epoch 1105/2000, Total Loss: 4.791261, Data Loss: 4.789132, Physics Loss: 0.000213\n",
      "Epoch 1106/2000, Total Loss: 4.791186, Data Loss: 4.789127, Physics Loss: 0.000206\n",
      "Epoch 1107/2000, Total Loss: 4.791096, Data Loss: 4.789023, Physics Loss: 0.000207\n",
      "Epoch 1108/2000, Total Loss: 4.791001, Data Loss: 4.788998, Physics Loss: 0.000200\n",
      "Epoch 1109/2000, Total Loss: 4.790930, Data Loss: 4.788922, Physics Loss: 0.000201\n",
      "Epoch 1110/2000, Total Loss: 4.790891, Data Loss: 4.788903, Physics Loss: 0.000199\n",
      "Epoch 1111/2000, Total Loss: 4.790886, Data Loss: 4.788895, Physics Loss: 0.000199\n",
      "Epoch 1112/2000, Total Loss: 4.790923, Data Loss: 4.788888, Physics Loss: 0.000204\n",
      "Epoch 1113/2000, Total Loss: 4.790975, Data Loss: 4.788938, Physics Loss: 0.000204\n",
      "Epoch 1114/2000, Total Loss: 4.791042, Data Loss: 4.788928, Physics Loss: 0.000211\n",
      "Epoch 1115/2000, Total Loss: 4.791100, Data Loss: 4.789001, Physics Loss: 0.000210\n",
      "Epoch 1116/2000, Total Loss: 4.791135, Data Loss: 4.788955, Physics Loss: 0.000218\n",
      "Epoch 1117/2000, Total Loss: 4.791167, Data Loss: 4.789022, Physics Loss: 0.000215\n",
      "Epoch 1118/2000, Total Loss: 4.791204, Data Loss: 4.788978, Physics Loss: 0.000223\n",
      "Epoch 1119/2000, Total Loss: 4.791235, Data Loss: 4.789053, Physics Loss: 0.000218\n",
      "Epoch 1120/2000, Total Loss: 4.791232, Data Loss: 4.788980, Physics Loss: 0.000225\n",
      "Epoch 1121/2000, Total Loss: 4.791220, Data Loss: 4.789045, Physics Loss: 0.000217\n",
      "Epoch 1122/2000, Total Loss: 4.791193, Data Loss: 4.788959, Physics Loss: 0.000223\n",
      "Epoch 1123/2000, Total Loss: 4.791149, Data Loss: 4.789005, Physics Loss: 0.000214\n",
      "Epoch 1124/2000, Total Loss: 4.791073, Data Loss: 4.788895, Physics Loss: 0.000218\n",
      "Epoch 1125/2000, Total Loss: 4.790976, Data Loss: 4.788893, Physics Loss: 0.000208\n",
      "Epoch 1126/2000, Total Loss: 4.790883, Data Loss: 4.788791, Physics Loss: 0.000209\n",
      "Epoch 1127/2000, Total Loss: 4.790799, Data Loss: 4.788774, Physics Loss: 0.000202\n",
      "Epoch 1128/2000, Total Loss: 4.790732, Data Loss: 4.788716, Physics Loss: 0.000202\n",
      "Epoch 1129/2000, Total Loss: 4.790687, Data Loss: 4.788697, Physics Loss: 0.000199\n",
      "Epoch 1130/2000, Total Loss: 4.790667, Data Loss: 4.788674, Physics Loss: 0.000199\n",
      "Epoch 1131/2000, Total Loss: 4.790662, Data Loss: 4.788668, Physics Loss: 0.000199\n",
      "Epoch 1132/2000, Total Loss: 4.790649, Data Loss: 4.788657, Physics Loss: 0.000199\n",
      "Epoch 1133/2000, Total Loss: 4.790659, Data Loss: 4.788642, Physics Loss: 0.000202\n",
      "Epoch 1134/2000, Total Loss: 4.790675, Data Loss: 4.788666, Physics Loss: 0.000201\n",
      "Epoch 1135/2000, Total Loss: 4.790707, Data Loss: 4.788647, Physics Loss: 0.000206\n",
      "Epoch 1136/2000, Total Loss: 4.790754, Data Loss: 4.788699, Physics Loss: 0.000206\n",
      "Epoch 1137/2000, Total Loss: 4.790798, Data Loss: 4.788680, Physics Loss: 0.000212\n",
      "Epoch 1138/2000, Total Loss: 4.790833, Data Loss: 4.788734, Physics Loss: 0.000210\n",
      "Epoch 1139/2000, Total Loss: 4.790891, Data Loss: 4.788707, Physics Loss: 0.000218\n",
      "Epoch 1140/2000, Total Loss: 4.790938, Data Loss: 4.788786, Physics Loss: 0.000215\n",
      "Epoch 1141/2000, Total Loss: 4.791004, Data Loss: 4.788751, Physics Loss: 0.000225\n",
      "Epoch 1142/2000, Total Loss: 4.791108, Data Loss: 4.788886, Physics Loss: 0.000222\n",
      "Epoch 1143/2000, Total Loss: 4.791253, Data Loss: 4.788867, Physics Loss: 0.000239\n",
      "Epoch 1144/2000, Total Loss: 4.791480, Data Loss: 4.789086, Physics Loss: 0.000239\n",
      "Epoch 1145/2000, Total Loss: 4.791693, Data Loss: 4.789087, Physics Loss: 0.000261\n",
      "Epoch 1146/2000, Total Loss: 4.791999, Data Loss: 4.789370, Physics Loss: 0.000263\n",
      "Epoch 1147/2000, Total Loss: 4.792268, Data Loss: 4.789392, Physics Loss: 0.000288\n",
      "Epoch 1148/2000, Total Loss: 4.792648, Data Loss: 4.789769, Physics Loss: 0.000288\n",
      "Epoch 1149/2000, Total Loss: 4.792848, Data Loss: 4.789703, Physics Loss: 0.000315\n",
      "Epoch 1150/2000, Total Loss: 4.793267, Data Loss: 4.790156, Physics Loss: 0.000311\n",
      "Epoch 1151/2000, Total Loss: 4.793367, Data Loss: 4.789982, Physics Loss: 0.000338\n",
      "Epoch 1152/2000, Total Loss: 4.793533, Data Loss: 4.790334, Physics Loss: 0.000320\n",
      "Epoch 1153/2000, Total Loss: 4.793102, Data Loss: 4.789894, Physics Loss: 0.000321\n",
      "Epoch 1154/2000, Total Loss: 4.792582, Data Loss: 4.789800, Physics Loss: 0.000278\n",
      "Epoch 1155/2000, Total Loss: 4.791735, Data Loss: 4.789199, Physics Loss: 0.000254\n",
      "Epoch 1156/2000, Total Loss: 4.791005, Data Loss: 4.788906, Physics Loss: 0.000210\n",
      "Epoch 1157/2000, Total Loss: 4.790561, Data Loss: 4.788611, Physics Loss: 0.000195\n",
      "Epoch 1158/2000, Total Loss: 4.790521, Data Loss: 4.788591, Physics Loss: 0.000193\n",
      "Epoch 1159/2000, Total Loss: 4.790773, Data Loss: 4.788760, Physics Loss: 0.000201\n",
      "Epoch 1160/2000, Total Loss: 4.791074, Data Loss: 4.788873, Physics Loss: 0.000220\n",
      "Epoch 1161/2000, Total Loss: 4.791198, Data Loss: 4.789013, Physics Loss: 0.000219\n",
      "Epoch 1162/2000, Total Loss: 4.791064, Data Loss: 4.788841, Physics Loss: 0.000222\n",
      "Epoch 1163/2000, Total Loss: 4.790784, Data Loss: 4.788739, Physics Loss: 0.000205\n",
      "Epoch 1164/2000, Total Loss: 4.790512, Data Loss: 4.788527, Physics Loss: 0.000198\n",
      "Epoch 1165/2000, Total Loss: 4.790386, Data Loss: 4.788464, Physics Loss: 0.000192\n",
      "Epoch 1166/2000, Total Loss: 4.790469, Data Loss: 4.788515, Physics Loss: 0.000195\n",
      "Epoch 1167/2000, Total Loss: 4.790655, Data Loss: 4.788563, Physics Loss: 0.000209\n",
      "Epoch 1168/2000, Total Loss: 4.790796, Data Loss: 4.788688, Physics Loss: 0.000211\n",
      "Epoch 1169/2000, Total Loss: 4.790809, Data Loss: 4.788611, Physics Loss: 0.000220\n",
      "Epoch 1170/2000, Total Loss: 4.790693, Data Loss: 4.788608, Physics Loss: 0.000209\n",
      "Epoch 1171/2000, Total Loss: 4.790509, Data Loss: 4.788434, Physics Loss: 0.000207\n",
      "Epoch 1172/2000, Total Loss: 4.790351, Data Loss: 4.788378, Physics Loss: 0.000197\n",
      "Epoch 1173/2000, Total Loss: 4.790277, Data Loss: 4.788305, Physics Loss: 0.000197\n",
      "Epoch 1174/2000, Total Loss: 4.790276, Data Loss: 4.788294, Physics Loss: 0.000198\n",
      "Epoch 1175/2000, Total Loss: 4.790351, Data Loss: 4.788346, Physics Loss: 0.000201\n",
      "Epoch 1176/2000, Total Loss: 4.790452, Data Loss: 4.788348, Physics Loss: 0.000210\n",
      "Epoch 1177/2000, Total Loss: 4.790525, Data Loss: 4.788438, Physics Loss: 0.000209\n",
      "Epoch 1178/2000, Total Loss: 4.790576, Data Loss: 4.788400, Physics Loss: 0.000218\n",
      "Epoch 1179/2000, Total Loss: 4.790596, Data Loss: 4.788475, Physics Loss: 0.000212\n",
      "Epoch 1180/2000, Total Loss: 4.790552, Data Loss: 4.788371, Physics Loss: 0.000218\n",
      "Epoch 1181/2000, Total Loss: 4.790469, Data Loss: 4.788378, Physics Loss: 0.000209\n",
      "Epoch 1182/2000, Total Loss: 4.790387, Data Loss: 4.788274, Physics Loss: 0.000211\n",
      "Epoch 1183/2000, Total Loss: 4.790302, Data Loss: 4.788275, Physics Loss: 0.000203\n",
      "Epoch 1184/2000, Total Loss: 4.790229, Data Loss: 4.788195, Physics Loss: 0.000203\n",
      "Epoch 1185/2000, Total Loss: 4.790164, Data Loss: 4.788177, Physics Loss: 0.000199\n",
      "Epoch 1186/2000, Total Loss: 4.790134, Data Loss: 4.788150, Physics Loss: 0.000198\n",
      "Epoch 1187/2000, Total Loss: 4.790151, Data Loss: 4.788144, Physics Loss: 0.000201\n",
      "Epoch 1188/2000, Total Loss: 4.790198, Data Loss: 4.788191, Physics Loss: 0.000201\n",
      "Epoch 1189/2000, Total Loss: 4.790254, Data Loss: 4.788180, Physics Loss: 0.000207\n",
      "Epoch 1190/2000, Total Loss: 4.790309, Data Loss: 4.788241, Physics Loss: 0.000207\n",
      "Epoch 1191/2000, Total Loss: 4.790368, Data Loss: 4.788221, Physics Loss: 0.000215\n",
      "Epoch 1192/2000, Total Loss: 4.790396, Data Loss: 4.788288, Physics Loss: 0.000211\n",
      "Epoch 1193/2000, Total Loss: 4.790418, Data Loss: 4.788229, Physics Loss: 0.000219\n",
      "Epoch 1194/2000, Total Loss: 4.790447, Data Loss: 4.788319, Physics Loss: 0.000213\n",
      "Epoch 1195/2000, Total Loss: 4.790464, Data Loss: 4.788257, Physics Loss: 0.000221\n",
      "Epoch 1196/2000, Total Loss: 4.790454, Data Loss: 4.788319, Physics Loss: 0.000213\n",
      "Epoch 1197/2000, Total Loss: 4.790441, Data Loss: 4.788232, Physics Loss: 0.000221\n",
      "Epoch 1198/2000, Total Loss: 4.790449, Data Loss: 4.788295, Physics Loss: 0.000215\n",
      "Epoch 1199/2000, Total Loss: 4.790468, Data Loss: 4.788234, Physics Loss: 0.000223\n",
      "Epoch 1200/2000, Total Loss: 4.790501, Data Loss: 4.788321, Physics Loss: 0.000218\n",
      "Epoch 1201/2000, Total Loss: 4.790563, Data Loss: 4.788278, Physics Loss: 0.000228\n",
      "Epoch 1202/2000, Total Loss: 4.790646, Data Loss: 4.788414, Physics Loss: 0.000223\n",
      "Epoch 1203/2000, Total Loss: 4.790683, Data Loss: 4.788334, Physics Loss: 0.000235\n",
      "Epoch 1204/2000, Total Loss: 4.790671, Data Loss: 4.788427, Physics Loss: 0.000224\n",
      "Epoch 1205/2000, Total Loss: 4.790580, Data Loss: 4.788282, Physics Loss: 0.000230\n",
      "Epoch 1206/2000, Total Loss: 4.790475, Data Loss: 4.788310, Physics Loss: 0.000217\n",
      "Epoch 1207/2000, Total Loss: 4.790346, Data Loss: 4.788163, Physics Loss: 0.000218\n",
      "Epoch 1208/2000, Total Loss: 4.790219, Data Loss: 4.788143, Physics Loss: 0.000208\n",
      "Epoch 1209/2000, Total Loss: 4.790115, Data Loss: 4.788042, Physics Loss: 0.000207\n",
      "Epoch 1210/2000, Total Loss: 4.790018, Data Loss: 4.788018, Physics Loss: 0.000200\n",
      "Epoch 1211/2000, Total Loss: 4.789953, Data Loss: 4.787951, Physics Loss: 0.000200\n",
      "Epoch 1212/2000, Total Loss: 4.789905, Data Loss: 4.787942, Physics Loss: 0.000196\n",
      "Epoch 1213/2000, Total Loss: 4.789889, Data Loss: 4.787916, Physics Loss: 0.000197\n",
      "Epoch 1214/2000, Total Loss: 4.789880, Data Loss: 4.787905, Physics Loss: 0.000197\n",
      "Epoch 1215/2000, Total Loss: 4.789869, Data Loss: 4.787900, Physics Loss: 0.000197\n",
      "Epoch 1216/2000, Total Loss: 4.789869, Data Loss: 4.787881, Physics Loss: 0.000199\n",
      "Epoch 1217/2000, Total Loss: 4.789875, Data Loss: 4.787892, Physics Loss: 0.000198\n",
      "Epoch 1218/2000, Total Loss: 4.789891, Data Loss: 4.787874, Physics Loss: 0.000202\n",
      "Epoch 1219/2000, Total Loss: 4.789906, Data Loss: 4.787900, Physics Loss: 0.000201\n",
      "Epoch 1220/2000, Total Loss: 4.789941, Data Loss: 4.787875, Physics Loss: 0.000207\n",
      "Epoch 1221/2000, Total Loss: 4.789964, Data Loss: 4.787924, Physics Loss: 0.000204\n",
      "Epoch 1222/2000, Total Loss: 4.790004, Data Loss: 4.787893, Physics Loss: 0.000211\n",
      "Epoch 1223/2000, Total Loss: 4.790048, Data Loss: 4.787970, Physics Loss: 0.000208\n",
      "Epoch 1224/2000, Total Loss: 4.790093, Data Loss: 4.787932, Physics Loss: 0.000216\n",
      "Epoch 1225/2000, Total Loss: 4.790158, Data Loss: 4.788035, Physics Loss: 0.000212\n",
      "Epoch 1226/2000, Total Loss: 4.790255, Data Loss: 4.787992, Physics Loss: 0.000226\n",
      "Epoch 1227/2000, Total Loss: 4.790431, Data Loss: 4.788155, Physics Loss: 0.000228\n",
      "Epoch 1228/2000, Total Loss: 4.790648, Data Loss: 4.788174, Physics Loss: 0.000247\n",
      "Epoch 1229/2000, Total Loss: 4.790953, Data Loss: 4.788447, Physics Loss: 0.000251\n",
      "Epoch 1230/2000, Total Loss: 4.791344, Data Loss: 4.788539, Physics Loss: 0.000281\n",
      "Epoch 1231/2000, Total Loss: 4.792013, Data Loss: 4.789082, Physics Loss: 0.000293\n",
      "Epoch 1232/2000, Total Loss: 4.792722, Data Loss: 4.789263, Physics Loss: 0.000346\n",
      "Epoch 1233/2000, Total Loss: 4.793866, Data Loss: 4.790175, Physics Loss: 0.000369\n",
      "Epoch 1234/2000, Total Loss: 4.794648, Data Loss: 4.790289, Physics Loss: 0.000436\n",
      "Epoch 1235/2000, Total Loss: 4.795976, Data Loss: 4.791451, Physics Loss: 0.000452\n",
      "Epoch 1236/2000, Total Loss: 4.795873, Data Loss: 4.790970, Physics Loss: 0.000490\n",
      "Epoch 1237/2000, Total Loss: 4.795640, Data Loss: 4.791307, Physics Loss: 0.000433\n",
      "Epoch 1238/2000, Total Loss: 4.793537, Data Loss: 4.789865, Physics Loss: 0.000367\n",
      "Epoch 1239/2000, Total Loss: 4.791393, Data Loss: 4.788915, Physics Loss: 0.000248\n",
      "Epoch 1240/2000, Total Loss: 4.789983, Data Loss: 4.788040, Physics Loss: 0.000194\n",
      "Epoch 1241/2000, Total Loss: 4.790241, Data Loss: 4.788184, Physics Loss: 0.000206\n",
      "Epoch 1242/2000, Total Loss: 4.791417, Data Loss: 4.788959, Physics Loss: 0.000246\n",
      "Epoch 1243/2000, Total Loss: 4.791818, Data Loss: 4.789095, Physics Loss: 0.000272\n",
      "Epoch 1244/2000, Total Loss: 4.791094, Data Loss: 4.788776, Physics Loss: 0.000232\n",
      "Epoch 1245/2000, Total Loss: 4.790041, Data Loss: 4.788087, Physics Loss: 0.000195\n",
      "Epoch 1246/2000, Total Loss: 4.789949, Data Loss: 4.788025, Physics Loss: 0.000192\n",
      "Epoch 1247/2000, Total Loss: 4.790605, Data Loss: 4.788459, Physics Loss: 0.000215\n",
      "Epoch 1248/2000, Total Loss: 4.790869, Data Loss: 4.788518, Physics Loss: 0.000235\n",
      "Epoch 1249/2000, Total Loss: 4.790449, Data Loss: 4.788362, Physics Loss: 0.000209\n",
      "Epoch 1250/2000, Total Loss: 4.789838, Data Loss: 4.787912, Physics Loss: 0.000193\n",
      "Epoch 1251/2000, Total Loss: 4.789771, Data Loss: 4.787865, Physics Loss: 0.000191\n",
      "Epoch 1252/2000, Total Loss: 4.790152, Data Loss: 4.788131, Physics Loss: 0.000202\n",
      "Epoch 1253/2000, Total Loss: 4.790399, Data Loss: 4.788173, Physics Loss: 0.000223\n",
      "Epoch 1254/2000, Total Loss: 4.790219, Data Loss: 4.788135, Physics Loss: 0.000208\n",
      "Epoch 1255/2000, Total Loss: 4.789824, Data Loss: 4.787825, Physics Loss: 0.000200\n",
      "Epoch 1256/2000, Total Loss: 4.789607, Data Loss: 4.787706, Physics Loss: 0.000190\n",
      "Epoch 1257/2000, Total Loss: 4.789702, Data Loss: 4.787768, Physics Loss: 0.000193\n",
      "Epoch 1258/2000, Total Loss: 4.789914, Data Loss: 4.787818, Physics Loss: 0.000210\n",
      "Epoch 1259/2000, Total Loss: 4.789988, Data Loss: 4.787923, Physics Loss: 0.000206\n",
      "Epoch 1260/2000, Total Loss: 4.789869, Data Loss: 4.787761, Physics Loss: 0.000211\n",
      "Epoch 1261/2000, Total Loss: 4.789656, Data Loss: 4.787679, Physics Loss: 0.000198\n",
      "Epoch 1262/2000, Total Loss: 4.789536, Data Loss: 4.787574, Physics Loss: 0.000196\n",
      "Epoch 1263/2000, Total Loss: 4.789572, Data Loss: 4.787575, Physics Loss: 0.000200\n",
      "Epoch 1264/2000, Total Loss: 4.789669, Data Loss: 4.787652, Physics Loss: 0.000202\n",
      "Epoch 1265/2000, Total Loss: 4.789729, Data Loss: 4.787631, Physics Loss: 0.000210\n",
      "Epoch 1266/2000, Total Loss: 4.789699, Data Loss: 4.787649, Physics Loss: 0.000205\n",
      "Epoch 1267/2000, Total Loss: 4.789620, Data Loss: 4.787562, Physics Loss: 0.000206\n",
      "Epoch 1268/2000, Total Loss: 4.789525, Data Loss: 4.787533, Physics Loss: 0.000199\n",
      "Epoch 1269/2000, Total Loss: 4.789477, Data Loss: 4.787491, Physics Loss: 0.000199\n",
      "Epoch 1270/2000, Total Loss: 4.789501, Data Loss: 4.787490, Physics Loss: 0.000201\n",
      "Epoch 1271/2000, Total Loss: 4.789576, Data Loss: 4.787562, Physics Loss: 0.000201\n",
      "Epoch 1272/2000, Total Loss: 4.789660, Data Loss: 4.787561, Physics Loss: 0.000210\n",
      "Epoch 1273/2000, Total Loss: 4.789662, Data Loss: 4.787617, Physics Loss: 0.000205\n",
      "Epoch 1274/2000, Total Loss: 4.789583, Data Loss: 4.787516, Physics Loss: 0.000207\n",
      "Epoch 1275/2000, Total Loss: 4.789470, Data Loss: 4.787484, Physics Loss: 0.000199\n",
      "Epoch 1276/2000, Total Loss: 4.789411, Data Loss: 4.787431, Physics Loss: 0.000198\n",
      "Epoch 1277/2000, Total Loss: 4.789416, Data Loss: 4.787423, Physics Loss: 0.000199\n",
      "Epoch 1278/2000, Total Loss: 4.789466, Data Loss: 4.787474, Physics Loss: 0.000199\n",
      "Epoch 1279/2000, Total Loss: 4.789511, Data Loss: 4.787457, Physics Loss: 0.000205\n",
      "Epoch 1280/2000, Total Loss: 4.789518, Data Loss: 4.787494, Physics Loss: 0.000202\n",
      "Epoch 1281/2000, Total Loss: 4.789484, Data Loss: 4.787428, Physics Loss: 0.000206\n",
      "Epoch 1282/2000, Total Loss: 4.789422, Data Loss: 4.787423, Physics Loss: 0.000200\n",
      "Epoch 1283/2000, Total Loss: 4.789364, Data Loss: 4.787366, Physics Loss: 0.000200\n",
      "Epoch 1284/2000, Total Loss: 4.789333, Data Loss: 4.787348, Physics Loss: 0.000198\n",
      "Epoch 1285/2000, Total Loss: 4.789330, Data Loss: 4.787345, Physics Loss: 0.000198\n",
      "Epoch 1286/2000, Total Loss: 4.789355, Data Loss: 4.787343, Physics Loss: 0.000201\n",
      "Epoch 1287/2000, Total Loss: 4.789383, Data Loss: 4.787369, Physics Loss: 0.000201\n",
      "Epoch 1288/2000, Total Loss: 4.789407, Data Loss: 4.787350, Physics Loss: 0.000206\n",
      "Epoch 1289/2000, Total Loss: 4.789441, Data Loss: 4.787415, Physics Loss: 0.000203\n",
      "Epoch 1290/2000, Total Loss: 4.789450, Data Loss: 4.787373, Physics Loss: 0.000208\n",
      "Epoch 1291/2000, Total Loss: 4.789396, Data Loss: 4.787383, Physics Loss: 0.000201\n",
      "Epoch 1292/2000, Total Loss: 4.789327, Data Loss: 4.787296, Physics Loss: 0.000203\n",
      "Epoch 1293/2000, Total Loss: 4.789282, Data Loss: 4.787291, Physics Loss: 0.000199\n",
      "Epoch 1294/2000, Total Loss: 4.789264, Data Loss: 4.787261, Physics Loss: 0.000200\n",
      "Epoch 1295/2000, Total Loss: 4.789236, Data Loss: 4.787249, Physics Loss: 0.000199\n",
      "Epoch 1296/2000, Total Loss: 4.789217, Data Loss: 4.787231, Physics Loss: 0.000199\n",
      "Epoch 1297/2000, Total Loss: 4.789211, Data Loss: 4.787228, Physics Loss: 0.000198\n",
      "Epoch 1298/2000, Total Loss: 4.789204, Data Loss: 4.787218, Physics Loss: 0.000199\n",
      "Epoch 1299/2000, Total Loss: 4.789195, Data Loss: 4.787209, Physics Loss: 0.000199\n",
      "Epoch 1300/2000, Total Loss: 4.789179, Data Loss: 4.787198, Physics Loss: 0.000198\n",
      "Epoch 1301/2000, Total Loss: 4.789173, Data Loss: 4.787185, Physics Loss: 0.000199\n",
      "Epoch 1302/2000, Total Loss: 4.789166, Data Loss: 4.787179, Physics Loss: 0.000199\n",
      "Epoch 1303/2000, Total Loss: 4.789155, Data Loss: 4.787169, Physics Loss: 0.000199\n",
      "Epoch 1304/2000, Total Loss: 4.789152, Data Loss: 4.787153, Physics Loss: 0.000200\n",
      "Epoch 1305/2000, Total Loss: 4.789151, Data Loss: 4.787161, Physics Loss: 0.000199\n",
      "Epoch 1306/2000, Total Loss: 4.789151, Data Loss: 4.787141, Physics Loss: 0.000201\n",
      "Epoch 1307/2000, Total Loss: 4.789143, Data Loss: 4.787149, Physics Loss: 0.000199\n",
      "Epoch 1308/2000, Total Loss: 4.789139, Data Loss: 4.787124, Physics Loss: 0.000202\n",
      "Epoch 1309/2000, Total Loss: 4.789138, Data Loss: 4.787135, Physics Loss: 0.000200\n",
      "Epoch 1310/2000, Total Loss: 4.789149, Data Loss: 4.787115, Physics Loss: 0.000203\n",
      "Epoch 1311/2000, Total Loss: 4.789158, Data Loss: 4.787139, Physics Loss: 0.000202\n",
      "Epoch 1312/2000, Total Loss: 4.789173, Data Loss: 4.787112, Physics Loss: 0.000206\n",
      "Epoch 1313/2000, Total Loss: 4.789189, Data Loss: 4.787160, Physics Loss: 0.000203\n",
      "Epoch 1314/2000, Total Loss: 4.789212, Data Loss: 4.787123, Physics Loss: 0.000209\n",
      "Epoch 1315/2000, Total Loss: 4.789224, Data Loss: 4.787164, Physics Loss: 0.000206\n",
      "Epoch 1316/2000, Total Loss: 4.789243, Data Loss: 4.787131, Physics Loss: 0.000211\n",
      "Epoch 1317/2000, Total Loss: 4.789239, Data Loss: 4.787172, Physics Loss: 0.000207\n",
      "Epoch 1318/2000, Total Loss: 4.789218, Data Loss: 4.787111, Physics Loss: 0.000211\n",
      "Epoch 1319/2000, Total Loss: 4.789178, Data Loss: 4.787136, Physics Loss: 0.000204\n",
      "Epoch 1320/2000, Total Loss: 4.789152, Data Loss: 4.787073, Physics Loss: 0.000208\n",
      "Epoch 1321/2000, Total Loss: 4.789120, Data Loss: 4.787097, Physics Loss: 0.000202\n",
      "Epoch 1322/2000, Total Loss: 4.789092, Data Loss: 4.787038, Physics Loss: 0.000205\n",
      "Epoch 1323/2000, Total Loss: 4.789054, Data Loss: 4.787043, Physics Loss: 0.000201\n",
      "Epoch 1324/2000, Total Loss: 4.789043, Data Loss: 4.787006, Physics Loss: 0.000204\n",
      "Epoch 1325/2000, Total Loss: 4.789025, Data Loss: 4.787017, Physics Loss: 0.000201\n",
      "Epoch 1326/2000, Total Loss: 4.789011, Data Loss: 4.786983, Physics Loss: 0.000203\n",
      "Epoch 1327/2000, Total Loss: 4.788981, Data Loss: 4.786979, Physics Loss: 0.000200\n",
      "Epoch 1328/2000, Total Loss: 4.788969, Data Loss: 4.786957, Physics Loss: 0.000201\n",
      "Epoch 1329/2000, Total Loss: 4.788959, Data Loss: 4.786963, Physics Loss: 0.000200\n",
      "Epoch 1330/2000, Total Loss: 4.788953, Data Loss: 4.786943, Physics Loss: 0.000201\n",
      "Epoch 1331/2000, Total Loss: 4.788933, Data Loss: 4.786939, Physics Loss: 0.000199\n",
      "Epoch 1332/2000, Total Loss: 4.788917, Data Loss: 4.786916, Physics Loss: 0.000200\n",
      "Epoch 1333/2000, Total Loss: 4.788908, Data Loss: 4.786908, Physics Loss: 0.000200\n",
      "Epoch 1334/2000, Total Loss: 4.788905, Data Loss: 4.786908, Physics Loss: 0.000200\n",
      "Epoch 1335/2000, Total Loss: 4.788907, Data Loss: 4.786896, Physics Loss: 0.000201\n",
      "Epoch 1336/2000, Total Loss: 4.788893, Data Loss: 4.786892, Physics Loss: 0.000200\n",
      "Epoch 1337/2000, Total Loss: 4.788880, Data Loss: 4.786872, Physics Loss: 0.000201\n",
      "Epoch 1338/2000, Total Loss: 4.788873, Data Loss: 4.786868, Physics Loss: 0.000200\n",
      "Epoch 1339/2000, Total Loss: 4.788871, Data Loss: 4.786856, Physics Loss: 0.000201\n",
      "Epoch 1340/2000, Total Loss: 4.788867, Data Loss: 4.786853, Physics Loss: 0.000201\n",
      "Epoch 1341/2000, Total Loss: 4.788864, Data Loss: 4.786841, Physics Loss: 0.000202\n",
      "Epoch 1342/2000, Total Loss: 4.788867, Data Loss: 4.786851, Physics Loss: 0.000202\n",
      "Epoch 1343/2000, Total Loss: 4.788888, Data Loss: 4.786838, Physics Loss: 0.000205\n",
      "Epoch 1344/2000, Total Loss: 4.788908, Data Loss: 4.786878, Physics Loss: 0.000203\n",
      "Epoch 1345/2000, Total Loss: 4.788952, Data Loss: 4.786856, Physics Loss: 0.000210\n",
      "Epoch 1346/2000, Total Loss: 4.789019, Data Loss: 4.786934, Physics Loss: 0.000208\n",
      "Epoch 1347/2000, Total Loss: 4.789150, Data Loss: 4.786941, Physics Loss: 0.000221\n",
      "Epoch 1348/2000, Total Loss: 4.789379, Data Loss: 4.787138, Physics Loss: 0.000224\n",
      "Epoch 1349/2000, Total Loss: 4.789769, Data Loss: 4.787248, Physics Loss: 0.000252\n",
      "Epoch 1350/2000, Total Loss: 4.790449, Data Loss: 4.787758, Physics Loss: 0.000269\n",
      "Epoch 1351/2000, Total Loss: 4.791523, Data Loss: 4.788167, Physics Loss: 0.000336\n",
      "Epoch 1352/2000, Total Loss: 4.793671, Data Loss: 4.789668, Physics Loss: 0.000400\n",
      "Epoch 1353/2000, Total Loss: 4.796481, Data Loss: 4.790761, Physics Loss: 0.000572\n",
      "Epoch 1354/2000, Total Loss: 4.802114, Data Loss: 4.794635, Physics Loss: 0.000748\n",
      "Epoch 1355/2000, Total Loss: 4.805803, Data Loss: 4.795716, Physics Loss: 0.001009\n",
      "Epoch 1356/2000, Total Loss: 4.811883, Data Loss: 4.800894, Physics Loss: 0.001099\n",
      "Epoch 1357/2000, Total Loss: 4.805316, Data Loss: 4.795989, Physics Loss: 0.000933\n",
      "Epoch 1358/2000, Total Loss: 4.796389, Data Loss: 4.791963, Physics Loss: 0.000443\n",
      "Epoch 1359/2000, Total Loss: 4.789660, Data Loss: 4.787610, Physics Loss: 0.000205\n",
      "Epoch 1360/2000, Total Loss: 4.794137, Data Loss: 4.790303, Physics Loss: 0.000383\n",
      "Epoch 1361/2000, Total Loss: 4.797916, Data Loss: 4.793110, Physics Loss: 0.000481\n",
      "Epoch 1362/2000, Total Loss: 4.791651, Data Loss: 4.789097, Physics Loss: 0.000255\n",
      "Epoch 1363/2000, Total Loss: 4.791491, Data Loss: 4.788903, Physics Loss: 0.000259\n",
      "Epoch 1364/2000, Total Loss: 4.795300, Data Loss: 4.791570, Physics Loss: 0.000373\n",
      "Epoch 1365/2000, Total Loss: 4.791649, Data Loss: 4.789151, Physics Loss: 0.000250\n",
      "Epoch 1366/2000, Total Loss: 4.791011, Data Loss: 4.788534, Physics Loss: 0.000248\n",
      "Epoch 1367/2000, Total Loss: 4.793369, Data Loss: 4.790359, Physics Loss: 0.000301\n",
      "Epoch 1368/2000, Total Loss: 4.791229, Data Loss: 4.788836, Physics Loss: 0.000239\n",
      "Epoch 1369/2000, Total Loss: 4.790725, Data Loss: 4.788420, Physics Loss: 0.000231\n",
      "Epoch 1370/2000, Total Loss: 4.791812, Data Loss: 4.789189, Physics Loss: 0.000262\n",
      "Epoch 1371/2000, Total Loss: 4.790717, Data Loss: 4.788543, Physics Loss: 0.000217\n",
      "Epoch 1372/2000, Total Loss: 4.790397, Data Loss: 4.788181, Physics Loss: 0.000222\n",
      "Epoch 1373/2000, Total Loss: 4.790767, Data Loss: 4.788409, Physics Loss: 0.000236\n",
      "Epoch 1374/2000, Total Loss: 4.790373, Data Loss: 4.788207, Physics Loss: 0.000217\n",
      "Epoch 1375/2000, Total Loss: 4.790135, Data Loss: 4.787990, Physics Loss: 0.000215\n",
      "Epoch 1376/2000, Total Loss: 4.790070, Data Loss: 4.787916, Physics Loss: 0.000215\n",
      "Epoch 1377/2000, Total Loss: 4.790130, Data Loss: 4.787954, Physics Loss: 0.000218\n",
      "Epoch 1378/2000, Total Loss: 4.789977, Data Loss: 4.787877, Physics Loss: 0.000210\n",
      "Epoch 1379/2000, Total Loss: 4.789549, Data Loss: 4.787454, Physics Loss: 0.000210\n",
      "Epoch 1380/2000, Total Loss: 4.789789, Data Loss: 4.787611, Physics Loss: 0.000218\n",
      "Epoch 1381/2000, Total Loss: 4.789984, Data Loss: 4.787841, Physics Loss: 0.000214\n",
      "Epoch 1382/2000, Total Loss: 4.789411, Data Loss: 4.787307, Physics Loss: 0.000210\n",
      "Epoch 1383/2000, Total Loss: 4.789343, Data Loss: 4.787209, Physics Loss: 0.000213\n",
      "Epoch 1384/2000, Total Loss: 4.789818, Data Loss: 4.787667, Physics Loss: 0.000215\n",
      "Epoch 1385/2000, Total Loss: 4.789465, Data Loss: 4.787313, Physics Loss: 0.000215\n",
      "Epoch 1386/2000, Total Loss: 4.789074, Data Loss: 4.786976, Physics Loss: 0.000210\n",
      "Epoch 1387/2000, Total Loss: 4.789565, Data Loss: 4.787441, Physics Loss: 0.000212\n",
      "Epoch 1388/2000, Total Loss: 4.789582, Data Loss: 4.787394, Physics Loss: 0.000219\n",
      "Epoch 1389/2000, Total Loss: 4.788968, Data Loss: 4.786941, Physics Loss: 0.000203\n",
      "Epoch 1390/2000, Total Loss: 4.789102, Data Loss: 4.787077, Physics Loss: 0.000202\n",
      "Epoch 1391/2000, Total Loss: 4.789458, Data Loss: 4.787305, Physics Loss: 0.000215\n",
      "Epoch 1392/2000, Total Loss: 4.789066, Data Loss: 4.787056, Physics Loss: 0.000201\n",
      "Epoch 1393/2000, Total Loss: 4.788837, Data Loss: 4.786878, Physics Loss: 0.000196\n",
      "Epoch 1394/2000, Total Loss: 4.789176, Data Loss: 4.787103, Physics Loss: 0.000207\n",
      "Epoch 1395/2000, Total Loss: 4.789133, Data Loss: 4.787142, Physics Loss: 0.000199\n",
      "Epoch 1396/2000, Total Loss: 4.788792, Data Loss: 4.786837, Physics Loss: 0.000196\n",
      "Epoch 1397/2000, Total Loss: 4.788894, Data Loss: 4.786912, Physics Loss: 0.000198\n",
      "Epoch 1398/2000, Total Loss: 4.789043, Data Loss: 4.787066, Physics Loss: 0.000198\n",
      "Epoch 1399/2000, Total Loss: 4.788853, Data Loss: 4.786863, Physics Loss: 0.000199\n",
      "Epoch 1400/2000, Total Loss: 4.788743, Data Loss: 4.786794, Physics Loss: 0.000195\n",
      "Epoch 1401/2000, Total Loss: 4.788859, Data Loss: 4.786900, Physics Loss: 0.000196\n",
      "Epoch 1402/2000, Total Loss: 4.788844, Data Loss: 4.786844, Physics Loss: 0.000200\n",
      "Epoch 1403/2000, Total Loss: 4.788724, Data Loss: 4.786766, Physics Loss: 0.000196\n",
      "Epoch 1404/2000, Total Loss: 4.788746, Data Loss: 4.786773, Physics Loss: 0.000197\n",
      "Epoch 1405/2000, Total Loss: 4.788764, Data Loss: 4.786766, Physics Loss: 0.000200\n",
      "Epoch 1406/2000, Total Loss: 4.788692, Data Loss: 4.786729, Physics Loss: 0.000196\n",
      "Epoch 1407/2000, Total Loss: 4.788686, Data Loss: 4.786702, Physics Loss: 0.000198\n",
      "Epoch 1408/2000, Total Loss: 4.788685, Data Loss: 4.786704, Physics Loss: 0.000198\n",
      "Epoch 1409/2000, Total Loss: 4.788649, Data Loss: 4.786693, Physics Loss: 0.000196\n",
      "Epoch 1410/2000, Total Loss: 4.788656, Data Loss: 4.786664, Physics Loss: 0.000199\n",
      "Epoch 1411/2000, Total Loss: 4.788662, Data Loss: 4.786676, Physics Loss: 0.000199\n",
      "Epoch 1412/2000, Total Loss: 4.788596, Data Loss: 4.786634, Physics Loss: 0.000196\n",
      "Epoch 1413/2000, Total Loss: 4.788564, Data Loss: 4.786604, Physics Loss: 0.000196\n",
      "Epoch 1414/2000, Total Loss: 4.788586, Data Loss: 4.786617, Physics Loss: 0.000197\n",
      "Epoch 1415/2000, Total Loss: 4.788579, Data Loss: 4.786604, Physics Loss: 0.000198\n",
      "Epoch 1416/2000, Total Loss: 4.788529, Data Loss: 4.786574, Physics Loss: 0.000195\n",
      "Epoch 1417/2000, Total Loss: 4.788520, Data Loss: 4.786561, Physics Loss: 0.000196\n",
      "Epoch 1418/2000, Total Loss: 4.788540, Data Loss: 4.786564, Physics Loss: 0.000198\n",
      "Epoch 1419/2000, Total Loss: 4.788518, Data Loss: 4.786551, Physics Loss: 0.000197\n",
      "Epoch 1420/2000, Total Loss: 4.788495, Data Loss: 4.786525, Physics Loss: 0.000197\n",
      "Epoch 1421/2000, Total Loss: 4.788509, Data Loss: 4.786540, Physics Loss: 0.000197\n",
      "Epoch 1422/2000, Total Loss: 4.788508, Data Loss: 4.786528, Physics Loss: 0.000198\n",
      "Epoch 1423/2000, Total Loss: 4.788479, Data Loss: 4.786503, Physics Loss: 0.000198\n",
      "Epoch 1424/2000, Total Loss: 4.788465, Data Loss: 4.786501, Physics Loss: 0.000196\n",
      "Epoch 1425/2000, Total Loss: 4.788472, Data Loss: 4.786489, Physics Loss: 0.000198\n",
      "Epoch 1426/2000, Total Loss: 4.788444, Data Loss: 4.786477, Physics Loss: 0.000197\n",
      "Epoch 1427/2000, Total Loss: 4.788425, Data Loss: 4.786461, Physics Loss: 0.000196\n",
      "Epoch 1428/2000, Total Loss: 4.788428, Data Loss: 4.786450, Physics Loss: 0.000198\n",
      "Epoch 1429/2000, Total Loss: 4.788422, Data Loss: 4.786458, Physics Loss: 0.000196\n",
      "Epoch 1430/2000, Total Loss: 4.788393, Data Loss: 4.786421, Physics Loss: 0.000197\n",
      "Epoch 1431/2000, Total Loss: 4.788392, Data Loss: 4.786417, Physics Loss: 0.000197\n",
      "Epoch 1432/2000, Total Loss: 4.788396, Data Loss: 4.786423, Physics Loss: 0.000197\n",
      "Epoch 1433/2000, Total Loss: 4.788372, Data Loss: 4.786392, Physics Loss: 0.000198\n",
      "Epoch 1434/2000, Total Loss: 4.788357, Data Loss: 4.786381, Physics Loss: 0.000198\n",
      "Epoch 1435/2000, Total Loss: 4.788362, Data Loss: 4.786385, Physics Loss: 0.000198\n",
      "Epoch 1436/2000, Total Loss: 4.788360, Data Loss: 4.786366, Physics Loss: 0.000199\n",
      "Epoch 1437/2000, Total Loss: 4.788347, Data Loss: 4.786365, Physics Loss: 0.000198\n",
      "Epoch 1438/2000, Total Loss: 4.788342, Data Loss: 4.786347, Physics Loss: 0.000199\n",
      "Epoch 1439/2000, Total Loss: 4.788335, Data Loss: 4.786343, Physics Loss: 0.000199\n",
      "Epoch 1440/2000, Total Loss: 4.788317, Data Loss: 4.786331, Physics Loss: 0.000199\n",
      "Epoch 1441/2000, Total Loss: 4.788306, Data Loss: 4.786315, Physics Loss: 0.000199\n",
      "Epoch 1442/2000, Total Loss: 4.788303, Data Loss: 4.786313, Physics Loss: 0.000199\n",
      "Epoch 1443/2000, Total Loss: 4.788290, Data Loss: 4.786300, Physics Loss: 0.000199\n",
      "Epoch 1444/2000, Total Loss: 4.788274, Data Loss: 4.786286, Physics Loss: 0.000199\n",
      "Epoch 1445/2000, Total Loss: 4.788270, Data Loss: 4.786282, Physics Loss: 0.000199\n",
      "Epoch 1446/2000, Total Loss: 4.788262, Data Loss: 4.786271, Physics Loss: 0.000199\n",
      "Epoch 1447/2000, Total Loss: 4.788252, Data Loss: 4.786264, Physics Loss: 0.000199\n",
      "Epoch 1448/2000, Total Loss: 4.788241, Data Loss: 4.786253, Physics Loss: 0.000199\n",
      "Epoch 1449/2000, Total Loss: 4.788235, Data Loss: 4.786242, Physics Loss: 0.000199\n",
      "Epoch 1450/2000, Total Loss: 4.788229, Data Loss: 4.786234, Physics Loss: 0.000199\n",
      "Epoch 1451/2000, Total Loss: 4.788218, Data Loss: 4.786223, Physics Loss: 0.000199\n",
      "Epoch 1452/2000, Total Loss: 4.788208, Data Loss: 4.786215, Physics Loss: 0.000199\n",
      "Epoch 1453/2000, Total Loss: 4.788201, Data Loss: 4.786205, Physics Loss: 0.000200\n",
      "Epoch 1454/2000, Total Loss: 4.788194, Data Loss: 4.786202, Physics Loss: 0.000199\n",
      "Epoch 1455/2000, Total Loss: 4.788184, Data Loss: 4.786189, Physics Loss: 0.000199\n",
      "Epoch 1456/2000, Total Loss: 4.788173, Data Loss: 4.786180, Physics Loss: 0.000199\n",
      "Epoch 1457/2000, Total Loss: 4.788167, Data Loss: 4.786175, Physics Loss: 0.000199\n",
      "Epoch 1458/2000, Total Loss: 4.788161, Data Loss: 4.786166, Physics Loss: 0.000200\n",
      "Epoch 1459/2000, Total Loss: 4.788154, Data Loss: 4.786159, Physics Loss: 0.000200\n",
      "Epoch 1460/2000, Total Loss: 4.788146, Data Loss: 4.786151, Physics Loss: 0.000200\n",
      "Epoch 1461/2000, Total Loss: 4.788141, Data Loss: 4.786140, Physics Loss: 0.000200\n",
      "Epoch 1462/2000, Total Loss: 4.788132, Data Loss: 4.786136, Physics Loss: 0.000200\n",
      "Epoch 1463/2000, Total Loss: 4.788126, Data Loss: 4.786123, Physics Loss: 0.000200\n",
      "Epoch 1464/2000, Total Loss: 4.788121, Data Loss: 4.786119, Physics Loss: 0.000200\n",
      "Epoch 1465/2000, Total Loss: 4.788111, Data Loss: 4.786107, Physics Loss: 0.000200\n",
      "Epoch 1466/2000, Total Loss: 4.788106, Data Loss: 4.786103, Physics Loss: 0.000200\n",
      "Epoch 1467/2000, Total Loss: 4.788101, Data Loss: 4.786098, Physics Loss: 0.000200\n",
      "Epoch 1468/2000, Total Loss: 4.788093, Data Loss: 4.786084, Physics Loss: 0.000201\n",
      "Epoch 1469/2000, Total Loss: 4.788089, Data Loss: 4.786088, Physics Loss: 0.000200\n",
      "Epoch 1470/2000, Total Loss: 4.788082, Data Loss: 4.786067, Physics Loss: 0.000201\n",
      "Epoch 1471/2000, Total Loss: 4.788071, Data Loss: 4.786058, Physics Loss: 0.000201\n",
      "Epoch 1472/2000, Total Loss: 4.788070, Data Loss: 4.786063, Physics Loss: 0.000201\n",
      "Epoch 1473/2000, Total Loss: 4.788061, Data Loss: 4.786045, Physics Loss: 0.000202\n",
      "Epoch 1474/2000, Total Loss: 4.788053, Data Loss: 4.786044, Physics Loss: 0.000201\n",
      "Epoch 1475/2000, Total Loss: 4.788043, Data Loss: 4.786030, Physics Loss: 0.000201\n",
      "Epoch 1476/2000, Total Loss: 4.788036, Data Loss: 4.786026, Physics Loss: 0.000201\n",
      "Epoch 1477/2000, Total Loss: 4.788030, Data Loss: 4.786021, Physics Loss: 0.000201\n",
      "Epoch 1478/2000, Total Loss: 4.788028, Data Loss: 4.786011, Physics Loss: 0.000202\n",
      "Epoch 1479/2000, Total Loss: 4.788021, Data Loss: 4.786012, Physics Loss: 0.000201\n",
      "Epoch 1480/2000, Total Loss: 4.788008, Data Loss: 4.785990, Physics Loss: 0.000202\n",
      "Epoch 1481/2000, Total Loss: 4.788002, Data Loss: 4.785987, Physics Loss: 0.000202\n",
      "Epoch 1482/2000, Total Loss: 4.787997, Data Loss: 4.785980, Physics Loss: 0.000202\n",
      "Epoch 1483/2000, Total Loss: 4.787989, Data Loss: 4.785971, Physics Loss: 0.000202\n",
      "Epoch 1484/2000, Total Loss: 4.787984, Data Loss: 4.785967, Physics Loss: 0.000202\n",
      "Epoch 1485/2000, Total Loss: 4.787978, Data Loss: 4.785958, Physics Loss: 0.000202\n",
      "Epoch 1486/2000, Total Loss: 4.787971, Data Loss: 4.785954, Physics Loss: 0.000202\n",
      "Epoch 1487/2000, Total Loss: 4.787963, Data Loss: 4.785945, Physics Loss: 0.000202\n",
      "Epoch 1488/2000, Total Loss: 4.787952, Data Loss: 4.785934, Physics Loss: 0.000202\n",
      "Epoch 1489/2000, Total Loss: 4.787948, Data Loss: 4.785927, Physics Loss: 0.000202\n",
      "Epoch 1490/2000, Total Loss: 4.787946, Data Loss: 4.785920, Physics Loss: 0.000203\n",
      "Epoch 1491/2000, Total Loss: 4.787937, Data Loss: 4.785917, Physics Loss: 0.000202\n",
      "Epoch 1492/2000, Total Loss: 4.787930, Data Loss: 4.785905, Physics Loss: 0.000203\n",
      "Epoch 1493/2000, Total Loss: 4.787923, Data Loss: 4.785902, Physics Loss: 0.000202\n",
      "Epoch 1494/2000, Total Loss: 4.787920, Data Loss: 4.785899, Physics Loss: 0.000202\n",
      "Epoch 1495/2000, Total Loss: 4.787935, Data Loss: 4.785892, Physics Loss: 0.000204\n",
      "Epoch 1496/2000, Total Loss: 4.787951, Data Loss: 4.785916, Physics Loss: 0.000203\n",
      "Epoch 1497/2000, Total Loss: 4.787976, Data Loss: 4.785904, Physics Loss: 0.000207\n",
      "Epoch 1498/2000, Total Loss: 4.787971, Data Loss: 4.785929, Physics Loss: 0.000204\n",
      "Epoch 1499/2000, Total Loss: 4.787933, Data Loss: 4.785877, Physics Loss: 0.000206\n",
      "Epoch 1500/2000, Total Loss: 4.787893, Data Loss: 4.785869, Physics Loss: 0.000202\n",
      "Epoch 1501/2000, Total Loss: 4.787871, Data Loss: 4.785843, Physics Loss: 0.000203\n",
      "Epoch 1502/2000, Total Loss: 4.787867, Data Loss: 4.785839, Physics Loss: 0.000203\n",
      "Epoch 1503/2000, Total Loss: 4.787876, Data Loss: 4.785851, Physics Loss: 0.000202\n",
      "Epoch 1504/2000, Total Loss: 4.787900, Data Loss: 4.785843, Physics Loss: 0.000206\n",
      "Epoch 1505/2000, Total Loss: 4.787905, Data Loss: 4.785873, Physics Loss: 0.000203\n",
      "Epoch 1506/2000, Total Loss: 4.787888, Data Loss: 4.785829, Physics Loss: 0.000206\n",
      "Epoch 1507/2000, Total Loss: 4.787847, Data Loss: 4.785822, Physics Loss: 0.000202\n",
      "Epoch 1508/2000, Total Loss: 4.787824, Data Loss: 4.785794, Physics Loss: 0.000203\n",
      "Epoch 1509/2000, Total Loss: 4.787825, Data Loss: 4.785789, Physics Loss: 0.000204\n",
      "Epoch 1510/2000, Total Loss: 4.787831, Data Loss: 4.785802, Physics Loss: 0.000203\n",
      "Epoch 1511/2000, Total Loss: 4.787842, Data Loss: 4.785787, Physics Loss: 0.000206\n",
      "Epoch 1512/2000, Total Loss: 4.787842, Data Loss: 4.785806, Physics Loss: 0.000204\n",
      "Epoch 1513/2000, Total Loss: 4.787836, Data Loss: 4.785774, Physics Loss: 0.000206\n",
      "Epoch 1514/2000, Total Loss: 4.787809, Data Loss: 4.785778, Physics Loss: 0.000203\n",
      "Epoch 1515/2000, Total Loss: 4.787789, Data Loss: 4.785749, Physics Loss: 0.000204\n",
      "Epoch 1516/2000, Total Loss: 4.787775, Data Loss: 4.785744, Physics Loss: 0.000203\n",
      "Epoch 1517/2000, Total Loss: 4.787768, Data Loss: 4.785734, Physics Loss: 0.000203\n",
      "Epoch 1518/2000, Total Loss: 4.787762, Data Loss: 4.785730, Physics Loss: 0.000203\n",
      "Epoch 1519/2000, Total Loss: 4.787760, Data Loss: 4.785728, Physics Loss: 0.000203\n",
      "Epoch 1520/2000, Total Loss: 4.787758, Data Loss: 4.785713, Physics Loss: 0.000205\n",
      "Epoch 1521/2000, Total Loss: 4.787758, Data Loss: 4.785727, Physics Loss: 0.000203\n",
      "Epoch 1522/2000, Total Loss: 4.787766, Data Loss: 4.785710, Physics Loss: 0.000206\n",
      "Epoch 1523/2000, Total Loss: 4.787776, Data Loss: 4.785734, Physics Loss: 0.000204\n",
      "Epoch 1524/2000, Total Loss: 4.787795, Data Loss: 4.785714, Physics Loss: 0.000208\n",
      "Epoch 1525/2000, Total Loss: 4.787812, Data Loss: 4.785749, Physics Loss: 0.000206\n",
      "Epoch 1526/2000, Total Loss: 4.787810, Data Loss: 4.785712, Physics Loss: 0.000210\n",
      "Epoch 1527/2000, Total Loss: 4.787789, Data Loss: 4.785733, Physics Loss: 0.000206\n",
      "Epoch 1528/2000, Total Loss: 4.787755, Data Loss: 4.785683, Physics Loss: 0.000207\n",
      "Epoch 1529/2000, Total Loss: 4.787735, Data Loss: 4.785700, Physics Loss: 0.000203\n",
      "Epoch 1530/2000, Total Loss: 4.787724, Data Loss: 4.785669, Physics Loss: 0.000205\n",
      "Epoch 1531/2000, Total Loss: 4.787697, Data Loss: 4.785662, Physics Loss: 0.000203\n",
      "Epoch 1532/2000, Total Loss: 4.787675, Data Loss: 4.785640, Physics Loss: 0.000203\n",
      "Epoch 1533/2000, Total Loss: 4.787673, Data Loss: 4.785635, Physics Loss: 0.000204\n",
      "Epoch 1534/2000, Total Loss: 4.787677, Data Loss: 4.785642, Physics Loss: 0.000204\n",
      "Epoch 1535/2000, Total Loss: 4.787698, Data Loss: 4.785634, Physics Loss: 0.000206\n",
      "Epoch 1536/2000, Total Loss: 4.787714, Data Loss: 4.785667, Physics Loss: 0.000205\n",
      "Epoch 1537/2000, Total Loss: 4.787727, Data Loss: 4.785635, Physics Loss: 0.000209\n",
      "Epoch 1538/2000, Total Loss: 4.787718, Data Loss: 4.785659, Physics Loss: 0.000206\n",
      "Epoch 1539/2000, Total Loss: 4.787703, Data Loss: 4.785618, Physics Loss: 0.000209\n",
      "Epoch 1540/2000, Total Loss: 4.787699, Data Loss: 4.785646, Physics Loss: 0.000205\n",
      "Epoch 1541/2000, Total Loss: 4.787701, Data Loss: 4.785613, Physics Loss: 0.000209\n",
      "Epoch 1542/2000, Total Loss: 4.787695, Data Loss: 4.785641, Physics Loss: 0.000205\n",
      "Epoch 1543/2000, Total Loss: 4.787692, Data Loss: 4.785605, Physics Loss: 0.000209\n",
      "Epoch 1544/2000, Total Loss: 4.787671, Data Loss: 4.785617, Physics Loss: 0.000205\n",
      "Epoch 1545/2000, Total Loss: 4.787660, Data Loss: 4.785581, Physics Loss: 0.000208\n",
      "Epoch 1546/2000, Total Loss: 4.787648, Data Loss: 4.785598, Physics Loss: 0.000205\n",
      "Epoch 1547/2000, Total Loss: 4.787636, Data Loss: 4.785563, Physics Loss: 0.000207\n",
      "Epoch 1548/2000, Total Loss: 4.787636, Data Loss: 4.785585, Physics Loss: 0.000205\n",
      "Epoch 1549/2000, Total Loss: 4.787637, Data Loss: 4.785555, Physics Loss: 0.000208\n",
      "Epoch 1550/2000, Total Loss: 4.787626, Data Loss: 4.785576, Physics Loss: 0.000205\n",
      "Epoch 1551/2000, Total Loss: 4.787631, Data Loss: 4.785542, Physics Loss: 0.000209\n",
      "Epoch 1552/2000, Total Loss: 4.787655, Data Loss: 4.785583, Physics Loss: 0.000207\n",
      "Epoch 1553/2000, Total Loss: 4.787677, Data Loss: 4.785560, Physics Loss: 0.000212\n",
      "Epoch 1554/2000, Total Loss: 4.787690, Data Loss: 4.785606, Physics Loss: 0.000208\n",
      "Epoch 1555/2000, Total Loss: 4.787693, Data Loss: 4.785564, Physics Loss: 0.000213\n",
      "Epoch 1556/2000, Total Loss: 4.787673, Data Loss: 4.785590, Physics Loss: 0.000208\n",
      "Epoch 1557/2000, Total Loss: 4.787652, Data Loss: 4.785539, Physics Loss: 0.000211\n",
      "Epoch 1558/2000, Total Loss: 4.787641, Data Loss: 4.785567, Physics Loss: 0.000207\n",
      "Epoch 1559/2000, Total Loss: 4.787639, Data Loss: 4.785529, Physics Loss: 0.000211\n",
      "Epoch 1560/2000, Total Loss: 4.787646, Data Loss: 4.785577, Physics Loss: 0.000207\n",
      "Epoch 1561/2000, Total Loss: 4.787649, Data Loss: 4.785526, Physics Loss: 0.000212\n",
      "Epoch 1562/2000, Total Loss: 4.787672, Data Loss: 4.785579, Physics Loss: 0.000209\n",
      "Epoch 1563/2000, Total Loss: 4.787704, Data Loss: 4.785549, Physics Loss: 0.000215\n",
      "Epoch 1564/2000, Total Loss: 4.787757, Data Loss: 4.785626, Physics Loss: 0.000213\n",
      "Epoch 1565/2000, Total Loss: 4.787813, Data Loss: 4.785601, Physics Loss: 0.000221\n",
      "Epoch 1566/2000, Total Loss: 4.787874, Data Loss: 4.785693, Physics Loss: 0.000218\n",
      "Epoch 1567/2000, Total Loss: 4.787955, Data Loss: 4.785667, Physics Loss: 0.000229\n",
      "Epoch 1568/2000, Total Loss: 4.788090, Data Loss: 4.785830, Physics Loss: 0.000226\n",
      "Epoch 1569/2000, Total Loss: 4.788182, Data Loss: 4.785785, Physics Loss: 0.000240\n",
      "Epoch 1570/2000, Total Loss: 4.788265, Data Loss: 4.785932, Physics Loss: 0.000233\n",
      "Epoch 1571/2000, Total Loss: 4.788284, Data Loss: 4.785835, Physics Loss: 0.000245\n",
      "Epoch 1572/2000, Total Loss: 4.788338, Data Loss: 4.785967, Physics Loss: 0.000237\n",
      "Epoch 1573/2000, Total Loss: 4.788358, Data Loss: 4.785887, Physics Loss: 0.000247\n",
      "Epoch 1574/2000, Total Loss: 4.788437, Data Loss: 4.786053, Physics Loss: 0.000238\n",
      "Epoch 1575/2000, Total Loss: 4.788448, Data Loss: 4.785945, Physics Loss: 0.000250\n",
      "Epoch 1576/2000, Total Loss: 4.788476, Data Loss: 4.786073, Physics Loss: 0.000240\n",
      "Epoch 1577/2000, Total Loss: 4.788405, Data Loss: 4.785916, Physics Loss: 0.000249\n",
      "Epoch 1578/2000, Total Loss: 4.788322, Data Loss: 4.785979, Physics Loss: 0.000234\n",
      "Epoch 1579/2000, Total Loss: 4.788167, Data Loss: 4.785800, Physics Loss: 0.000237\n",
      "Epoch 1580/2000, Total Loss: 4.787979, Data Loss: 4.785779, Physics Loss: 0.000220\n",
      "Epoch 1581/2000, Total Loss: 4.787748, Data Loss: 4.785580, Physics Loss: 0.000217\n",
      "Epoch 1582/2000, Total Loss: 4.787564, Data Loss: 4.785518, Physics Loss: 0.000205\n",
      "Epoch 1583/2000, Total Loss: 4.787453, Data Loss: 4.785424, Physics Loss: 0.000203\n",
      "Epoch 1584/2000, Total Loss: 4.787416, Data Loss: 4.785408, Physics Loss: 0.000201\n",
      "Epoch 1585/2000, Total Loss: 4.787435, Data Loss: 4.785425, Physics Loss: 0.000201\n",
      "Epoch 1586/2000, Total Loss: 4.787492, Data Loss: 4.785428, Physics Loss: 0.000206\n",
      "Epoch 1587/2000, Total Loss: 4.787589, Data Loss: 4.785513, Physics Loss: 0.000208\n",
      "Epoch 1588/2000, Total Loss: 4.787681, Data Loss: 4.785511, Physics Loss: 0.000217\n",
      "Epoch 1589/2000, Total Loss: 4.787762, Data Loss: 4.785604, Physics Loss: 0.000216\n",
      "Epoch 1590/2000, Total Loss: 4.787821, Data Loss: 4.785565, Physics Loss: 0.000226\n",
      "Epoch 1591/2000, Total Loss: 4.787851, Data Loss: 4.785659, Physics Loss: 0.000219\n",
      "Epoch 1592/2000, Total Loss: 4.787814, Data Loss: 4.785560, Physics Loss: 0.000225\n",
      "Epoch 1593/2000, Total Loss: 4.787749, Data Loss: 4.785596, Physics Loss: 0.000215\n",
      "Epoch 1594/2000, Total Loss: 4.787663, Data Loss: 4.785478, Physics Loss: 0.000219\n",
      "Epoch 1595/2000, Total Loss: 4.787598, Data Loss: 4.785488, Physics Loss: 0.000211\n",
      "Epoch 1596/2000, Total Loss: 4.787526, Data Loss: 4.785387, Physics Loss: 0.000214\n",
      "Epoch 1597/2000, Total Loss: 4.787457, Data Loss: 4.785379, Physics Loss: 0.000208\n",
      "Epoch 1598/2000, Total Loss: 4.787394, Data Loss: 4.785312, Physics Loss: 0.000208\n",
      "Epoch 1599/2000, Total Loss: 4.787354, Data Loss: 4.785312, Physics Loss: 0.000204\n",
      "Epoch 1600/2000, Total Loss: 4.787339, Data Loss: 4.785287, Physics Loss: 0.000205\n",
      "Epoch 1601/2000, Total Loss: 4.787322, Data Loss: 4.785278, Physics Loss: 0.000204\n",
      "Epoch 1602/2000, Total Loss: 4.787313, Data Loss: 4.785268, Physics Loss: 0.000205\n",
      "Epoch 1603/2000, Total Loss: 4.787332, Data Loss: 4.785266, Physics Loss: 0.000207\n",
      "Epoch 1604/2000, Total Loss: 4.787365, Data Loss: 4.785305, Physics Loss: 0.000206\n",
      "Epoch 1605/2000, Total Loss: 4.787415, Data Loss: 4.785298, Physics Loss: 0.000212\n",
      "Epoch 1606/2000, Total Loss: 4.787481, Data Loss: 4.785375, Physics Loss: 0.000211\n",
      "Epoch 1607/2000, Total Loss: 4.787556, Data Loss: 4.785351, Physics Loss: 0.000220\n",
      "Epoch 1608/2000, Total Loss: 4.787679, Data Loss: 4.785483, Physics Loss: 0.000220\n",
      "Epoch 1609/2000, Total Loss: 4.787827, Data Loss: 4.785483, Physics Loss: 0.000234\n",
      "Epoch 1610/2000, Total Loss: 4.788041, Data Loss: 4.785699, Physics Loss: 0.000234\n",
      "Epoch 1611/2000, Total Loss: 4.788272, Data Loss: 4.785738, Physics Loss: 0.000253\n",
      "Epoch 1612/2000, Total Loss: 4.788581, Data Loss: 4.786029, Physics Loss: 0.000255\n",
      "Epoch 1613/2000, Total Loss: 4.788809, Data Loss: 4.786037, Physics Loss: 0.000277\n",
      "Epoch 1614/2000, Total Loss: 4.789115, Data Loss: 4.786367, Physics Loss: 0.000275\n",
      "Epoch 1615/2000, Total Loss: 4.789251, Data Loss: 4.786263, Physics Loss: 0.000299\n",
      "Epoch 1616/2000, Total Loss: 4.789462, Data Loss: 4.786583, Physics Loss: 0.000288\n",
      "Epoch 1617/2000, Total Loss: 4.789310, Data Loss: 4.786318, Physics Loss: 0.000299\n",
      "Epoch 1618/2000, Total Loss: 4.789120, Data Loss: 4.786395, Physics Loss: 0.000273\n",
      "Epoch 1619/2000, Total Loss: 4.788602, Data Loss: 4.785960, Physics Loss: 0.000264\n",
      "Epoch 1620/2000, Total Loss: 4.788066, Data Loss: 4.785783, Physics Loss: 0.000228\n",
      "Epoch 1621/2000, Total Loss: 4.787554, Data Loss: 4.785412, Physics Loss: 0.000214\n",
      "Epoch 1622/2000, Total Loss: 4.787286, Data Loss: 4.785289, Physics Loss: 0.000200\n",
      "Epoch 1623/2000, Total Loss: 4.787349, Data Loss: 4.785333, Physics Loss: 0.000202\n",
      "Epoch 1624/2000, Total Loss: 4.787637, Data Loss: 4.785464, Physics Loss: 0.000217\n",
      "Epoch 1625/2000, Total Loss: 4.787992, Data Loss: 4.785735, Physics Loss: 0.000226\n",
      "Epoch 1626/2000, Total Loss: 4.788200, Data Loss: 4.785770, Physics Loss: 0.000243\n",
      "Epoch 1627/2000, Total Loss: 4.788245, Data Loss: 4.785890, Physics Loss: 0.000236\n",
      "Epoch 1628/2000, Total Loss: 4.787991, Data Loss: 4.785634, Physics Loss: 0.000236\n",
      "Epoch 1629/2000, Total Loss: 4.787672, Data Loss: 4.785523, Physics Loss: 0.000215\n",
      "Epoch 1630/2000, Total Loss: 4.787394, Data Loss: 4.785294, Physics Loss: 0.000210\n",
      "Epoch 1631/2000, Total Loss: 4.787236, Data Loss: 4.785224, Physics Loss: 0.000201\n",
      "Epoch 1632/2000, Total Loss: 4.787227, Data Loss: 4.785214, Physics Loss: 0.000201\n",
      "Epoch 1633/2000, Total Loss: 4.787346, Data Loss: 4.785254, Physics Loss: 0.000209\n",
      "Epoch 1634/2000, Total Loss: 4.787547, Data Loss: 4.785407, Physics Loss: 0.000214\n",
      "Epoch 1635/2000, Total Loss: 4.787742, Data Loss: 4.785455, Physics Loss: 0.000229\n",
      "Epoch 1636/2000, Total Loss: 4.787897, Data Loss: 4.785624, Physics Loss: 0.000227\n",
      "Epoch 1637/2000, Total Loss: 4.787872, Data Loss: 4.785512, Physics Loss: 0.000236\n",
      "Epoch 1638/2000, Total Loss: 4.787733, Data Loss: 4.785515, Physics Loss: 0.000222\n",
      "Epoch 1639/2000, Total Loss: 4.787530, Data Loss: 4.785312, Physics Loss: 0.000222\n",
      "Epoch 1640/2000, Total Loss: 4.787375, Data Loss: 4.785281, Physics Loss: 0.000209\n",
      "Epoch 1641/2000, Total Loss: 4.787255, Data Loss: 4.785157, Physics Loss: 0.000210\n",
      "Epoch 1642/2000, Total Loss: 4.787173, Data Loss: 4.785133, Physics Loss: 0.000204\n",
      "Epoch 1643/2000, Total Loss: 4.787129, Data Loss: 4.785094, Physics Loss: 0.000204\n",
      "Epoch 1644/2000, Total Loss: 4.787132, Data Loss: 4.785088, Physics Loss: 0.000204\n",
      "Epoch 1645/2000, Total Loss: 4.787173, Data Loss: 4.785121, Physics Loss: 0.000205\n",
      "Epoch 1646/2000, Total Loss: 4.787230, Data Loss: 4.785123, Physics Loss: 0.000211\n",
      "Epoch 1647/2000, Total Loss: 4.787290, Data Loss: 4.785201, Physics Loss: 0.000209\n",
      "Epoch 1648/2000, Total Loss: 4.787334, Data Loss: 4.785171, Physics Loss: 0.000216\n",
      "Epoch 1649/2000, Total Loss: 4.787352, Data Loss: 4.785239, Physics Loss: 0.000211\n",
      "Epoch 1650/2000, Total Loss: 4.787323, Data Loss: 4.785161, Physics Loss: 0.000216\n",
      "Epoch 1651/2000, Total Loss: 4.787302, Data Loss: 4.785193, Physics Loss: 0.000211\n",
      "Epoch 1652/2000, Total Loss: 4.787281, Data Loss: 4.785132, Physics Loss: 0.000215\n",
      "Epoch 1653/2000, Total Loss: 4.787264, Data Loss: 4.785168, Physics Loss: 0.000210\n",
      "Epoch 1654/2000, Total Loss: 4.787248, Data Loss: 4.785105, Physics Loss: 0.000214\n",
      "Epoch 1655/2000, Total Loss: 4.787248, Data Loss: 4.785144, Physics Loss: 0.000210\n",
      "Epoch 1656/2000, Total Loss: 4.787258, Data Loss: 4.785103, Physics Loss: 0.000216\n",
      "Epoch 1657/2000, Total Loss: 4.787296, Data Loss: 4.785178, Physics Loss: 0.000212\n",
      "Epoch 1658/2000, Total Loss: 4.787328, Data Loss: 4.785137, Physics Loss: 0.000219\n",
      "Epoch 1659/2000, Total Loss: 4.787333, Data Loss: 4.785202, Physics Loss: 0.000213\n",
      "Epoch 1660/2000, Total Loss: 4.787299, Data Loss: 4.785126, Physics Loss: 0.000217\n",
      "Epoch 1661/2000, Total Loss: 4.787254, Data Loss: 4.785151, Physics Loss: 0.000210\n",
      "Epoch 1662/2000, Total Loss: 4.787191, Data Loss: 4.785059, Physics Loss: 0.000213\n",
      "Epoch 1663/2000, Total Loss: 4.787142, Data Loss: 4.785063, Physics Loss: 0.000208\n",
      "Epoch 1664/2000, Total Loss: 4.787106, Data Loss: 4.785005, Physics Loss: 0.000210\n",
      "Epoch 1665/2000, Total Loss: 4.787084, Data Loss: 4.785012, Physics Loss: 0.000207\n",
      "Epoch 1666/2000, Total Loss: 4.787054, Data Loss: 4.784973, Physics Loss: 0.000208\n",
      "Epoch 1667/2000, Total Loss: 4.787035, Data Loss: 4.784986, Physics Loss: 0.000205\n",
      "Epoch 1668/2000, Total Loss: 4.787045, Data Loss: 4.784968, Physics Loss: 0.000208\n",
      "Epoch 1669/2000, Total Loss: 4.787048, Data Loss: 4.784996, Physics Loss: 0.000205\n",
      "Epoch 1670/2000, Total Loss: 4.787035, Data Loss: 4.784963, Physics Loss: 0.000207\n",
      "Epoch 1671/2000, Total Loss: 4.786989, Data Loss: 4.784939, Physics Loss: 0.000205\n",
      "Epoch 1672/2000, Total Loss: 4.786958, Data Loss: 4.784911, Physics Loss: 0.000205\n",
      "Epoch 1673/2000, Total Loss: 4.786962, Data Loss: 4.784909, Physics Loss: 0.000205\n",
      "Epoch 1674/2000, Total Loss: 4.786967, Data Loss: 4.784919, Physics Loss: 0.000205\n",
      "Epoch 1675/2000, Total Loss: 4.786974, Data Loss: 4.784905, Physics Loss: 0.000207\n",
      "Epoch 1676/2000, Total Loss: 4.786970, Data Loss: 4.784916, Physics Loss: 0.000205\n",
      "Epoch 1677/2000, Total Loss: 4.786973, Data Loss: 4.784890, Physics Loss: 0.000208\n",
      "Epoch 1678/2000, Total Loss: 4.786988, Data Loss: 4.784916, Physics Loss: 0.000207\n",
      "Epoch 1679/2000, Total Loss: 4.787011, Data Loss: 4.784902, Physics Loss: 0.000211\n",
      "Epoch 1680/2000, Total Loss: 4.787060, Data Loss: 4.784958, Physics Loss: 0.000210\n",
      "Epoch 1681/2000, Total Loss: 4.787116, Data Loss: 4.784944, Physics Loss: 0.000217\n",
      "Epoch 1682/2000, Total Loss: 4.787201, Data Loss: 4.785046, Physics Loss: 0.000216\n",
      "Epoch 1683/2000, Total Loss: 4.787304, Data Loss: 4.785039, Physics Loss: 0.000227\n",
      "Epoch 1684/2000, Total Loss: 4.787443, Data Loss: 4.785197, Physics Loss: 0.000225\n",
      "Epoch 1685/2000, Total Loss: 4.787607, Data Loss: 4.785199, Physics Loss: 0.000241\n",
      "Epoch 1686/2000, Total Loss: 4.787880, Data Loss: 4.785455, Physics Loss: 0.000243\n",
      "Epoch 1687/2000, Total Loss: 4.788239, Data Loss: 4.785542, Physics Loss: 0.000270\n",
      "Epoch 1688/2000, Total Loss: 4.788881, Data Loss: 4.786060, Physics Loss: 0.000282\n",
      "Epoch 1689/2000, Total Loss: 4.789514, Data Loss: 4.786249, Physics Loss: 0.000326\n",
      "Epoch 1690/2000, Total Loss: 4.790491, Data Loss: 4.787055, Physics Loss: 0.000344\n",
      "Epoch 1691/2000, Total Loss: 4.791036, Data Loss: 4.787092, Physics Loss: 0.000394\n",
      "Epoch 1692/2000, Total Loss: 4.791905, Data Loss: 4.787962, Physics Loss: 0.000394\n",
      "Epoch 1693/2000, Total Loss: 4.791710, Data Loss: 4.787550, Physics Loss: 0.000416\n",
      "Epoch 1694/2000, Total Loss: 4.791423, Data Loss: 4.787772, Physics Loss: 0.000365\n",
      "Epoch 1695/2000, Total Loss: 4.789874, Data Loss: 4.786628, Physics Loss: 0.000325\n",
      "Epoch 1696/2000, Total Loss: 4.788349, Data Loss: 4.785910, Physics Loss: 0.000244\n",
      "Epoch 1697/2000, Total Loss: 4.787225, Data Loss: 4.785155, Physics Loss: 0.000207\n",
      "Epoch 1698/2000, Total Loss: 4.787099, Data Loss: 4.785088, Physics Loss: 0.000201\n",
      "Epoch 1699/2000, Total Loss: 4.787734, Data Loss: 4.785528, Physics Loss: 0.000221\n",
      "Epoch 1700/2000, Total Loss: 4.788261, Data Loss: 4.785784, Physics Loss: 0.000248\n",
      "Epoch 1701/2000, Total Loss: 4.788236, Data Loss: 4.785877, Physics Loss: 0.000236\n",
      "Epoch 1702/2000, Total Loss: 4.787631, Data Loss: 4.785412, Physics Loss: 0.000222\n",
      "Epoch 1703/2000, Total Loss: 4.787098, Data Loss: 4.785106, Physics Loss: 0.000199\n",
      "Epoch 1704/2000, Total Loss: 4.786995, Data Loss: 4.785028, Physics Loss: 0.000197\n",
      "Epoch 1705/2000, Total Loss: 4.787244, Data Loss: 4.785163, Physics Loss: 0.000208\n",
      "Epoch 1706/2000, Total Loss: 4.787453, Data Loss: 4.785336, Physics Loss: 0.000212\n",
      "Epoch 1707/2000, Total Loss: 4.787352, Data Loss: 4.785194, Physics Loss: 0.000216\n",
      "Epoch 1708/2000, Total Loss: 4.787072, Data Loss: 4.785045, Physics Loss: 0.000203\n",
      "Epoch 1709/2000, Total Loss: 4.786905, Data Loss: 4.784904, Physics Loss: 0.000200\n",
      "Epoch 1710/2000, Total Loss: 4.786921, Data Loss: 4.784911, Physics Loss: 0.000201\n",
      "Epoch 1711/2000, Total Loss: 4.787018, Data Loss: 4.784997, Physics Loss: 0.000202\n",
      "Epoch 1712/2000, Total Loss: 4.787035, Data Loss: 4.784940, Physics Loss: 0.000210\n",
      "Epoch 1713/2000, Total Loss: 4.786992, Data Loss: 4.784937, Physics Loss: 0.000205\n",
      "Epoch 1714/2000, Total Loss: 4.786920, Data Loss: 4.784846, Physics Loss: 0.000207\n",
      "Epoch 1715/2000, Total Loss: 4.786847, Data Loss: 4.784818, Physics Loss: 0.000203\n",
      "Epoch 1716/2000, Total Loss: 4.786798, Data Loss: 4.784770, Physics Loss: 0.000203\n",
      "Epoch 1717/2000, Total Loss: 4.786789, Data Loss: 4.784758, Physics Loss: 0.000203\n",
      "Epoch 1718/2000, Total Loss: 4.786801, Data Loss: 4.784759, Physics Loss: 0.000204\n",
      "Epoch 1719/2000, Total Loss: 4.786810, Data Loss: 4.784747, Physics Loss: 0.000206\n",
      "Epoch 1720/2000, Total Loss: 4.786811, Data Loss: 4.784766, Physics Loss: 0.000205\n",
      "Epoch 1721/2000, Total Loss: 4.786818, Data Loss: 4.784738, Physics Loss: 0.000208\n",
      "Epoch 1722/2000, Total Loss: 4.786814, Data Loss: 4.784765, Physics Loss: 0.000205\n",
      "Epoch 1723/2000, Total Loss: 4.786789, Data Loss: 4.784719, Physics Loss: 0.000207\n",
      "Epoch 1724/2000, Total Loss: 4.786756, Data Loss: 4.784721, Physics Loss: 0.000204\n",
      "Epoch 1725/2000, Total Loss: 4.786726, Data Loss: 4.784685, Physics Loss: 0.000204\n",
      "Epoch 1726/2000, Total Loss: 4.786720, Data Loss: 4.784685, Physics Loss: 0.000203\n",
      "Epoch 1727/2000, Total Loss: 4.786726, Data Loss: 4.784692, Physics Loss: 0.000203\n",
      "Epoch 1728/2000, Total Loss: 4.786734, Data Loss: 4.784684, Physics Loss: 0.000205\n",
      "Epoch 1729/2000, Total Loss: 4.786740, Data Loss: 4.784706, Physics Loss: 0.000203\n",
      "Epoch 1730/2000, Total Loss: 4.786737, Data Loss: 4.784679, Physics Loss: 0.000206\n",
      "Epoch 1731/2000, Total Loss: 4.786726, Data Loss: 4.784692, Physics Loss: 0.000203\n",
      "Epoch 1732/2000, Total Loss: 4.786714, Data Loss: 4.784665, Physics Loss: 0.000205\n",
      "Epoch 1733/2000, Total Loss: 4.786700, Data Loss: 4.784670, Physics Loss: 0.000203\n",
      "Epoch 1734/2000, Total Loss: 4.786688, Data Loss: 4.784651, Physics Loss: 0.000204\n",
      "Epoch 1735/2000, Total Loss: 4.786672, Data Loss: 4.784650, Physics Loss: 0.000202\n",
      "Epoch 1736/2000, Total Loss: 4.786665, Data Loss: 4.784638, Physics Loss: 0.000203\n",
      "Epoch 1737/2000, Total Loss: 4.786652, Data Loss: 4.784627, Physics Loss: 0.000202\n",
      "Epoch 1738/2000, Total Loss: 4.786650, Data Loss: 4.784626, Physics Loss: 0.000202\n",
      "Epoch 1739/2000, Total Loss: 4.786659, Data Loss: 4.784619, Physics Loss: 0.000204\n",
      "Epoch 1740/2000, Total Loss: 4.786662, Data Loss: 4.784630, Physics Loss: 0.000203\n",
      "Epoch 1741/2000, Total Loss: 4.786669, Data Loss: 4.784614, Physics Loss: 0.000206\n",
      "Epoch 1742/2000, Total Loss: 4.786669, Data Loss: 4.784633, Physics Loss: 0.000204\n",
      "Epoch 1743/2000, Total Loss: 4.786666, Data Loss: 4.784605, Physics Loss: 0.000206\n",
      "Epoch 1744/2000, Total Loss: 4.786652, Data Loss: 4.784617, Physics Loss: 0.000203\n",
      "Epoch 1745/2000, Total Loss: 4.786633, Data Loss: 4.784581, Physics Loss: 0.000205\n",
      "Epoch 1746/2000, Total Loss: 4.786619, Data Loss: 4.784585, Physics Loss: 0.000203\n",
      "Epoch 1747/2000, Total Loss: 4.786602, Data Loss: 4.784562, Physics Loss: 0.000204\n",
      "Epoch 1748/2000, Total Loss: 4.786590, Data Loss: 4.784563, Physics Loss: 0.000203\n",
      "Epoch 1749/2000, Total Loss: 4.786582, Data Loss: 4.784547, Physics Loss: 0.000204\n",
      "Epoch 1750/2000, Total Loss: 4.786572, Data Loss: 4.784546, Physics Loss: 0.000203\n",
      "Epoch 1751/2000, Total Loss: 4.786564, Data Loss: 4.784539, Physics Loss: 0.000203\n",
      "Epoch 1752/2000, Total Loss: 4.786556, Data Loss: 4.784527, Physics Loss: 0.000203\n",
      "Epoch 1753/2000, Total Loss: 4.786559, Data Loss: 4.784530, Physics Loss: 0.000203\n",
      "Epoch 1754/2000, Total Loss: 4.786556, Data Loss: 4.784519, Physics Loss: 0.000204\n",
      "Epoch 1755/2000, Total Loss: 4.786556, Data Loss: 4.784525, Physics Loss: 0.000203\n",
      "Epoch 1756/2000, Total Loss: 4.786551, Data Loss: 4.784509, Physics Loss: 0.000204\n",
      "Epoch 1757/2000, Total Loss: 4.786538, Data Loss: 4.784509, Physics Loss: 0.000203\n",
      "Epoch 1758/2000, Total Loss: 4.786536, Data Loss: 4.784495, Physics Loss: 0.000204\n",
      "Epoch 1759/2000, Total Loss: 4.786540, Data Loss: 4.784503, Physics Loss: 0.000204\n",
      "Epoch 1760/2000, Total Loss: 4.786533, Data Loss: 4.784488, Physics Loss: 0.000204\n",
      "Epoch 1761/2000, Total Loss: 4.786527, Data Loss: 4.784496, Physics Loss: 0.000203\n",
      "Epoch 1762/2000, Total Loss: 4.786527, Data Loss: 4.784478, Physics Loss: 0.000205\n",
      "Epoch 1763/2000, Total Loss: 4.786535, Data Loss: 4.784501, Physics Loss: 0.000203\n",
      "Epoch 1764/2000, Total Loss: 4.786544, Data Loss: 4.784486, Physics Loss: 0.000206\n",
      "Epoch 1765/2000, Total Loss: 4.786545, Data Loss: 4.784504, Physics Loss: 0.000204\n",
      "Epoch 1766/2000, Total Loss: 4.786560, Data Loss: 4.784484, Physics Loss: 0.000208\n",
      "Epoch 1767/2000, Total Loss: 4.786587, Data Loss: 4.784525, Physics Loss: 0.000206\n",
      "Epoch 1768/2000, Total Loss: 4.786627, Data Loss: 4.784508, Physics Loss: 0.000212\n",
      "Epoch 1769/2000, Total Loss: 4.786686, Data Loss: 4.784584, Physics Loss: 0.000210\n",
      "Epoch 1770/2000, Total Loss: 4.786757, Data Loss: 4.784569, Physics Loss: 0.000219\n",
      "Epoch 1771/2000, Total Loss: 4.786865, Data Loss: 4.784709, Physics Loss: 0.000216\n",
      "Epoch 1772/2000, Total Loss: 4.786968, Data Loss: 4.784700, Physics Loss: 0.000227\n",
      "Epoch 1773/2000, Total Loss: 4.787091, Data Loss: 4.784865, Physics Loss: 0.000223\n",
      "Epoch 1774/2000, Total Loss: 4.787216, Data Loss: 4.784835, Physics Loss: 0.000238\n",
      "Epoch 1775/2000, Total Loss: 4.787472, Data Loss: 4.785079, Physics Loss: 0.000239\n",
      "Epoch 1776/2000, Total Loss: 4.787823, Data Loss: 4.785146, Physics Loss: 0.000268\n",
      "Epoch 1777/2000, Total Loss: 4.788457, Data Loss: 4.785654, Physics Loss: 0.000280\n",
      "Epoch 1778/2000, Total Loss: 4.789159, Data Loss: 4.785875, Physics Loss: 0.000328\n",
      "Epoch 1779/2000, Total Loss: 4.790317, Data Loss: 4.786808, Physics Loss: 0.000351\n",
      "Epoch 1780/2000, Total Loss: 4.791112, Data Loss: 4.787015, Physics Loss: 0.000410\n",
      "Epoch 1781/2000, Total Loss: 4.792338, Data Loss: 4.788157, Physics Loss: 0.000418\n",
      "Epoch 1782/2000, Total Loss: 4.792213, Data Loss: 4.787773, Physics Loss: 0.000444\n",
      "Epoch 1783/2000, Total Loss: 4.791814, Data Loss: 4.787964, Physics Loss: 0.000385\n",
      "Epoch 1784/2000, Total Loss: 4.789673, Data Loss: 4.786404, Physics Loss: 0.000327\n",
      "Epoch 1785/2000, Total Loss: 4.787677, Data Loss: 4.785360, Physics Loss: 0.000232\n",
      "Epoch 1786/2000, Total Loss: 4.786641, Data Loss: 4.784675, Physics Loss: 0.000197\n",
      "Epoch 1787/2000, Total Loss: 4.787116, Data Loss: 4.784955, Physics Loss: 0.000216\n",
      "Epoch 1788/2000, Total Loss: 4.788248, Data Loss: 4.785782, Physics Loss: 0.000247\n",
      "Epoch 1789/2000, Total Loss: 4.788576, Data Loss: 4.785847, Physics Loss: 0.000273\n",
      "Epoch 1790/2000, Total Loss: 4.787956, Data Loss: 4.785592, Physics Loss: 0.000236\n",
      "Epoch 1791/2000, Total Loss: 4.786936, Data Loss: 4.784877, Physics Loss: 0.000206\n",
      "Epoch 1792/2000, Total Loss: 4.786580, Data Loss: 4.784655, Physics Loss: 0.000192\n",
      "Epoch 1793/2000, Total Loss: 4.787038, Data Loss: 4.784957, Physics Loss: 0.000208\n",
      "Epoch 1794/2000, Total Loss: 4.787587, Data Loss: 4.785248, Physics Loss: 0.000234\n",
      "Epoch 1795/2000, Total Loss: 4.787611, Data Loss: 4.785334, Physics Loss: 0.000228\n",
      "Epoch 1796/2000, Total Loss: 4.787045, Data Loss: 4.784896, Physics Loss: 0.000215\n",
      "Epoch 1797/2000, Total Loss: 4.786565, Data Loss: 4.784608, Physics Loss: 0.000196\n",
      "Epoch 1798/2000, Total Loss: 4.786542, Data Loss: 4.784579, Physics Loss: 0.000196\n",
      "Epoch 1799/2000, Total Loss: 4.786881, Data Loss: 4.784738, Physics Loss: 0.000214\n",
      "Epoch 1800/2000, Total Loss: 4.787179, Data Loss: 4.785016, Physics Loss: 0.000216\n",
      "Epoch 1801/2000, Total Loss: 4.787116, Data Loss: 4.784873, Physics Loss: 0.000224\n",
      "Epoch 1802/2000, Total Loss: 4.786782, Data Loss: 4.784727, Physics Loss: 0.000206\n",
      "Epoch 1803/2000, Total Loss: 4.786461, Data Loss: 4.784458, Physics Loss: 0.000200\n",
      "Epoch 1804/2000, Total Loss: 4.786419, Data Loss: 4.784427, Physics Loss: 0.000199\n",
      "Epoch 1805/2000, Total Loss: 4.786589, Data Loss: 4.784559, Physics Loss: 0.000203\n",
      "Epoch 1806/2000, Total Loss: 4.786769, Data Loss: 4.784608, Physics Loss: 0.000216\n",
      "Epoch 1807/2000, Total Loss: 4.786818, Data Loss: 4.784695, Physics Loss: 0.000212\n",
      "Epoch 1808/2000, Total Loss: 4.786686, Data Loss: 4.784533, Physics Loss: 0.000215\n",
      "Epoch 1809/2000, Total Loss: 4.786499, Data Loss: 4.784463, Physics Loss: 0.000204\n",
      "Epoch 1810/2000, Total Loss: 4.786368, Data Loss: 4.784348, Physics Loss: 0.000202\n",
      "Epoch 1811/2000, Total Loss: 4.786371, Data Loss: 4.784342, Physics Loss: 0.000203\n",
      "Epoch 1812/2000, Total Loss: 4.786454, Data Loss: 4.784420, Physics Loss: 0.000203\n",
      "Epoch 1813/2000, Total Loss: 4.786514, Data Loss: 4.784408, Physics Loss: 0.000211\n",
      "Epoch 1814/2000, Total Loss: 4.786504, Data Loss: 4.784452, Physics Loss: 0.000205\n",
      "Epoch 1815/2000, Total Loss: 4.786430, Data Loss: 4.784365, Physics Loss: 0.000207\n",
      "Epoch 1816/2000, Total Loss: 4.786353, Data Loss: 4.784347, Physics Loss: 0.000201\n",
      "Epoch 1817/2000, Total Loss: 4.786311, Data Loss: 4.784305, Physics Loss: 0.000201\n",
      "Epoch 1818/2000, Total Loss: 4.786310, Data Loss: 4.784303, Physics Loss: 0.000201\n",
      "Epoch 1819/2000, Total Loss: 4.786350, Data Loss: 4.784346, Physics Loss: 0.000200\n",
      "Epoch 1820/2000, Total Loss: 4.786391, Data Loss: 4.784338, Physics Loss: 0.000205\n",
      "Epoch 1821/2000, Total Loss: 4.786382, Data Loss: 4.784365, Physics Loss: 0.000202\n",
      "Epoch 1822/2000, Total Loss: 4.786360, Data Loss: 4.784315, Physics Loss: 0.000205\n",
      "Epoch 1823/2000, Total Loss: 4.786335, Data Loss: 4.784326, Physics Loss: 0.000201\n",
      "Epoch 1824/2000, Total Loss: 4.786307, Data Loss: 4.784282, Physics Loss: 0.000203\n",
      "Epoch 1825/2000, Total Loss: 4.786279, Data Loss: 4.784282, Physics Loss: 0.000200\n",
      "Epoch 1826/2000, Total Loss: 4.786256, Data Loss: 4.784255, Physics Loss: 0.000200\n",
      "Epoch 1827/2000, Total Loss: 4.786261, Data Loss: 4.784254, Physics Loss: 0.000201\n",
      "Epoch 1828/2000, Total Loss: 4.786300, Data Loss: 4.784289, Physics Loss: 0.000201\n",
      "Epoch 1829/2000, Total Loss: 4.786362, Data Loss: 4.784290, Physics Loss: 0.000207\n",
      "Epoch 1830/2000, Total Loss: 4.786419, Data Loss: 4.784366, Physics Loss: 0.000205\n",
      "Epoch 1831/2000, Total Loss: 4.786439, Data Loss: 4.784330, Physics Loss: 0.000211\n",
      "Epoch 1832/2000, Total Loss: 4.786439, Data Loss: 4.784384, Physics Loss: 0.000206\n",
      "Epoch 1833/2000, Total Loss: 4.786412, Data Loss: 4.784316, Physics Loss: 0.000210\n",
      "Epoch 1834/2000, Total Loss: 4.786360, Data Loss: 4.784327, Physics Loss: 0.000203\n",
      "Epoch 1835/2000, Total Loss: 4.786304, Data Loss: 4.784246, Physics Loss: 0.000206\n",
      "Epoch 1836/2000, Total Loss: 4.786243, Data Loss: 4.784236, Physics Loss: 0.000201\n",
      "Epoch 1837/2000, Total Loss: 4.786206, Data Loss: 4.784192, Physics Loss: 0.000201\n",
      "Epoch 1838/2000, Total Loss: 4.786185, Data Loss: 4.784195, Physics Loss: 0.000199\n",
      "Epoch 1839/2000, Total Loss: 4.786166, Data Loss: 4.784175, Physics Loss: 0.000199\n",
      "Epoch 1840/2000, Total Loss: 4.786164, Data Loss: 4.784171, Physics Loss: 0.000199\n",
      "Epoch 1841/2000, Total Loss: 4.786165, Data Loss: 4.784176, Physics Loss: 0.000199\n",
      "Epoch 1842/2000, Total Loss: 4.786170, Data Loss: 4.784164, Physics Loss: 0.000201\n",
      "Epoch 1843/2000, Total Loss: 4.786180, Data Loss: 4.784183, Physics Loss: 0.000200\n",
      "Epoch 1844/2000, Total Loss: 4.786174, Data Loss: 4.784158, Physics Loss: 0.000202\n",
      "Epoch 1845/2000, Total Loss: 4.786163, Data Loss: 4.784171, Physics Loss: 0.000199\n",
      "Epoch 1846/2000, Total Loss: 4.786149, Data Loss: 4.784142, Physics Loss: 0.000201\n",
      "Epoch 1847/2000, Total Loss: 4.786133, Data Loss: 4.784146, Physics Loss: 0.000199\n",
      "Epoch 1848/2000, Total Loss: 4.786120, Data Loss: 4.784123, Physics Loss: 0.000200\n",
      "Epoch 1849/2000, Total Loss: 4.786113, Data Loss: 4.784126, Physics Loss: 0.000199\n",
      "Epoch 1850/2000, Total Loss: 4.786102, Data Loss: 4.784111, Physics Loss: 0.000199\n",
      "Epoch 1851/2000, Total Loss: 4.786094, Data Loss: 4.784106, Physics Loss: 0.000199\n",
      "Epoch 1852/2000, Total Loss: 4.786089, Data Loss: 4.784101, Physics Loss: 0.000199\n",
      "Epoch 1853/2000, Total Loss: 4.786087, Data Loss: 4.784091, Physics Loss: 0.000200\n",
      "Epoch 1854/2000, Total Loss: 4.786085, Data Loss: 4.784100, Physics Loss: 0.000199\n",
      "Epoch 1855/2000, Total Loss: 4.786077, Data Loss: 4.784080, Physics Loss: 0.000200\n",
      "Epoch 1856/2000, Total Loss: 4.786068, Data Loss: 4.784081, Physics Loss: 0.000199\n",
      "Epoch 1857/2000, Total Loss: 4.786064, Data Loss: 4.784067, Physics Loss: 0.000200\n",
      "Epoch 1858/2000, Total Loss: 4.786068, Data Loss: 4.784075, Physics Loss: 0.000199\n",
      "Epoch 1859/2000, Total Loss: 4.786069, Data Loss: 4.784062, Physics Loss: 0.000201\n",
      "Epoch 1860/2000, Total Loss: 4.786061, Data Loss: 4.784069, Physics Loss: 0.000199\n",
      "Epoch 1861/2000, Total Loss: 4.786072, Data Loss: 4.784056, Physics Loss: 0.000202\n",
      "Epoch 1862/2000, Total Loss: 4.786087, Data Loss: 4.784093, Physics Loss: 0.000199\n",
      "Epoch 1863/2000, Total Loss: 4.786091, Data Loss: 4.784061, Physics Loss: 0.000203\n",
      "Epoch 1864/2000, Total Loss: 4.786084, Data Loss: 4.784078, Physics Loss: 0.000201\n",
      "Epoch 1865/2000, Total Loss: 4.786068, Data Loss: 4.784038, Physics Loss: 0.000203\n",
      "Epoch 1866/2000, Total Loss: 4.786061, Data Loss: 4.784057, Physics Loss: 0.000200\n",
      "Epoch 1867/2000, Total Loss: 4.786057, Data Loss: 4.784028, Physics Loss: 0.000203\n",
      "Epoch 1868/2000, Total Loss: 4.786040, Data Loss: 4.784042, Physics Loss: 0.000200\n",
      "Epoch 1869/2000, Total Loss: 4.786040, Data Loss: 4.784018, Physics Loss: 0.000202\n",
      "Epoch 1870/2000, Total Loss: 4.786054, Data Loss: 4.784053, Physics Loss: 0.000200\n",
      "Epoch 1871/2000, Total Loss: 4.786064, Data Loss: 4.784030, Physics Loss: 0.000203\n",
      "Epoch 1872/2000, Total Loss: 4.786051, Data Loss: 4.784052, Physics Loss: 0.000200\n",
      "Epoch 1873/2000, Total Loss: 4.786027, Data Loss: 4.784002, Physics Loss: 0.000203\n",
      "Epoch 1874/2000, Total Loss: 4.786010, Data Loss: 4.784011, Physics Loss: 0.000200\n",
      "Epoch 1875/2000, Total Loss: 4.786001, Data Loss: 4.783982, Physics Loss: 0.000202\n",
      "Epoch 1876/2000, Total Loss: 4.785987, Data Loss: 4.783993, Physics Loss: 0.000199\n",
      "Epoch 1877/2000, Total Loss: 4.785973, Data Loss: 4.783963, Physics Loss: 0.000201\n",
      "Epoch 1878/2000, Total Loss: 4.785958, Data Loss: 4.783971, Physics Loss: 0.000199\n",
      "Epoch 1879/2000, Total Loss: 4.785947, Data Loss: 4.783950, Physics Loss: 0.000200\n",
      "Epoch 1880/2000, Total Loss: 4.785943, Data Loss: 4.783951, Physics Loss: 0.000199\n",
      "Epoch 1881/2000, Total Loss: 4.785941, Data Loss: 4.783947, Physics Loss: 0.000199\n",
      "Epoch 1882/2000, Total Loss: 4.785945, Data Loss: 4.783937, Physics Loss: 0.000201\n",
      "Epoch 1883/2000, Total Loss: 4.785970, Data Loss: 4.783972, Physics Loss: 0.000200\n",
      "Epoch 1884/2000, Total Loss: 4.786020, Data Loss: 4.783967, Physics Loss: 0.000205\n",
      "Epoch 1885/2000, Total Loss: 4.786104, Data Loss: 4.784063, Physics Loss: 0.000204\n",
      "Epoch 1886/2000, Total Loss: 4.786250, Data Loss: 4.784087, Physics Loss: 0.000216\n",
      "Epoch 1887/2000, Total Loss: 4.786499, Data Loss: 4.784309, Physics Loss: 0.000219\n",
      "Epoch 1888/2000, Total Loss: 4.786885, Data Loss: 4.784433, Physics Loss: 0.000245\n",
      "Epoch 1889/2000, Total Loss: 4.787556, Data Loss: 4.784956, Physics Loss: 0.000260\n",
      "Epoch 1890/2000, Total Loss: 4.788498, Data Loss: 4.785322, Physics Loss: 0.000318\n",
      "Epoch 1891/2000, Total Loss: 4.790189, Data Loss: 4.786553, Physics Loss: 0.000364\n",
      "Epoch 1892/2000, Total Loss: 4.791962, Data Loss: 4.787292, Physics Loss: 0.000467\n",
      "Epoch 1893/2000, Total Loss: 4.795192, Data Loss: 4.789706, Physics Loss: 0.000549\n",
      "Epoch 1894/2000, Total Loss: 4.796744, Data Loss: 4.790157, Physics Loss: 0.000659\n",
      "Epoch 1895/2000, Total Loss: 4.799069, Data Loss: 4.792406, Physics Loss: 0.000666\n",
      "Epoch 1896/2000, Total Loss: 4.795698, Data Loss: 4.789866, Physics Loss: 0.000583\n",
      "Epoch 1897/2000, Total Loss: 4.791300, Data Loss: 4.787709, Physics Loss: 0.000359\n",
      "Epoch 1898/2000, Total Loss: 4.786860, Data Loss: 4.784719, Physics Loss: 0.000214\n",
      "Epoch 1899/2000, Total Loss: 4.787218, Data Loss: 4.784933, Physics Loss: 0.000229\n",
      "Epoch 1900/2000, Total Loss: 4.790314, Data Loss: 4.787201, Physics Loss: 0.000311\n",
      "Epoch 1901/2000, Total Loss: 4.790127, Data Loss: 4.786921, Physics Loss: 0.000321\n",
      "Epoch 1902/2000, Total Loss: 4.787487, Data Loss: 4.785352, Physics Loss: 0.000214\n",
      "Epoch 1903/2000, Total Loss: 4.786627, Data Loss: 4.784663, Physics Loss: 0.000196\n",
      "Epoch 1904/2000, Total Loss: 4.788413, Data Loss: 4.785820, Physics Loss: 0.000259\n",
      "Epoch 1905/2000, Total Loss: 4.789022, Data Loss: 4.786406, Physics Loss: 0.000262\n",
      "Epoch 1906/2000, Total Loss: 4.787219, Data Loss: 4.785096, Physics Loss: 0.000212\n",
      "Epoch 1907/2000, Total Loss: 4.786521, Data Loss: 4.784566, Physics Loss: 0.000195\n",
      "Epoch 1908/2000, Total Loss: 4.787625, Data Loss: 4.785307, Physics Loss: 0.000232\n",
      "Epoch 1909/2000, Total Loss: 4.787971, Data Loss: 4.785620, Physics Loss: 0.000235\n",
      "Epoch 1910/2000, Total Loss: 4.786957, Data Loss: 4.784906, Physics Loss: 0.000205\n",
      "Epoch 1911/2000, Total Loss: 4.786328, Data Loss: 4.784359, Physics Loss: 0.000197\n",
      "Epoch 1912/2000, Total Loss: 4.787078, Data Loss: 4.784846, Physics Loss: 0.000223\n",
      "Epoch 1913/2000, Total Loss: 4.787647, Data Loss: 4.785413, Physics Loss: 0.000223\n",
      "Epoch 1914/2000, Total Loss: 4.786854, Data Loss: 4.784737, Physics Loss: 0.000212\n",
      "Epoch 1915/2000, Total Loss: 4.786138, Data Loss: 4.784179, Physics Loss: 0.000196\n",
      "Epoch 1916/2000, Total Loss: 4.786599, Data Loss: 4.784562, Physics Loss: 0.000204\n",
      "Epoch 1917/2000, Total Loss: 4.787245, Data Loss: 4.784929, Physics Loss: 0.000232\n",
      "Epoch 1918/2000, Total Loss: 4.786914, Data Loss: 4.784795, Physics Loss: 0.000212\n",
      "Epoch 1919/2000, Total Loss: 4.786101, Data Loss: 4.784117, Physics Loss: 0.000198\n",
      "Epoch 1920/2000, Total Loss: 4.786076, Data Loss: 4.784085, Physics Loss: 0.000199\n",
      "Epoch 1921/2000, Total Loss: 4.786625, Data Loss: 4.784536, Physics Loss: 0.000209\n",
      "Epoch 1922/2000, Total Loss: 4.786776, Data Loss: 4.784567, Physics Loss: 0.000221\n",
      "Epoch 1923/2000, Total Loss: 4.786347, Data Loss: 4.784298, Physics Loss: 0.000205\n",
      "Epoch 1924/2000, Total Loss: 4.785969, Data Loss: 4.783973, Physics Loss: 0.000200\n",
      "Epoch 1925/2000, Total Loss: 4.786090, Data Loss: 4.784073, Physics Loss: 0.000202\n",
      "Epoch 1926/2000, Total Loss: 4.786371, Data Loss: 4.784320, Physics Loss: 0.000205\n",
      "Epoch 1927/2000, Total Loss: 4.786388, Data Loss: 4.784213, Physics Loss: 0.000218\n",
      "Epoch 1928/2000, Total Loss: 4.786212, Data Loss: 4.784163, Physics Loss: 0.000205\n",
      "Epoch 1929/2000, Total Loss: 4.786014, Data Loss: 4.783994, Physics Loss: 0.000202\n",
      "Epoch 1930/2000, Total Loss: 4.785943, Data Loss: 4.783969, Physics Loss: 0.000197\n",
      "Epoch 1931/2000, Total Loss: 4.786026, Data Loss: 4.784053, Physics Loss: 0.000197\n",
      "Epoch 1932/2000, Total Loss: 4.786095, Data Loss: 4.784043, Physics Loss: 0.000205\n",
      "Epoch 1933/2000, Total Loss: 4.786011, Data Loss: 4.784029, Physics Loss: 0.000198\n",
      "Epoch 1934/2000, Total Loss: 4.785879, Data Loss: 4.783933, Physics Loss: 0.000195\n",
      "Epoch 1935/2000, Total Loss: 4.785851, Data Loss: 4.783916, Physics Loss: 0.000193\n",
      "Epoch 1936/2000, Total Loss: 4.785933, Data Loss: 4.783981, Physics Loss: 0.000195\n",
      "Epoch 1937/2000, Total Loss: 4.785967, Data Loss: 4.783972, Physics Loss: 0.000200\n",
      "Epoch 1938/2000, Total Loss: 4.785913, Data Loss: 4.783971, Physics Loss: 0.000194\n",
      "Epoch 1939/2000, Total Loss: 4.785839, Data Loss: 4.783898, Physics Loss: 0.000194\n",
      "Epoch 1940/2000, Total Loss: 4.785811, Data Loss: 4.783885, Physics Loss: 0.000193\n",
      "Epoch 1941/2000, Total Loss: 4.785823, Data Loss: 4.783897, Physics Loss: 0.000193\n",
      "Epoch 1942/2000, Total Loss: 4.785864, Data Loss: 4.783894, Physics Loss: 0.000197\n",
      "Epoch 1943/2000, Total Loss: 4.785867, Data Loss: 4.783931, Physics Loss: 0.000194\n",
      "Epoch 1944/2000, Total Loss: 4.785804, Data Loss: 4.783859, Physics Loss: 0.000195\n",
      "Epoch 1945/2000, Total Loss: 4.785745, Data Loss: 4.783827, Physics Loss: 0.000192\n",
      "Epoch 1946/2000, Total Loss: 4.785750, Data Loss: 4.783832, Physics Loss: 0.000192\n",
      "Epoch 1947/2000, Total Loss: 4.785805, Data Loss: 4.783848, Physics Loss: 0.000196\n",
      "Epoch 1948/2000, Total Loss: 4.785832, Data Loss: 4.783901, Physics Loss: 0.000193\n",
      "Epoch 1949/2000, Total Loss: 4.785783, Data Loss: 4.783828, Physics Loss: 0.000196\n",
      "Epoch 1950/2000, Total Loss: 4.785716, Data Loss: 4.783804, Physics Loss: 0.000191\n",
      "Epoch 1951/2000, Total Loss: 4.785683, Data Loss: 4.783770, Physics Loss: 0.000191\n",
      "Epoch 1952/2000, Total Loss: 4.785680, Data Loss: 4.783766, Physics Loss: 0.000191\n",
      "Epoch 1953/2000, Total Loss: 4.785689, Data Loss: 4.783779, Physics Loss: 0.000191\n",
      "Epoch 1954/2000, Total Loss: 4.785697, Data Loss: 4.783765, Physics Loss: 0.000193\n",
      "Epoch 1955/2000, Total Loss: 4.785691, Data Loss: 4.783777, Physics Loss: 0.000191\n",
      "Epoch 1956/2000, Total Loss: 4.785668, Data Loss: 4.783744, Physics Loss: 0.000192\n",
      "Epoch 1957/2000, Total Loss: 4.785640, Data Loss: 4.783739, Physics Loss: 0.000190\n",
      "Epoch 1958/2000, Total Loss: 4.785624, Data Loss: 4.783723, Physics Loss: 0.000190\n",
      "Epoch 1959/2000, Total Loss: 4.785619, Data Loss: 4.783716, Physics Loss: 0.000190\n",
      "Epoch 1960/2000, Total Loss: 4.785616, Data Loss: 4.783720, Physics Loss: 0.000190\n",
      "Epoch 1961/2000, Total Loss: 4.785606, Data Loss: 4.783704, Physics Loss: 0.000190\n",
      "Epoch 1962/2000, Total Loss: 4.785602, Data Loss: 4.783707, Physics Loss: 0.000189\n",
      "Epoch 1963/2000, Total Loss: 4.785592, Data Loss: 4.783693, Physics Loss: 0.000190\n",
      "Epoch 1964/2000, Total Loss: 4.785583, Data Loss: 4.783691, Physics Loss: 0.000189\n",
      "Epoch 1965/2000, Total Loss: 4.785576, Data Loss: 4.783681, Physics Loss: 0.000190\n",
      "Epoch 1966/2000, Total Loss: 4.785566, Data Loss: 4.783669, Physics Loss: 0.000190\n",
      "Epoch 1967/2000, Total Loss: 4.785565, Data Loss: 4.783672, Physics Loss: 0.000189\n",
      "Epoch 1968/2000, Total Loss: 4.785558, Data Loss: 4.783662, Physics Loss: 0.000190\n",
      "Epoch 1969/2000, Total Loss: 4.785551, Data Loss: 4.783658, Physics Loss: 0.000189\n",
      "Epoch 1970/2000, Total Loss: 4.785549, Data Loss: 4.783656, Physics Loss: 0.000189\n",
      "Epoch 1971/2000, Total Loss: 4.785538, Data Loss: 4.783643, Physics Loss: 0.000189\n",
      "Epoch 1972/2000, Total Loss: 4.785536, Data Loss: 4.783643, Physics Loss: 0.000189\n",
      "Epoch 1973/2000, Total Loss: 4.785528, Data Loss: 4.783630, Physics Loss: 0.000190\n",
      "Epoch 1974/2000, Total Loss: 4.785519, Data Loss: 4.783628, Physics Loss: 0.000189\n",
      "Epoch 1975/2000, Total Loss: 4.785517, Data Loss: 4.783617, Physics Loss: 0.000190\n",
      "Epoch 1976/2000, Total Loss: 4.785517, Data Loss: 4.783621, Physics Loss: 0.000190\n",
      "Epoch 1977/2000, Total Loss: 4.785521, Data Loss: 4.783611, Physics Loss: 0.000191\n",
      "Epoch 1978/2000, Total Loss: 4.785514, Data Loss: 4.783614, Physics Loss: 0.000190\n",
      "Epoch 1979/2000, Total Loss: 4.785511, Data Loss: 4.783593, Physics Loss: 0.000192\n",
      "Epoch 1980/2000, Total Loss: 4.785518, Data Loss: 4.783617, Physics Loss: 0.000190\n",
      "Epoch 1981/2000, Total Loss: 4.785513, Data Loss: 4.783591, Physics Loss: 0.000192\n",
      "Epoch 1982/2000, Total Loss: 4.785502, Data Loss: 4.783606, Physics Loss: 0.000190\n",
      "Epoch 1983/2000, Total Loss: 4.785478, Data Loss: 4.783567, Physics Loss: 0.000191\n",
      "Epoch 1984/2000, Total Loss: 4.785462, Data Loss: 4.783563, Physics Loss: 0.000190\n",
      "Epoch 1985/2000, Total Loss: 4.785446, Data Loss: 4.783547, Physics Loss: 0.000190\n",
      "Epoch 1986/2000, Total Loss: 4.785448, Data Loss: 4.783545, Physics Loss: 0.000190\n",
      "Epoch 1987/2000, Total Loss: 4.785453, Data Loss: 4.783552, Physics Loss: 0.000190\n",
      "Epoch 1988/2000, Total Loss: 4.785450, Data Loss: 4.783536, Physics Loss: 0.000191\n",
      "Epoch 1989/2000, Total Loss: 4.785450, Data Loss: 4.783553, Physics Loss: 0.000190\n",
      "Epoch 1990/2000, Total Loss: 4.785448, Data Loss: 4.783529, Physics Loss: 0.000192\n",
      "Epoch 1991/2000, Total Loss: 4.785438, Data Loss: 4.783537, Physics Loss: 0.000190\n",
      "Epoch 1992/2000, Total Loss: 4.785429, Data Loss: 4.783514, Physics Loss: 0.000192\n",
      "Epoch 1993/2000, Total Loss: 4.785415, Data Loss: 4.783514, Physics Loss: 0.000190\n",
      "Epoch 1994/2000, Total Loss: 4.785399, Data Loss: 4.783494, Physics Loss: 0.000190\n",
      "Epoch 1995/2000, Total Loss: 4.785392, Data Loss: 4.783491, Physics Loss: 0.000190\n",
      "Epoch 1996/2000, Total Loss: 4.785389, Data Loss: 4.783489, Physics Loss: 0.000190\n",
      "Epoch 1997/2000, Total Loss: 4.785385, Data Loss: 4.783483, Physics Loss: 0.000190\n",
      "Epoch 1998/2000, Total Loss: 4.785378, Data Loss: 4.783479, Physics Loss: 0.000190\n",
      "Epoch 1999/2000, Total Loss: 4.785374, Data Loss: 4.783472, Physics Loss: 0.000190\n",
      "Epoch 2000/2000, Total Loss: 4.785367, Data Loss: 4.783467, Physics Loss: 0.000190\n"
     ]
    }
   ],
   "source": [
    "loss_history = []\n",
    "loss_data_history = []\n",
    "loss_physics_history = []\n",
    "alpha = 1.0  # Peso de la pérdida de datos\n",
    "beta = 10.0  # Incrementamos el peso de la física\n",
    "model = PINNWithCNN().to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-2, momentum=0.9, weight_decay=1e-2)\n",
    "epochs = 2000\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    epoch_loss = 0.0\n",
    "    epoch_loss_data = 0.0\n",
    "    epoch_loss_physics = 0.0\n",
    "\n",
    "    for batch in loader_cnn:\n",
    "        inputs, u_true, v_true, p_true, T_true, q_true = [t.to(device) for t in batch]\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss, loss_data, loss_physics = loss_pde_cnn(model, inputs, u_true, v_true, p_true, T_true, q_true, alpha, beta)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "        epoch_loss_data += loss_data.item()\n",
    "        epoch_loss_physics += loss_physics.item()\n",
    "\n",
    "    # Guarda las pérdidas promedio de cada época\n",
    "    loss_history.append(epoch_loss / len(loader_cnn))\n",
    "    loss_data_history.append(epoch_loss_data / len(loader_cnn))\n",
    "    loss_physics_history.append(epoch_loss_physics / len(loader_cnn))\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}/{epochs}, Total Loss: {epoch_loss / len(loader_cnn):.6f}, \"\n",
    "          f\"Data Loss: {epoch_loss_data / len(loader_cnn):.6f}, \"\n",
    "          f\"Physics Loss: {epoch_loss_physics / len(loader_cnn):.6f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(loss_history, label='Total Loss')\n",
    "plt.plot(loss_data_history, label='Data Loss')\n",
    "plt.plot(loss_physics_history, label='Physics Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Loss Components Over Epochs')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
